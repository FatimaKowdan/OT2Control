<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>ml_models API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ml_models</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import time #TODO delete this debugging only
from abc import ABC
from abc import abstractmethod
import threading
from sklearn.multioutput import MultiOutputRegressor
from sklearn.linear_model import Lasso

import numpy as np

class MLModel():
    &#39;&#39;&#39;
    This is the base class of any machine learning model.  
    It provides the basic interface that is required in order to use the
    ML model with the controller  
    ATTRIBUTES:
        list&lt;int&gt; tids: a list of thread ids that this model has (or potentially some form of a
          thread executor object
        bool quit: True indicates MLModel is ready to quit, False indicates MLModel would like
          to keep going  
    &#39;&#39;&#39;
    def __init__(self, model, max_iters=np.inf):
        self.curr_iter = 0
        self.max_iters = max_iters
        self.quit = False
        self.model = model
        self.model_lock = threading.Lock()
        self.X_lock = threading.Lock()
        self.X = None
        self.quit = self.update_quit()

    def train(self, X, y):
        &#39;&#39;&#39;
        This is function is used to train the ML model.  
        Internally, launches a private thread
        This call should wait on any current training threads to complete  
        This call should launch a training thread to retrain the model on the new data
        params:
            np.array X: shape (num_pts, num_features) the recieved data for each new well
            np.array y: shape(num_pts, n_classes) the labels to predict
        &#39;&#39;&#39;
        train_thread = threading.Thread(target=self._train, name=&#39;train thread&#39;, args=(X,y))
        train_thread.start()
        self.curr_iter += 1
        self.update_quit()

    @abstractmethod
    def _train(self, X, y):
        &#39;&#39;&#39;
        This method should take care of all training. It is expected that it will update
        the model in whatever way is fitting for your model. It will be called when the user
        calls train.  
        Use extreme caution when implementing this method, and note that self is NOT threadsafe.
        i.e. if you plan on using any of the attributes of this class, make sure you lock them
        appropriately, or only use them in this method (WITH A HUGE COMMENT SOMEWHERE)  
        The line of code in this method should almost always be, with self.model_lock: ...  
        Strictly speaking, the model_lock is overkill. Since we always join this method before
        calling predict which uses the model, but it&#39;s good practice if other methods ever use
        the model_lock.  
        As long as we freeze the ml_model while training, things are simple, and this allows
        the controller to run other commands while we&#39;re training, but I&#39;ve implemented the
        architecture to have the ml_model do other work while it&#39;s training.  
        params:  
            np.array X: shape (num_pts, num_features) the recieved data for each new well  
            np.array y: shape(num_pts, n_classes) the labels to predict  
        Postconditions:  
            The model has been trained on the new data
        &#39;&#39;&#39;
        pass

    def predict(self):
        &#39;&#39;&#39;
        This is the starter code for any predict method. It must be overriden, but every override
        should first call super().predict(n_predictions)  
        This call should wait on the training thread to complete if it is has not been collected
        yet.  
        &#39;&#39;&#39;
        train_thread = [thread for thread in threading.enumerate() \
                            if thread.name == &#39;train thread&#39;]
        if train_thread:
            train_thread = train_thread[0]
            train_thread.join() #wait till you&#39;re done training

    def update_quit(self):
        &#39;&#39;&#39;
        used to update the quit parameter of this model  
        This method will just check that you have not exceded max_iters, but should be
        extended by children to check if you&#39;ve reached the target.  
        &#39;&#39;&#39;
        self.quit =  self.curr_iter &gt;= self.max_iters

    @abstractmethod
    def generate_seed_rxns(self):
        &#39;&#39;&#39;
        This method is called before the model is trained to generate a batch of training
        points  
        returns:  
            np.array: (batch_size,y.shape) 
        &#39;&#39;&#39;
        pass
        
class DummyMLModel(MLModel):
    &#39;&#39;&#39;
    This is the base class of any machine learning model.  
    It provides the basic interface that is required in order to use the
    ML model with the controller  
    ATTRIBUTES:  
        list&lt;int&gt; tids: a list of thread ids that this model has (or potentially some form of a
          thread executor object  
        bool quit: True indicates MLModel is ready to quit, False indicates MLModel would like
          to keep going  
        int curr_iter: formally, this is the number of times the train method has been called
        int max_iters: the number of iters to execute before quiting  
    &#39;&#39;&#39;
    def __init__(self, y_shape, max_iters=np.inf, batch_size=5):
        super().__init__(None, max_iters) #don&#39;t have a model
        self.y_shape = y_shape
        self.batch_size = batch_size

    def _train(self, X, y):
        &#39;&#39;&#39;
        This call should wait on any current training threads to complete  
        This call should launch a training thread to retrain the model on the new data
        training is also where current iteration is updated  
        params:  
            np.array X: shape (num_pts, num_features) the recieved data for each new well  
            np.array y: shape(num_pts, n_classes) the labels to predict  
        Postconditions:  
            The model has been trained on the new data
        &#39;&#39;&#39;
        with self.model_lock: #note for dummy this is not necessary, just an example
            print(&#39;&lt;&lt;ML&gt;&gt; training!&#39;)

    def predict(self):
        &#39;&#39;&#39;
        This call should wait on the training thread to complete if it is has not been collected
        yet.  
        params:  
            int n_predictions: the number of instances to predict  
        returns:  
            np.array: shape is n_predictions, y.shape. Features are pi e-2  
        &#39;&#39;&#39;
        with self.model_lock:
            print(&#39;&lt;&lt;ML&gt;&gt; generating preditions&#39;)
        return np.ones((self.batch_size, self.y_shape)) * 3.1415e-2

    def generate_seed_rxns(self):
        &#39;&#39;&#39;
        This method is called before the model is trained to generate a batch of training
        points  
        returns:  
            np.array: (batch_size,n_features) 
        &#39;&#39;&#39;
        if self.generate_seed_rxns.n_calls == 0:
            return np.ones((self.batch_size,self.y_shape)) * 3.1415e-2
        else:
            return np.ones((self.batch_size,self.y_shape)) * 2 * 3.1415e-2
    generate_seed_rxns.n_calls = 0

class LinReg(MLModel):
    &#39;&#39;&#39;
    Model to use Linear Regression algorithm
    model_lock also locks X
    UNIMPLEMENTED:  
      only runs for batch size of 1  
    &#39;&#39;&#39;
    def __init__(self, model, final_spectra, y_shape, max_iters, batch_size=1):
        super().__init__(model, max_iters) #don&#39;t have a model
        self.FINAL_SPECTRA = final_spectra
        self.y_shape = y_shape
        self.batch_size = batch_size

    def generate_seed_rxns(self):
        &#39;&#39;&#39;
        This method is called before the model is trained to generate a batch of training
        points  
        returns:  
            np.array: (batch_size,n_features) 
        &#39;&#39;&#39;
        #TODO talk to Mark about a good set of seeds to start at
        if self.generate_seed_rxns.n_calls == 0:
            return np.ones((self.batch_size,self.y_shape)) * 3.1415e-2
        else:
            return np.ones((self.batch_size,self.y_shape)) * 2 * 3.1415e-2
    generate_seed_rxns.n_calls = 0

    def predict(self):
        &#39;&#39;&#39;
        This call should wait on the training thread to complete if it is has not been collected
        yet.  
        params:  
            int n_predictions: the number of instances to predict  
        returns:  
            np.array: shape is n_predictions, y.shape. Features are pi e-2  
        &#39;&#39;&#39;
        super().predict()
        with self.model_lock:
            y_pred = self.model.predict(self.FINAL_SPECTRA)
        return y_pred
 
    def _train(self, X, y):
        &#39;&#39;&#39;
        This call should wait on any current training threads to complete  
        This call should launch a training thread to retrain the model on the new data
        training is also where current iteration is updated  
        params:  
            np.array X: shape (num_pts, num_features) the recieved data for each new well  
            np.array y: shape(num_pts, n_classes) the labels to predict  
        Postconditions:  
            The model has been trained on the new data
        &#39;&#39;&#39;
        #update the data with the new scans
        time.sleep(40)
        print(&#39;&lt;&lt;ML&gt;&gt; training&#39;)
        with self.model_lock:
            if isinstance(self.X,np.ndarray):
                self.X = np.concatenate((self.X, X))
                self.y = np.concatenate((self.y, y))
            else:
                self.X = X
                self.y = y
            self.model.fit(self.X, self.y)
        print(&#39;&lt;&lt;ML&gt;&gt; done training&#39;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="ml_models.DummyMLModel"><code class="flex name class">
<span>class <span class="ident">DummyMLModel</span></span>
<span>(</span><span>y_shape, max_iters=inf, batch_size=5)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the base class of any machine learning model.<br>
It provides the basic interface that is required in order to use the
ML model with the controller<br>
ATTRIBUTES:<br>
list<int> tids: a list of thread ids that this model has (or potentially some form of a
thread executor object<br>
bool quit: True indicates MLModel is ready to quit, False indicates MLModel would like
to keep going<br>
int curr_iter: formally, this is the number of times the train method has been called
int max_iters: the number of iters to execute before quiting</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DummyMLModel(MLModel):
    &#39;&#39;&#39;
    This is the base class of any machine learning model.  
    It provides the basic interface that is required in order to use the
    ML model with the controller  
    ATTRIBUTES:  
        list&lt;int&gt; tids: a list of thread ids that this model has (or potentially some form of a
          thread executor object  
        bool quit: True indicates MLModel is ready to quit, False indicates MLModel would like
          to keep going  
        int curr_iter: formally, this is the number of times the train method has been called
        int max_iters: the number of iters to execute before quiting  
    &#39;&#39;&#39;
    def __init__(self, y_shape, max_iters=np.inf, batch_size=5):
        super().__init__(None, max_iters) #don&#39;t have a model
        self.y_shape = y_shape
        self.batch_size = batch_size

    def _train(self, X, y):
        &#39;&#39;&#39;
        This call should wait on any current training threads to complete  
        This call should launch a training thread to retrain the model on the new data
        training is also where current iteration is updated  
        params:  
            np.array X: shape (num_pts, num_features) the recieved data for each new well  
            np.array y: shape(num_pts, n_classes) the labels to predict  
        Postconditions:  
            The model has been trained on the new data
        &#39;&#39;&#39;
        with self.model_lock: #note for dummy this is not necessary, just an example
            print(&#39;&lt;&lt;ML&gt;&gt; training!&#39;)

    def predict(self):
        &#39;&#39;&#39;
        This call should wait on the training thread to complete if it is has not been collected
        yet.  
        params:  
            int n_predictions: the number of instances to predict  
        returns:  
            np.array: shape is n_predictions, y.shape. Features are pi e-2  
        &#39;&#39;&#39;
        with self.model_lock:
            print(&#39;&lt;&lt;ML&gt;&gt; generating preditions&#39;)
        return np.ones((self.batch_size, self.y_shape)) * 3.1415e-2

    def generate_seed_rxns(self):
        &#39;&#39;&#39;
        This method is called before the model is trained to generate a batch of training
        points  
        returns:  
            np.array: (batch_size,n_features) 
        &#39;&#39;&#39;
        if self.generate_seed_rxns.n_calls == 0:
            return np.ones((self.batch_size,self.y_shape)) * 3.1415e-2
        else:
            return np.ones((self.batch_size,self.y_shape)) * 2 * 3.1415e-2
    generate_seed_rxns.n_calls = 0</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="ml_models.MLModel" href="#ml_models.MLModel">MLModel</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="ml_models.DummyMLModel.generate_seed_rxns"><code class="name flex">
<span>def <span class="ident">generate_seed_rxns</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This method is called before the model is trained to generate a batch of training
points<br>
returns:<br>
np.array: (batch_size,n_features)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_seed_rxns(self):
    &#39;&#39;&#39;
    This method is called before the model is trained to generate a batch of training
    points  
    returns:  
        np.array: (batch_size,n_features) 
    &#39;&#39;&#39;
    if self.generate_seed_rxns.n_calls == 0:
        return np.ones((self.batch_size,self.y_shape)) * 3.1415e-2
    else:
        return np.ones((self.batch_size,self.y_shape)) * 2 * 3.1415e-2</code></pre>
</details>
</dd>
<dt id="ml_models.DummyMLModel.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This call should wait on the training thread to complete if it is has not been collected
yet.<br>
params:<br>
int n_predictions: the number of instances to predict<br>
returns:<br>
np.array: shape is n_predictions, y.shape. Features are pi e-2</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self):
    &#39;&#39;&#39;
    This call should wait on the training thread to complete if it is has not been collected
    yet.  
    params:  
        int n_predictions: the number of instances to predict  
    returns:  
        np.array: shape is n_predictions, y.shape. Features are pi e-2  
    &#39;&#39;&#39;
    with self.model_lock:
        print(&#39;&lt;&lt;ML&gt;&gt; generating preditions&#39;)
    return np.ones((self.batch_size, self.y_shape)) * 3.1415e-2</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="ml_models.MLModel" href="#ml_models.MLModel">MLModel</a></b></code>:
<ul class="hlist">
<li><code><a title="ml_models.MLModel.train" href="#ml_models.MLModel.train">train</a></code></li>
<li><code><a title="ml_models.MLModel.update_quit" href="#ml_models.MLModel.update_quit">update_quit</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="ml_models.LinReg"><code class="flex name class">
<span>class <span class="ident">LinReg</span></span>
<span>(</span><span>model, final_spectra, y_shape, max_iters, batch_size=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Model to use Linear Regression algorithm
model_lock also locks X
UNIMPLEMENTED:<br>
only runs for batch size of 1</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LinReg(MLModel):
    &#39;&#39;&#39;
    Model to use Linear Regression algorithm
    model_lock also locks X
    UNIMPLEMENTED:  
      only runs for batch size of 1  
    &#39;&#39;&#39;
    def __init__(self, model, final_spectra, y_shape, max_iters, batch_size=1):
        super().__init__(model, max_iters) #don&#39;t have a model
        self.FINAL_SPECTRA = final_spectra
        self.y_shape = y_shape
        self.batch_size = batch_size

    def generate_seed_rxns(self):
        &#39;&#39;&#39;
        This method is called before the model is trained to generate a batch of training
        points  
        returns:  
            np.array: (batch_size,n_features) 
        &#39;&#39;&#39;
        #TODO talk to Mark about a good set of seeds to start at
        if self.generate_seed_rxns.n_calls == 0:
            return np.ones((self.batch_size,self.y_shape)) * 3.1415e-2
        else:
            return np.ones((self.batch_size,self.y_shape)) * 2 * 3.1415e-2
    generate_seed_rxns.n_calls = 0

    def predict(self):
        &#39;&#39;&#39;
        This call should wait on the training thread to complete if it is has not been collected
        yet.  
        params:  
            int n_predictions: the number of instances to predict  
        returns:  
            np.array: shape is n_predictions, y.shape. Features are pi e-2  
        &#39;&#39;&#39;
        super().predict()
        with self.model_lock:
            y_pred = self.model.predict(self.FINAL_SPECTRA)
        return y_pred
 
    def _train(self, X, y):
        &#39;&#39;&#39;
        This call should wait on any current training threads to complete  
        This call should launch a training thread to retrain the model on the new data
        training is also where current iteration is updated  
        params:  
            np.array X: shape (num_pts, num_features) the recieved data for each new well  
            np.array y: shape(num_pts, n_classes) the labels to predict  
        Postconditions:  
            The model has been trained on the new data
        &#39;&#39;&#39;
        #update the data with the new scans
        time.sleep(40)
        print(&#39;&lt;&lt;ML&gt;&gt; training&#39;)
        with self.model_lock:
            if isinstance(self.X,np.ndarray):
                self.X = np.concatenate((self.X, X))
                self.y = np.concatenate((self.y, y))
            else:
                self.X = X
                self.y = y
            self.model.fit(self.X, self.y)
        print(&#39;&lt;&lt;ML&gt;&gt; done training&#39;)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="ml_models.MLModel" href="#ml_models.MLModel">MLModel</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="ml_models.LinReg.generate_seed_rxns"><code class="name flex">
<span>def <span class="ident">generate_seed_rxns</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This method is called before the model is trained to generate a batch of training
points<br>
returns:<br>
np.array: (batch_size,n_features)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_seed_rxns(self):
    &#39;&#39;&#39;
    This method is called before the model is trained to generate a batch of training
    points  
    returns:  
        np.array: (batch_size,n_features) 
    &#39;&#39;&#39;
    #TODO talk to Mark about a good set of seeds to start at
    if self.generate_seed_rxns.n_calls == 0:
        return np.ones((self.batch_size,self.y_shape)) * 3.1415e-2
    else:
        return np.ones((self.batch_size,self.y_shape)) * 2 * 3.1415e-2</code></pre>
</details>
</dd>
<dt id="ml_models.LinReg.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This call should wait on the training thread to complete if it is has not been collected
yet.<br>
params:<br>
int n_predictions: the number of instances to predict<br>
returns:<br>
np.array: shape is n_predictions, y.shape. Features are pi e-2</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self):
    &#39;&#39;&#39;
    This call should wait on the training thread to complete if it is has not been collected
    yet.  
    params:  
        int n_predictions: the number of instances to predict  
    returns:  
        np.array: shape is n_predictions, y.shape. Features are pi e-2  
    &#39;&#39;&#39;
    super().predict()
    with self.model_lock:
        y_pred = self.model.predict(self.FINAL_SPECTRA)
    return y_pred</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="ml_models.MLModel" href="#ml_models.MLModel">MLModel</a></b></code>:
<ul class="hlist">
<li><code><a title="ml_models.MLModel.train" href="#ml_models.MLModel.train">train</a></code></li>
<li><code><a title="ml_models.MLModel.update_quit" href="#ml_models.MLModel.update_quit">update_quit</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="ml_models.MLModel"><code class="flex name class">
<span>class <span class="ident">MLModel</span></span>
<span>(</span><span>model, max_iters=inf)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the base class of any machine learning model.<br>
It provides the basic interface that is required in order to use the
ML model with the controller
</p>
<h2 id="attributes">Attributes</h2>
<p>list<int> tids: a list of thread ids that this model has (or potentially some form of a
thread executor object
bool quit: True indicates MLModel is ready to quit, False indicates MLModel would like
to keep going</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class MLModel():
    &#39;&#39;&#39;
    This is the base class of any machine learning model.  
    It provides the basic interface that is required in order to use the
    ML model with the controller  
    ATTRIBUTES:
        list&lt;int&gt; tids: a list of thread ids that this model has (or potentially some form of a
          thread executor object
        bool quit: True indicates MLModel is ready to quit, False indicates MLModel would like
          to keep going  
    &#39;&#39;&#39;
    def __init__(self, model, max_iters=np.inf):
        self.curr_iter = 0
        self.max_iters = max_iters
        self.quit = False
        self.model = model
        self.model_lock = threading.Lock()
        self.X_lock = threading.Lock()
        self.X = None
        self.quit = self.update_quit()

    def train(self, X, y):
        &#39;&#39;&#39;
        This is function is used to train the ML model.  
        Internally, launches a private thread
        This call should wait on any current training threads to complete  
        This call should launch a training thread to retrain the model on the new data
        params:
            np.array X: shape (num_pts, num_features) the recieved data for each new well
            np.array y: shape(num_pts, n_classes) the labels to predict
        &#39;&#39;&#39;
        train_thread = threading.Thread(target=self._train, name=&#39;train thread&#39;, args=(X,y))
        train_thread.start()
        self.curr_iter += 1
        self.update_quit()

    @abstractmethod
    def _train(self, X, y):
        &#39;&#39;&#39;
        This method should take care of all training. It is expected that it will update
        the model in whatever way is fitting for your model. It will be called when the user
        calls train.  
        Use extreme caution when implementing this method, and note that self is NOT threadsafe.
        i.e. if you plan on using any of the attributes of this class, make sure you lock them
        appropriately, or only use them in this method (WITH A HUGE COMMENT SOMEWHERE)  
        The line of code in this method should almost always be, with self.model_lock: ...  
        Strictly speaking, the model_lock is overkill. Since we always join this method before
        calling predict which uses the model, but it&#39;s good practice if other methods ever use
        the model_lock.  
        As long as we freeze the ml_model while training, things are simple, and this allows
        the controller to run other commands while we&#39;re training, but I&#39;ve implemented the
        architecture to have the ml_model do other work while it&#39;s training.  
        params:  
            np.array X: shape (num_pts, num_features) the recieved data for each new well  
            np.array y: shape(num_pts, n_classes) the labels to predict  
        Postconditions:  
            The model has been trained on the new data
        &#39;&#39;&#39;
        pass

    def predict(self):
        &#39;&#39;&#39;
        This is the starter code for any predict method. It must be overriden, but every override
        should first call super().predict(n_predictions)  
        This call should wait on the training thread to complete if it is has not been collected
        yet.  
        &#39;&#39;&#39;
        train_thread = [thread for thread in threading.enumerate() \
                            if thread.name == &#39;train thread&#39;]
        if train_thread:
            train_thread = train_thread[0]
            train_thread.join() #wait till you&#39;re done training

    def update_quit(self):
        &#39;&#39;&#39;
        used to update the quit parameter of this model  
        This method will just check that you have not exceded max_iters, but should be
        extended by children to check if you&#39;ve reached the target.  
        &#39;&#39;&#39;
        self.quit =  self.curr_iter &gt;= self.max_iters

    @abstractmethod
    def generate_seed_rxns(self):
        &#39;&#39;&#39;
        This method is called before the model is trained to generate a batch of training
        points  
        returns:  
            np.array: (batch_size,y.shape) 
        &#39;&#39;&#39;
        pass</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="ml_models.DummyMLModel" href="#ml_models.DummyMLModel">DummyMLModel</a></li>
<li><a title="ml_models.LinReg" href="#ml_models.LinReg">LinReg</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="ml_models.MLModel.generate_seed_rxns"><code class="name flex">
<span>def <span class="ident">generate_seed_rxns</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This method is called before the model is trained to generate a batch of training
points<br>
returns:<br>
np.array: (batch_size,y.shape)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def generate_seed_rxns(self):
    &#39;&#39;&#39;
    This method is called before the model is trained to generate a batch of training
    points  
    returns:  
        np.array: (batch_size,y.shape) 
    &#39;&#39;&#39;
    pass</code></pre>
</details>
</dd>
<dt id="ml_models.MLModel.predict"><code class="name flex">
<span>def <span class="ident">predict</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>This is the starter code for any predict method. It must be overriden, but every override
should first call super().predict(n_predictions)<br>
This call should wait on the training thread to complete if it is has not been collected
yet.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predict(self):
    &#39;&#39;&#39;
    This is the starter code for any predict method. It must be overriden, but every override
    should first call super().predict(n_predictions)  
    This call should wait on the training thread to complete if it is has not been collected
    yet.  
    &#39;&#39;&#39;
    train_thread = [thread for thread in threading.enumerate() \
                        if thread.name == &#39;train thread&#39;]
    if train_thread:
        train_thread = train_thread[0]
        train_thread.join() #wait till you&#39;re done training</code></pre>
</details>
</dd>
<dt id="ml_models.MLModel.train"><code class="name flex">
<span>def <span class="ident">train</span></span>(<span>self, X, y)</span>
</code></dt>
<dd>
<div class="desc"><p>This is function is used to train the ML model.<br>
Internally, launches a private thread
This call should wait on any current training threads to complete<br>
This call should launch a training thread to retrain the model on the new data
params:
np.array X: shape (num_pts, num_features) the recieved data for each new well
np.array y: shape(num_pts, n_classes) the labels to predict</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def train(self, X, y):
    &#39;&#39;&#39;
    This is function is used to train the ML model.  
    Internally, launches a private thread
    This call should wait on any current training threads to complete  
    This call should launch a training thread to retrain the model on the new data
    params:
        np.array X: shape (num_pts, num_features) the recieved data for each new well
        np.array y: shape(num_pts, n_classes) the labels to predict
    &#39;&#39;&#39;
    train_thread = threading.Thread(target=self._train, name=&#39;train thread&#39;, args=(X,y))
    train_thread.start()
    self.curr_iter += 1
    self.update_quit()</code></pre>
</details>
</dd>
<dt id="ml_models.MLModel.update_quit"><code class="name flex">
<span>def <span class="ident">update_quit</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>used to update the quit parameter of this model<br>
This method will just check that you have not exceded max_iters, but should be
extended by children to check if you've reached the target.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update_quit(self):
    &#39;&#39;&#39;
    used to update the quit parameter of this model  
    This method will just check that you have not exceded max_iters, but should be
    extended by children to check if you&#39;ve reached the target.  
    &#39;&#39;&#39;
    self.quit =  self.curr_iter &gt;= self.max_iters</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="ml_models.DummyMLModel" href="#ml_models.DummyMLModel">DummyMLModel</a></code></h4>
<ul class="">
<li><code><a title="ml_models.DummyMLModel.generate_seed_rxns" href="#ml_models.DummyMLModel.generate_seed_rxns">generate_seed_rxns</a></code></li>
<li><code><a title="ml_models.DummyMLModel.predict" href="#ml_models.DummyMLModel.predict">predict</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="ml_models.LinReg" href="#ml_models.LinReg">LinReg</a></code></h4>
<ul class="">
<li><code><a title="ml_models.LinReg.generate_seed_rxns" href="#ml_models.LinReg.generate_seed_rxns">generate_seed_rxns</a></code></li>
<li><code><a title="ml_models.LinReg.predict" href="#ml_models.LinReg.predict">predict</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="ml_models.MLModel" href="#ml_models.MLModel">MLModel</a></code></h4>
<ul class="">
<li><code><a title="ml_models.MLModel.generate_seed_rxns" href="#ml_models.MLModel.generate_seed_rxns">generate_seed_rxns</a></code></li>
<li><code><a title="ml_models.MLModel.predict" href="#ml_models.MLModel.predict">predict</a></code></li>
<li><code><a title="ml_models.MLModel.train" href="#ml_models.MLModel.train">train</a></code></li>
<li><code><a title="ml_models.MLModel.update_quit" href="#ml_models.MLModel.update_quit">update_quit</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>