<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>controller API documentation</title>
<meta name="description" content="This module contains everything that the server needs to run. Partly seperate from the OT2 because
it needs different packages (OT2 uses historic â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>controller</code></h1>
</header>
<section id="section-intro">
<p>This module contains everything that the server needs to run. Partly seperate from the OT2 because
it needs different packages (OT2 uses historic packages) and partly for organizational purposes.
The core of this module is the ProtocolExecutor class. The ProtocolExecutor is responsible for
interfacing with the robot, the platereader, and googlesheets. It's purpose is to load a reaction
protocol from googlesheets and then execute that protocol line by line by communicating with the
robot and platereader. Attempts to do as much computation as possible before sending commands
to those applications
The ProtocolExecutor uses a PlateReader.
PlateReader is a custom class that is built for controlling the platereader.
In order to control the platereader, the software should be closed when PlateReader
is instantiated, and (obviously) the software should exist on the machine you're running
This module also contains two launchers.
launch_protocol_exec runs a protocol from the sheets using a protocol executor
launch_auto runs in automatic machine learning mode
A main method is supplied that will run if you run this script. It will call one of the launchers
based on command line args. (run this script with -h)</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#39;&#39;&#39;
This module contains everything that the server needs to run. Partly seperate from the OT2 because
it needs different packages (OT2 uses historic packages) and partly for organizational purposes.
The core of this module is the ProtocolExecutor class. The ProtocolExecutor is responsible for 
interfacing with the robot, the platereader, and googlesheets. It&#39;s purpose is to load a reaction
protocol from googlesheets and then execute that protocol line by line by communicating with the
robot and platereader. Attempts to do as much computation as possible before sending commands 
to those applications
The ProtocolExecutor uses a PlateReader.
PlateReader is a custom class that is built for controlling the platereader. 
In order to control the platereader, the software should be closed when PlateReader 
is instantiated, and (obviously) the software should exist on the machine you&#39;re running
This module also contains two launchers.
launch_protocol_exec runs a protocol from the sheets using a protocol executor
launch_auto runs in automatic machine learning mode
A main method is supplied that will run if you run this script. It will call one of the launchers
based on command line args. (run this script with -h)
&#39;&#39;&#39;
from abc import ABC
from abc import abstractmethod
from collections import defaultdict
from collections import namedtuple
import socket
import json
import dill
import math
import os
import shutil
import webbrowser
from tempfile import NamedTemporaryFile
import logging
import asyncio
import threading
import time
import argparse
import re
import functools
from datetime import datetime

from bidict import bidict
import gspread
from df2gspread import df2gspread as d2g
from df2gspread import gspread2df as g2d
from oauth2client.service_account import ServiceAccountCredentials
import pandas as pd
import numpy as np
import opentrons.execute
from opentrons import protocol_api, simulate, types
from boltons.socketutils import BufferedSocket
import matplotlib.patches as mpatches
import matplotlib.pyplot as plt
import matplotlib.cm as cm

from Armchair.armchair import Armchair
from ot2_robot import launch_eve_server
from df_utils import make_unique, df_popout, wslpath, error_exit
from ml_models import DummyMLModel


def init_parser():
    parser = argparse.ArgumentParser()
    mode_help_str = &#39;mode=auto runs in ml, mode=protocol or not supplied runs protocol&#39;
    parser.add_argument(&#39;-m&#39;,&#39;--mode&#39;,help=mode_help_str,default=&#39;protocol&#39;)
    parser.add_argument(&#39;-n&#39;,&#39;--name&#39;,help=&#39;the name of the google sheet&#39;)
    parser.add_argument(&#39;-c&#39;,&#39;--cache&#39;,help=&#39;flag. if supplied, uses cache&#39;,action=&#39;store_true&#39;)
    parser.add_argument(&#39;-s&#39;,&#39;--simulate&#39;,help=&#39;runs robot and pr in simulation mode&#39;,action=&#39;store_true&#39;)
    return parser

def main(serveraddr):
    &#39;&#39;&#39;
    prompts for input and then calls appropriate launcher
    &#39;&#39;&#39;
    parser = init_parser()
    args = parser.parse_args()
    if args.mode == &#39;protocol&#39;:
        print(&#39;launching in protocol mode&#39;)
        launch_protocol_exec(serveraddr,args.name,args.cache,args.simulate)
    elif args.mode == &#39;auto&#39;:
        print(&#39;launching in auto mode&#39;)
        launch_auto(serveraddr,args.name,args.cache,args.simulate)
    else:
        print(&#34;invalid argument to mode, &#39;{}&#39;&#34;.format(args.mode))
        parser.print_help()

def launch_protocol_exec(serveraddr, rxn_sheet_name=None, use_cache=False, simulate=False):
    &#39;&#39;&#39;
    main function to launch a controller and execute a protocol
    &#39;&#39;&#39;
    #instantiate a controller
    if not rxn_sheet_name:
        rxn_sheet_name = input(&#39;&lt;&lt;controller&gt;&gt; please input the sheet name &#39;)
    if not use_cache:
        #using the cache bypasses google docs communication and uses the last rxn you loaded
        use_cache = &#39;y&#39; == input(&#39;&lt;&lt;controller&gt;&gt; would you like to use spreadsheet cache? [yn] &#39;)
    my_ip = socket.gethostbyname(socket.gethostname())
    controller = ProtocolExecutor(rxn_sheet_name, my_ip, serveraddr, use_cache=use_cache)

    tests_passed = controller.run_simulation()

    if tests_passed:
        if input(&#39;would you like to run the protocol? [yn] &#39;).lower() == &#39;y&#39;:
            controller.run_protocol(simulate)
    else:
        print(&#39;Failed Some Tests. Please fix your errors and try again&#39;)

def launch_auto(serveraddr, rxn_sheet_name, use_cache, simulate):
    &#39;&#39;&#39;
    main function to launch an auto scientist that designs it&#39;s own experiments
    &#39;&#39;&#39;
    if not rxn_sheet_name:
        rxn_sheet_name = input(&#39;&lt;&lt;controller&gt;&gt; please input the sheet name &#39;)
    if not use_cache:
        #using the cache bypasses google docs communication and uses the last rxn you loaded
        use_cache = &#39;y&#39; == input(&#39;&lt;&lt;controller&gt;&gt; would you like to use spreadsheet cache? [yn] &#39;)
    my_ip = socket.gethostbyname(socket.gethostname())
    auto = AutoContr(rxn_sheet_name, my_ip, serveraddr, use_cache=use_cache)
    auto.run_simulation()
    if input(&#39;would you like to run on robot and pr? [yn] &#39;).lower() == &#39;y&#39;:
        #need a new model because last is fit to sim
        model = None
        auto.run_protocol(model, simulate)


class Controller(ABC):
    &#39;&#39;&#39;
    This class is a shared interface for the ProtocolExecutor and the ______AI__Executor___  

    ATTRIBUTES:  
        armchair.Armchair portal: the Armchair object to ship files across  
        rxn_sheet_name: the name of the reaction sheet  
        str cache_path: path to a directory for all cache files  
        bool use_cache: read from cache if possible  
        str eve_files_path: the path to put files from eve  
        str debug_path: the path to place debugging information  
        str my_ip: the ip of this controller  
        str server_ip: the ip of the server. This is modified for simulation, but returned to 
          original state at the end of simulation  
        dict&lt;str:object&gt; robo_params: convenient place for the parameters for the robot  
            + bool using_temp_ctrl: True if the temperature control is being used  
            + float temp: the temperature in celcius to keep the temp control at  
            + df reagent_df: holds information about reagents  
                + float conc: the concentration  
                + str loc: location on labware  
                + int deck_pos: the position on the deck  
                + float mass: the mass of the tube with reagent and cap  
            dict&lt;str:str&gt; instruments: maps &#39;left&#39; and &#39;right&#39; to the pipette names  
            df labware_df  
                + int deck_pos: the position of the labware on the deck  
                + str name: the name of the labware  
                + str first_usable: a location of the first usable tip/well on labware  
                + list&lt;str&gt; empty_list: a list of locations on the labware that have empty tubes  
            df product_df: This information is used to figure out where to put chemicals  
                + INDEX  
                + str chemical_name: the name of the chemical  
                + COLS  
                + str labware: the requested labware you want to put it in  
                + str container: the container you want to put it in  
                + float max_vol: the maximum volume you will put in the container  
        bool simulate: whether a simulation is being run or not. False by default. changed true 
          temporarily when simulating  
        int buff_size: this is the size of the buffer between Armchair commands. It&#39;s size
          corresponds to the number of commands you want to pile up in the socket buffer.
          Really more for developers  
    PRIVATE ATTRS:  
        dict&lt;str:ChemCacheEntry&gt; _cached_reader_locs: chemical information from the robot
            ChemCacheEntry is a named tuple with below attributes
            The tuple has following structure:  
            str loc: the loc of the well on it&#39;s labware (translated to human if on pr)  
            int deck_pos: the position of the labware it&#39;s on  
            float vol: the volume in the container  
            float aspiratible_vol: the volume minus dead vol  
    CONSTANTS:  
        bidict&lt;str:tuple&lt;str,str&gt;&gt; PLATEREADER_INDEX_TRANSLATOR: used to translate from locs on
        wellplate to locs on the opentrons object. Use a json viewer for more structural info  
    METHODS:  
        run_protocol(simulate, port) void: both args have good defaults. simulate can be used to
          simulate on the plate reader and robot, but generally you want false to actually run
          the protocol. port can be configured, but 50000 is default  
        run_simulation() int: runs a simulation on local machine. Tries plate reader, but
          not necessary. returns an error code  
        close_connection() void: automatically called by run_protocol. used to terminate a 
          connection with eve  
        init_robot(simulate): used to initialize the robot. called automatically in run. simulate
          is the same as used by the robot protocol  
        translate_wellmap() void: used to convert a wellmap.tsv from robot to wells locs 
          that correspond to platereader  
    &#39;&#39;&#39;
    #this has two keys, &#39;deck_pos&#39; and &#39;loc&#39;. They map to the plate reader and the loc on that plate
    #reader given a regular loc for a 96well plate.
    #Please do not read this. paste it into a nice json viewer.
    PLATEREADER_INDEX_TRANSLATOR = bidict({&#39;A1&#39;: (&#39;E1&#39;, &#39;platereader4&#39;), &#39;A2&#39;: (&#39;D1&#39;, &#39;platereader4&#39;), &#39;A3&#39;: (&#39;C1&#39;, &#39;platereader4&#39;), &#39;A4&#39;: (&#39;B1&#39;, &#39;platereader4&#39;), &#39;A5&#39;: (&#39;A1&#39;, &#39;platereader4&#39;), &#39;A12&#39;: (&#39;A1&#39;, &#39;platereader7&#39;), &#39;A11&#39;: (&#39;B1&#39;, &#39;platereader7&#39;), &#39;A10&#39;: (&#39;C1&#39;, &#39;platereader7&#39;), &#39;A9&#39;: (&#39;D1&#39;, &#39;platereader7&#39;), &#39;A8&#39;: (&#39;E1&#39;, &#39;platereader7&#39;), &#39;A7&#39;: (&#39;F1&#39;, &#39;platereader7&#39;), &#39;A6&#39;: (&#39;G1&#39;, &#39;platereader7&#39;), &#39;B1&#39;: (&#39;E2&#39;, &#39;platereader4&#39;), &#39;B2&#39;: (&#39;D2&#39;, &#39;platereader4&#39;), &#39;B3&#39;: (&#39;C2&#39;, &#39;platereader4&#39;), &#39;B4&#39;: (&#39;B2&#39;, &#39;platereader4&#39;), &#39;B5&#39;: (&#39;A2&#39;, &#39;platereader4&#39;), &#39;B6&#39;: (&#39;G2&#39;, &#39;platereader7&#39;), &#39;B7&#39;: (&#39;F2&#39;, &#39;platereader7&#39;), &#39;B8&#39;: (&#39;E2&#39;, &#39;platereader7&#39;), &#39;B9&#39;: (&#39;D2&#39;, &#39;platereader7&#39;), &#39;B10&#39;: (&#39;C2&#39;, &#39;platereader7&#39;), &#39;B11&#39;: (&#39;B2&#39;, &#39;platereader7&#39;), &#39;B12&#39;: (&#39;A2&#39;, &#39;platereader7&#39;), &#39;C1&#39;: (&#39;E3&#39;, &#39;platereader4&#39;), &#39;C2&#39;: (&#39;D3&#39;, &#39;platereader4&#39;), &#39;C3&#39;: (&#39;C3&#39;, &#39;platereader4&#39;), &#39;C4&#39;: (&#39;B3&#39;, &#39;platereader4&#39;), &#39;C5&#39;: (&#39;A3&#39;, &#39;platereader4&#39;), &#39;C6&#39;: (&#39;G3&#39;, &#39;platereader7&#39;), &#39;C7&#39;: (&#39;F3&#39;, &#39;platereader7&#39;), &#39;C8&#39;: (&#39;E3&#39;, &#39;platereader7&#39;), &#39;C9&#39;: (&#39;D3&#39;, &#39;platereader7&#39;), &#39;C10&#39;: (&#39;C3&#39;, &#39;platereader7&#39;), &#39;C11&#39;: (&#39;B3&#39;, &#39;platereader7&#39;), &#39;C12&#39;: (&#39;A3&#39;, &#39;platereader7&#39;), &#39;D1&#39;: (&#39;E4&#39;, &#39;platereader4&#39;), &#39;D2&#39;: (&#39;D4&#39;, &#39;platereader4&#39;), &#39;D3&#39;: (&#39;C4&#39;, &#39;platereader4&#39;), &#39;D4&#39;: (&#39;B4&#39;, &#39;platereader4&#39;), &#39;D5&#39;: (&#39;A4&#39;, &#39;platereader4&#39;), &#39;D6&#39;: (&#39;G4&#39;, &#39;platereader7&#39;), &#39;D7&#39;: (&#39;F4&#39;, &#39;platereader7&#39;), &#39;D8&#39;: (&#39;E4&#39;, &#39;platereader7&#39;), &#39;D9&#39;: (&#39;D4&#39;, &#39;platereader7&#39;), &#39;D10&#39;: (&#39;C4&#39;, &#39;platereader7&#39;), &#39;D11&#39;: (&#39;B4&#39;, &#39;platereader7&#39;), &#39;D12&#39;: (&#39;A4&#39;, &#39;platereader7&#39;), &#39;E1&#39;: (&#39;E5&#39;, &#39;platereader4&#39;), &#39;E2&#39;: (&#39;D5&#39;, &#39;platereader4&#39;), &#39;E3&#39;: (&#39;C5&#39;, &#39;platereader4&#39;), &#39;E4&#39;: (&#39;B5&#39;, &#39;platereader4&#39;), &#39;E5&#39;: (&#39;A5&#39;, &#39;platereader4&#39;), &#39;E6&#39;: (&#39;G5&#39;, &#39;platereader7&#39;), &#39;E7&#39;: (&#39;F5&#39;, &#39;platereader7&#39;), &#39;E8&#39;: (&#39;E5&#39;, &#39;platereader7&#39;), &#39;E9&#39;: (&#39;D5&#39;, &#39;platereader7&#39;), &#39;E10&#39;: (&#39;C5&#39;, &#39;platereader7&#39;), &#39;E11&#39;: (&#39;B5&#39;, &#39;platereader7&#39;), &#39;E12&#39;: (&#39;A5&#39;, &#39;platereader7&#39;), &#39;F1&#39;: (&#39;E6&#39;, &#39;platereader4&#39;), &#39;F2&#39;: (&#39;D6&#39;, &#39;platereader4&#39;), &#39;F3&#39;: (&#39;C6&#39;, &#39;platereader4&#39;), &#39;F4&#39;: (&#39;B6&#39;, &#39;platereader4&#39;), &#39;F5&#39;: (&#39;A6&#39;, &#39;platereader4&#39;), &#39;F6&#39;: (&#39;G6&#39;, &#39;platereader7&#39;), &#39;F7&#39;: (&#39;F6&#39;, &#39;platereader7&#39;), &#39;F8&#39;: (&#39;E6&#39;, &#39;platereader7&#39;), &#39;F9&#39;: (&#39;D6&#39;, &#39;platereader7&#39;), &#39;F10&#39;: (&#39;C6&#39;, &#39;platereader7&#39;), &#39;F11&#39;: (&#39;B6&#39;, &#39;platereader7&#39;), &#39;F12&#39;: (&#39;A6&#39;, &#39;platereader7&#39;), &#39;G1&#39;: (&#39;E7&#39;, &#39;platereader4&#39;), &#39;G2&#39;: (&#39;D7&#39;, &#39;platereader4&#39;), &#39;G3&#39;: (&#39;C7&#39;, &#39;platereader4&#39;), &#39;G4&#39;: (&#39;B7&#39;, &#39;platereader4&#39;), &#39;G5&#39;: (&#39;A7&#39;, &#39;platereader4&#39;), &#39;G6&#39;: (&#39;G7&#39;, &#39;platereader7&#39;), &#39;G7&#39;: (&#39;F7&#39;, &#39;platereader7&#39;), &#39;G8&#39;: (&#39;E7&#39;, &#39;platereader7&#39;), &#39;G9&#39;: (&#39;D7&#39;, &#39;platereader7&#39;), &#39;G10&#39;: (&#39;C7&#39;, &#39;platereader7&#39;), &#39;G11&#39;: (&#39;B7&#39;, &#39;platereader7&#39;), &#39;G12&#39;: (&#39;A7&#39;, &#39;platereader7&#39;), &#39;H1&#39;: (&#39;E8&#39;, &#39;platereader4&#39;), &#39;H2&#39;: (&#39;D8&#39;, &#39;platereader4&#39;), &#39;H3&#39;: (&#39;C8&#39;, &#39;platereader4&#39;), &#39;H4&#39;: (&#39;B8&#39;, &#39;platereader4&#39;), &#39;H5&#39;: (&#39;A8&#39;, &#39;platereader4&#39;), &#39;H6&#39;: (&#39;G8&#39;, &#39;platereader7&#39;), &#39;H7&#39;: (&#39;F8&#39;, &#39;platereader7&#39;), &#39;H8&#39;: (&#39;E8&#39;, &#39;platereader7&#39;), &#39;H9&#39;: (&#39;D8&#39;, &#39;platereader7&#39;), &#39;H10&#39;: (&#39;C8&#39;, &#39;platereader7&#39;), &#39;H11&#39;: (&#39;B8&#39;, &#39;platereader7&#39;), &#39;H12&#39;: (&#39;A8&#39;, &#39;platereader7&#39;)})

    ChemCacheEntry = namedtuple(&#39;ChemCacheEntry&#39;,[&#39;loc&#39;,&#39;deck_pos&#39;,&#39;vol&#39;,&#39;aspirable_vol&#39;])

    def __init__(self, rxn_sheet_name, my_ip, server_ip, buff_size=4, use_cache=False, cache_path=&#39;Cache&#39;):
        &#39;&#39;&#39;
        Note that init does not initialize the portal. This must be done explicitly or by calling
        a run function that creates a portal. The portal is not passed to init because although
        the code must not use more than one portal at a time, the portal may change over the 
        lifetime of the class
        NOte that pr cannot be initialized until you know if you&#39;re simulating or not, so it
        is instantiated in run
        &#39;&#39;&#39;
        #set according to input
        self.cache_path=cache_path
        self._make_cache()
        self.use_cache = use_cache
        self.my_ip = my_ip
        self.server_ip = server_ip
        self.buff_size=4
        self.simulate = False #by default will be changed if a simulation is run
        self._cached_reader_locs = {} #maps wellname to loc on platereader
        #this will be gradually filled
        self.robo_params = {}
        #necessary helper params
        self._check_cache_metadata(rxn_sheet_name)
        credentials = self._init_credentials(rxn_sheet_name)
        wks_key = self._get_wks_key(credentials, rxn_sheet_name)
        rxn_spreadsheet = self._open_sheet(rxn_sheet_name, credentials)
        header_data = self._download_sheet(rxn_spreadsheet,0)
        input_data = self._download_sheet(rxn_spreadsheet,1)
        deck_data = self._download_sheet(rxn_spreadsheet, 2)
        self._init_robo_header_params(header_data)
        self._make_out_dirs(header_data)
        self.rxn_df = self._load_rxn_df(input_data)
        self._query_reagents(wks_key, credentials)
        raw_reagent_df = self._download_reagent_data(wks_key, credentials)#will be replaced soon
        #with a parsed reagent_df. This is exactly as is pulled from gsheets
        empty_containers = self._get_empty_containers(raw_reagent_df)
        self.robo_params[&#39;dry_containers&#39;] = self._get_dry_containers(raw_reagent_df)
        products_to_labware = self._get_products_to_labware(input_data)
        self.robo_params[&#39;reagent_df&#39;] = self._parse_raw_reagent_df(raw_reagent_df)
        self.robo_params[&#39;instruments&#39;] = self._get_instrument_dict(deck_data)
        self.robo_params[&#39;labware_df&#39;] = self._get_labware_df(deck_data, empty_containers)
        self.robo_params[&#39;product_df&#39;] = self._get_product_df(products_to_labware)
        self.run_all_checks()

    def _check_cache_metadata(self, rxn_sheet_name):
        &#39;&#39;&#39;
        Checks a file, .metadata.txt with the cache path.
        Postconditions:
            If use_cache is true:
                reads .metadata.txt
                asserts that the rxn_sheet_name matches the name in sheet
                prints the timestamp that the cache was last written
            If use_cache is false:
                writes .metadata.txt with the sheet name and a timestamp
        &#39;&#39;&#39;
        if self.use_cache:
            assert (os.path.exists(os.path.join(self.cache_path, &#39;.metadata.json&#39;))), \
                    &#34;tried to read metadata in cache, but file does not exist&#34;
            with open(os.path.join(self.cache_path, &#39;.metadata.json&#39;), &#39;r&#39;) as file:
                metadata = json.load(file)
            assert (metadata[&#39;name&#39;] == rxn_sheet_name), &#34;desired sheet was, &#39;{}&#39;, but cached data is for &#39;{}&#39;&#34;.format(rxn_sheet_name, metadata[&#39;name&#39;])
            print(&#34;&lt;&lt;controller&gt;&gt; using cached data for &#39;{}&#39;, last updated &#39;{}&#39;&#34;.format(
                    metadata[&#39;name&#39;],metadata[&#39;timestamp&#39;]))
        else:
            metadata = {&#39;timestamp&#39;:datetime.now().strftime(&#39;%d-%b-%Y %H:%M:%S:%f&#39;),
                        &#39;name&#39;:rxn_sheet_name}
            with open(os.path.join(self.cache_path, &#39;.metadata.json&#39;), &#39;w&#39;) as file:
                json.dump(metadata, file)

    def _get_wks_key_pairs(self, credentials, rxn_sheet_name):
        &#39;&#39;&#39;
        open and search a sheet that tells you which sheet is associated with the reaction
        Or read from cache if cache is enabled  
        params:  
            ServiceAccountCredentials credentials: to access the sheets  
            str rxn_sheet_name: the name of sheet  
        returns:  
            list&lt;list&lt;str&gt;&gt; name_key_pairs: the data in the wks_key spreadsheet  
        Postconditions:  
            If cached data could not be found, will dump spreadsheet data to name_key_pairs.pkl 
            in cache path  
        &#39;&#39;&#39;
        if self.use_cache:
            #load cache
            with open(os.path.join(self.cache_path, &#39;name_key_pairs.pkl&#39;), &#39;rb&#39;) as name_key_pairs_cache:
                name_key_pairs = dill.load(name_key_pairs_cache)
        else:
            #pull down data
            gc = gspread.authorize(credentials)
            name_key_wks = gc.open_by_url(&#39;https://docs.google.com/spreadsheets/d/1m2Uzk8z-qn2jJ2U1NHkeN7CJ8TQpK3R0Ai19zlAB1Ew/edit#gid=0&#39;).get_worksheet(0)
            name_key_pairs = name_key_wks.get_all_values() #list&lt;list&lt;str name, str key&gt;&gt;
            #Note the key is a unique identifier that can be used to access the sheet
            #d2g uses it to access the worksheet
            #dump to cache
            with open(os.path.join(self.cache_path, &#39;name_key_pairs.pkl&#39;), &#39;wb&#39;) as name_key_pairs_cache:
                dill.dump(name_key_pairs, name_key_pairs_cache)
        return name_key_pairs

    def _init_pr(self,simulate):
        try:
            self.pr = PlateReader(os.path.join(self.out_path, &#39;pr_data&#39;),simulate)
        except:
            print(&#39;&lt;&lt;controller&gt;&gt; failed to initialize platereader, initializing dummy reader&#39;)
            self.pr = DummyReader(os.path.join(self.out_path, &#39;pr_data&#39;))

    def _download_sheet(self, rxn_spreadsheet, index):
        &#39;&#39;&#39;
        pulls down the sheet at the index  
        params:  
            gspread.Spreadsheet rxn_spreadsheet: the sheet with all the reactions  
            int index: the index of the sheet to pull down  
        returns:  
            list&lt;list&lt;str&gt;&gt; data: the input template sheet pulled down into a list  
        &#39;&#39;&#39;
        if self.use_cache:
            with open(os.path.join(self.cache_path,&#39;wks_data{}.pkl&#39;.format(index)), &#39;rb&#39;) as rxn_wks_data_cache:
                data = dill.load(rxn_wks_data_cache)
        else:
            rxn_wks = rxn_spreadsheet.get_worksheet(index)
            data = rxn_wks.get_all_values()
            with open(os.path.join(self.cache_path,&#39;wks_data{}.pkl&#39;.format(index)),&#39;wb&#39;) as rxn_wks_data_cache:
                dill.dump(data, rxn_wks_data_cache)
        return data


    def _make_out_dirs(self, header_data):
        &#39;&#39;&#39;
        params:  
            list&lt;list&lt;str&gt;&gt; header_data: data from the header  
        Postconditions:  
            All paths used by this class have been initialized if they were not before
            They are not overwritten if they already exist. paths variables of this class
            have also been initialized
        &#39;&#39;&#39;

        out_path = &#39;Ideally this would be a gdrive path, but for now everything is local&#39;
        if not os.path.exists(out_path):
            #not on the laptop
            out_path = &#39;./Controller_Out&#39;
        #get the root folder
        header_dict = {row[0]:row[1] for row in header_data[1:]}
        data_dir = header_dict[&#39;data_dir&#39;]
        self.out_path = os.path.join(out_path, data_dir)
        #if the folder doesn&#39;t exist yet, make it
        self.eve_files_path = os.path.join(self.out_path, &#39;Eve_Files&#39;)
        self.debug_path = os.path.join(self.out_path, &#39;Debug&#39;)
        self.plot_path = os.path.join(self.out_path, &#39;Plots&#39;)
        paths = [self.out_path, self.eve_files_path, self.debug_path, self.plot_path]
        for path in paths:
            if not os.path.exists(path):
                os.makedirs(path)

    def _make_cache(self):
        if not os.path.exists(self.cache_path):
            os.makedirs(self.cache_path)

    def _init_credentials(self, rxn_sheet_name):
        &#39;&#39;&#39;
        this function reads a local json file to get the credentials needed to access other funcs  
        params:  
            str rxn_sheet_name: the name of the reaction sheet to run  
        returns:  
            ServiceAccountCredentials: the credentials to access that sheet  
        &#39;&#39;&#39;
        scope = [&#39;https://spreadsheets.google.com/feeds&#39;,
                 &#39;https://www.googleapis.com/auth/drive&#39;]
        #get login credentials from local file. Your json file here
        path = &#39;Credentials/hendricks-lab-jupyter-sheets-5363dda1a7e0.json&#39;
        credentials = ServiceAccountCredentials.from_json_keyfile_name(path, scope) 
        return credentials

    def _get_wks_key(self, credentials, rxn_sheet_name):
        &#39;&#39;&#39;
        open and search a sheet that tells you which sheet is associated with the reaction  
        params:  
            ServiceAccountCredentials credentials: to access the sheets  
            str rxn_sheet_name: the name of sheet  
        returns:  
            if self.use_cache:  
                str wks_key: the key associated with the sheet. It functions similar to a url  
            else:  
                None: this is ok because the wks key will not be used if caching  
        &#39;&#39;&#39;
        name_key_pairs = self._get_wks_key_pairs(credentials, rxn_sheet_name)
        try:
            i=0
            wks_key = None
            while not wks_key and i &lt;= len(name_key_pairs):
                row = name_key_pairs[i]
                if row[0] == rxn_sheet_name:
                    wks_key = row[1]
                i+=1
        except IndexError:
            raise Exception(&#39;Spreadsheet Name/Key pair was not found. Check the dict spreadsheet \
            and make sure the spreadsheet name is spelled exactly the same as the reaction \
            spreadsheet.&#39;)
        return wks_key

    def _open_sheet(self, rxn_sheet_name, credentials):
        &#39;&#39;&#39;
        open the google sheet  
        params:  
            str rxn_sheet_name: the title of the sheet to be opened  
            oauth2client.ServiceAccountCredentials credentials: credentials read from a local json  
        returns:  
            if self.use_cache:  
                gspread.Spreadsheet the spreadsheet (probably of all the reactions)  
            else:  
                None: this is fine because the wks should never be used if cache is true  
        &#39;&#39;&#39;
        gc = gspread.authorize(credentials)
        try:
            if self.use_cache:
                wks = None
            else:
                wks = gc.open(rxn_sheet_name)
        except: 
            raise Exception(&#39;Spreadsheet Not Found: Make sure the spreadsheet name is spelled correctly and that it is shared with the robot &#39;)
        return wks

    def _init_robo_header_params(self, header_data):
        &#39;&#39;&#39;
        loads the header data into self.robo_params  
        params:  
            list&lt;list&lt;str&gt; header_data: as in gsheets  
        Postconditions:  
            simulate, using_temp_ctrl, and temp have been initialized according to values in 
            excel  
        &#39;&#39;&#39;
        header_dict = {row[0]:row[1] for row in header_data[1:]}
        self.robo_params[&#39;using_temp_ctrl&#39;] = header_dict[&#39;using_temp_ctrl&#39;] == &#39;yes&#39;
        self.robo_params[&#39;temp&#39;] = float(header_dict[&#39;temp&#39;]) if self.robo_params[&#39;using_temp_ctrl&#39;] else None

    def _plot_setup_overlay(self,title):
        &#39;&#39;&#39;
        Sets up a figure for an overlay plot  
        params:  
            str title: the title of the reaction  
        &#39;&#39;&#39;
        #formats the figure nicely
        plt.figure(num=None, figsize=(4, 4),dpi=300, facecolor=&#39;w&#39;, edgecolor=&#39;k&#39;)
        plt.legend(loc=&#34;upper right&#34;,frameon = False, prop={&#34;size&#34;:7},labelspacing = 0.5)
        plt.rc(&#39;axes&#39;, linewidth = 2)
        plt.xlabel(&#39;Wavelength (nm)&#39;,fontsize = 16)
        plt.ylabel(&#39;Absorbance (a.u.)&#39;, fontsize = 16)
        plt.tick_params(axis = &#34;both&#34;, width = 2)
        plt.tick_params(axis = &#34;both&#34;, width = 2)
        plt.xticks([300,400,500,600,700,800,900,1000])
        plt.yticks([i/10 for i in range(0,11,1)])
        plt.axis([300, 1000, 0.0 , 1.0])
        plt.xticks(fontsize = 10)
        plt.yticks(fontsize = 10)
        plt.title(str(title), fontsize = 16, pad = 20)
        
    def plot_LAM_overlay(self,df,wells,filename=None):
        &#39;&#39;&#39;
        plots overlayed spectra of wells in the order that they are specified  
        params:  
            df df: dataframe with columns = chem_names, and values of each column is a series
              of scans in 701 intervals.  
            str filename: the title of the plot, and the file  
            list&lt;str&gt; wells: an ordered list of all of the chem_names you want to plot.  
        Postconditions:  
            plot has been written with name &#34;overlay.png&#34; to the plotting dir. or 
            {filename}.png if filename was supplied  
        &#39;&#39;&#39;
        if not filename:
            filename = &#34;overlay&#34;
        x_vals = list(range(300,1001))
        #overlays only things you specify
        y = []
        #df = df[df_reorder]
        #headers = [well_key[k] for k in df.columns]
        #legend_colors = []
        for chem_name in wells:
            y.append(df[chem_name].iloc[-701:].to_list())
        self._plot_setup_overlay(filename)
        colors = list(cm.rainbow(np.linspace(0, 1,len(y))))
        for i in range(len(y)):
            plt.plot(x_vals,y[i],color = tuple(colors[i]))
        patches = [mpatches.Patch(color=color, label=label) for label, color in zip(wells, colors)]
        plt.legend(patches, wells, loc=&#39;upper right&#39;, frameon=False,prop={&#39;size&#39;:3})
        legend = pd.DataFrame({&#39;Color&#39;:patches,&#39;Labels&#39;: wells})
        plt.savefig(os.path.join(self.plot_path, &#39;{}.png&#39;.format(filename)))
        plt.close()
       
    # below until ~end is all not used yet needs to be worked up
    def plot_kin_subplots(self,df,n_cycles,wells,filename=None):
        &#39;&#39;&#39;
        TODO this function doesn&#39;t save properly, but it does show. Don&#39;t know issue  
        plots kinetics for each well in the order given by wells.  
        params:  
            df df: the scan data  
            int n_cycles: the number of cycles for the scan data  
            list&lt;str&gt; wells: the wells you want to plot in order
        Postconditions:  
            plot has been written with name &#34;{filename}_overlay.png&#34; to the plotting dir.  
            If filename is not supplied, name is kin_subplots
        &#39;&#39;&#39;
        if not filename:
            filename=kin_subplots
        x_vals = list(range(300,1001))
        colors = list(cm.rainbow(np.linspace(0, 1, n_cycles)))
        fig, axes = plt.subplots(8, 12, dpi=300, figsize=(50, 50),subplot_kw=dict(box_aspect=1,sharex = True,sharey = True))
        for idx, (chem_name, ax) in enumerate(zip(wells, axes.flatten())):
            ax.set_title(chem_name)
            self._plot_kin(ax, df, n_cycles, chem_name)
            plt.subplots_adjust(wspace=0.3, hspace= -0.1)
        
            ax.tick_params(
                which=&#39;both&#39;,
                bottom=&#39;off&#39;,
                left=&#39;off&#39;,
                right=&#39;off&#39;,
                top=&#39;off&#39;
            )
            ax.set_xlim((300,1000))
            ax.set_ylim((0,1.0))
            ax.set_xlabel(&#34;Wavlength (nm)&#34;)
            ax.set_ylabel(&#34;Absorbance (A.U.)&#34;)
            ax.set_xticks(range(301, 1100, 100))
            #ax.set_aspect(adjustable=&#39;box&#39;)
            #ax.set_yticks(range(0,1))
        else:
            [ax.set_visible(False) for ax in axes.flatten()[idx+1:]]
        plt.savefig(os.path.join(self.plot_path, &#39;{}.png&#39;.format(filename)))
        plt.close()

    def _plot_kin(self, ax, df, n_cycles, chem_name):
        &#39;&#39;&#39;
        helper method for kinetics plotting methods  
        params:  
            plt.axes ax: or anything with a plot func. the place you want ot plot  
            df df: the scan data  
            int n_cycles: the number of cycles in per well scanned  
            str chem_name: the name of the chemical to be plotted  
        Postconditions:  
            a kinetics plot of the well has been plotted on ax  
        &#39;&#39;&#39;
        x_vals = list(range(300,1001))
        colors = list(cm.rainbow(np.linspace(0, 1, n_cycles)))
        kin = 0
        col = df[chem_name]
        for kin in range(n_cycles):
            ax.plot(x_vals, df[chem_name].iloc[kin*701:(kin+1)*701],color=tuple(colors[kin]))
        
    
    def plot_single_kin(self, df, n_cycles, chem_name, filename=None):
        &#39;&#39;&#39;
        plots one kinetics trace. 
        params:  
            df df: the scan data  
            int n_cycles: the number of cycles in per well scanned  
            str chem_name: the name of the chemical to be plotted  
            str filename: the name of the file to write  
        Postconditions:  
            A kinetics trace of the well has been written to the Plots directory.
            under the name filename. If filename was None, the filename will be 
            {chem_name}_kinetics.png
        &#39;&#39;&#39;
        if not filename:
            filename = &#39;{}_kinetics&#39;.format(chem_name)
        self._plot_setup_overlay(&#39;Kinetics {}: &#39;.format(chem_name))
        self._plot_kin(plt,df, n_cycles, chem_name)
        plt.savefig(os.path.join(self.plot_path, &#39;{}.png&#39;.format(filename)))
        plt.close()

    def _get_empty_containers(self, raw_reagent_df):
        &#39;&#39;&#39;
        only one line, but there&#39;s a lot going on. extracts the empty lines from the raw_reagent_df  
        params:  
            df raw_reagent_df: as in reagent_info of excel  
        returns:  
            df empty_containers:  
                + INDEX:  
                + int deck_pos: the position on the deck  
                + COLS:  
                + str loc: location on the labware  
        &#39;&#39;&#39;
        return raw_reagent_df.loc[&#39;empty&#39; == raw_reagent_df.index].set_index(&#39;deck_pos&#39;).drop(columns=[&#39;conc&#39;, &#39;mass&#39;])

    def _get_dry_containers(self, raw_reagent_df):
        &#39;&#39;&#39;
        params:  
            df raw_reagent_df: the reagent dataframe as recieved from excel  
        returns:  
            df dry_containers:  
                note: cannot be sent over pickle as is because the index has duplicates.
                  solution is to reset the index for shipping
                + str index: the chemical name
                + float conc: the concentration once built
                + str loc: the location on the labware
                + int deck_pos: position on the deck
                + float required_vol: the volume of water needed to turn this into a reagent
        &#39;&#39;&#39;
        #other rows will be empty str unless dry
        dry_containers = raw_reagent_df.loc[raw_reagent_df[&#39;molar_mass&#39;].astype(bool)].astype(
                {&#39;deck_pos&#39;:int,&#39;mass&#39;:float,&#39;molar_mass&#39;:float})
        dry_containers.drop(columns=&#39;conc&#39;,inplace=True)
        dry_containers.reset_index(inplace=True)
        dry_containers[&#39;index&#39;] = dry_containers[&#39;index&#39;].apply(lambda x: x.replace(&#39; &#39;,&#39;_&#39;))
        return dry_containers


    
    def _parse_raw_reagent_df(self, raw_reagent_df):
        &#39;&#39;&#39;
        parses the raw_reagent_df into final form for reagent_df  
        params:  
            df raw_reagent_df: as in excel  
        returns:  
            df reagent_df: empties ignored, columns with correct types  
        &#39;&#39;&#39;
        # incase not on axis
        reagent_df = raw_reagent_df.drop([&#39;empty&#39;], errors=&#39;ignore&#39;)
        reagent_df = reagent_df.loc[~reagent_df[&#39;molar_mass&#39;].astype(bool)] #drop dry
        reagent_df.drop(columns=&#39;molar_mass&#39;,inplace=True)
        try:
            reagent_df = reagent_df.astype({&#39;conc&#39;:float,&#39;deck_pos&#39;:int,&#39;mass&#39;:float})
        except ValueError as e:
            raise ValueError(&#34;Your reagent info could not be parsed. Likely you left out a required field, or you did not specify a concentration on the input sheet&#34;)
        return reagent_df

    def _get_instrument_dict(self, deck_data):
        &#39;&#39;&#39;
        uses data from deck sheet to return the instrument params  
        Preconditions:  
            The second sheet in the worksheet must be initialized with where you&#39;ve placed reagents 
            and the first thing not being used  
        params:  
            list&lt;list&lt;str&gt;&gt;deck_data: the deck data as in excel  
        returns:  
            Dict&lt;str:str&gt;: key is &#39;left&#39; or &#39;right&#39; for the slots. val is the name of instrument  
        &#39;&#39;&#39;
        #the format google fetches this in is funky, so we convert it into a nice df
        #make instruments
        instruments = {}
        instruments[&#39;left&#39;] = deck_data[13][0]
        instruments[&#39;right&#39;] = deck_data[13][1]
        return instruments
    
    def _get_labware_df(self, deck_data, empty_containers):
        &#39;&#39;&#39;
        uses data from deck sheet to get information about labware locations, first tip, etc.  
        Preconditions:  
            The second sheet in the worksheet must be initialized with where you&#39;ve placed reagents 
            and the first thing not being used  
        params:  
            list&lt;list&lt;str&gt;&gt;deck_data: the deck data as in excel  
            df empty_containers: this is used for tubes. it holds the containers that can be used  
                + int index: deck_pos  
                + str position: the position of the empty container on the labware  
        returns:  
            df:  
                + str name: the common name of the labware  
                + str first_usable: the first tip/well to use  
                + int deck_pos: the position on the deck of this labware  
                + str empty_list: the available slots for empty tubes format &#39;A1,B2,...&#39; No specific
                  order  
        &#39;&#39;&#39;
        labware_dict = {&#39;name&#39;:[], &#39;first_usable&#39;:[],&#39;deck_pos&#39;:[]}
        for row_i in range(0,10,3):
            for col_i in range(3):
                labware_dict[&#39;name&#39;].append(deck_data[row_i+1][col_i])
                labware_dict[&#39;first_usable&#39;].append(deck_data[row_i+2][col_i])
                labware_dict[&#39;deck_pos&#39;].append(deck_data[row_i][col_i])
        labware_df = pd.DataFrame(labware_dict)
        #platereader positions need to be translated, and they shouldn&#39;t be put in both
        #slots
        platereader_rows = labware_df.loc[(labware_df[&#39;name&#39;] == &#39;platereader7&#39;) | \
                (labware_df[&#39;name&#39;] == &#39;platereader4&#39;)]
        usable_rows = platereader_rows.loc[platereader_rows[&#39;first_usable&#39;].astype(bool), &#39;first_usable&#39;]
        assert (not usable_rows.empty), &#34;please specify a first tip/well for the platereader&#34;
        assert (usable_rows.shape[0] == 1), &#34;too many first wells specified for platereader&#34;
        platereader_input_first_usable = usable_rows.iloc[0]
        platereader_name = self.PLATEREADER_INDEX_TRANSLATOR[platereader_input_first_usable][1]
        platereader_first_usable = self.PLATEREADER_INDEX_TRANSLATOR[platereader_input_first_usable][0]
        if platereader_name == &#39;platereader7&#39;:
            platereader4_first_usable = &#39;F8&#39; #anything larger than what is on plate
            platereader7_first_usable = platereader_first_usable
        else:
            platereader4_first_usable = platereader_first_usable
            platereader7_first_usable = &#39;G1&#39;
        labware_df.loc[labware_df[&#39;name&#39;]==&#39;platereader4&#39;,&#39;first_usable&#39;] = platereader4_first_usable
        labware_df.loc[labware_df[&#39;name&#39;]==&#39;platereader7&#39;,&#39;first_usable&#39;] = platereader7_first_usable
        labware_df = labware_df.loc[labware_df[&#39;name&#39;] != &#39;&#39;] #remove empty slots
        labware_df.set_index(&#39;deck_pos&#39;, inplace=True)
        #add empty containers in list form
        #there&#39;s some fancy formating here that gets you a series with deck as the index and
        #comma seperated loc strings eg &#39;A1,A3,B2&#39; as values
        grouped = empty_containers[&#39;loc&#39;].apply(lambda pos: pos+&#39;,&#39;).groupby(&#39;deck_pos&#39;)
        labware_locs = grouped.sum().apply(lambda pos: pos[:len(pos)-1])
        labware_df = labware_df.join(labware_locs, how=&#39;left&#39;)
        labware_df[&#39;loc&#39;] = labware_df[&#39;loc&#39;].fillna(&#39;&#39;)
        labware_df.rename(columns={&#39;loc&#39;:&#39;empty_list&#39;},inplace=True)
        labware_df.reset_index(inplace=True)
        labware_df[&#39;deck_pos&#39;] = pd.to_numeric(labware_df[&#39;deck_pos&#39;])
        return labware_df

    def save(self):
        self.portal.send_pack(&#39;save&#39;)
        #server will initiate file transfer
        files = self.portal.recv_ftp()
        for filename, file_bytes in files:
            with open(os.path.join(self.eve_files_path,filename), &#39;wb&#39;) as write_file:
                write_file.write(file_bytes)
        self.translate_wellmap()
        

    def close_connection(self):
        &#39;&#39;&#39;
        runs through closing procedure with robot    
        Postconditions:    
            Log files have been written to self.out_path  
            Connection has been closed  
        &#39;&#39;&#39;
        print(&#39;&lt;&lt;controller&gt;&gt; initializing breakdown&#39;)
        self.save()
        #server should now send a close command
        self.portal.send_pack(&#39;close&#39;)
        print(&#39;&lt;&lt;controller&gt;&gt; shutting down&#39;)
        self.portal.close()
    
    def translate_wellmap(self):
        &#39;&#39;&#39;
        Preconditions:  
            there exists a file wellmap.tsv in self.eve_files, and that file has eve level
            machine labels  
        Postconditions:  
            translated_wellmap.tsv has been created. translated is a copy of wellmap with   
            it&#39;s locations translated to human locs, but the labware pos remains the same  
        &#39;&#39;&#39;
        df = pd.read_csv(os.path.join(self.eve_files_path,&#39;wellmap.tsv&#39;), sep=&#39;\t&#39;)
        df[&#39;loc&#39;] = df.apply(lambda r: r[&#39;loc&#39;] if (r[&#39;deck_pos&#39;] not in [4,7]) else self.PLATEREADER_INDEX_TRANSLATOR.inv[(r[&#39;loc&#39;],&#39;platereader&#39;+str(r[&#39;deck_pos&#39;]))],axis=1)
        df.to_csv(os.path.join(self.eve_files_path,&#39;translated_wellmap.tsv&#39;),sep=&#39;\t&#39;,index=False)

    def init_robot(self, simulate):
        &#39;&#39;&#39;
        this does the dirty work of sending accumulated params over network to the robot  
        params:  
            bool simulate: whether the robot should run a simulation  
        Postconditions:  
            robot has been initialized with necessary params  
        &#39;&#39;&#39;
        #send robot data to initialize itself
        cid = self.portal.send_pack(&#39;init&#39;, simulate, 
                self.robo_params[&#39;using_temp_ctrl&#39;], self.robo_params[&#39;temp&#39;],
                self.robo_params[&#39;labware_df&#39;].to_dict(), self.robo_params[&#39;instruments&#39;],
                self.robo_params[&#39;reagent_df&#39;].to_dict(), self.my_ip,
                self.robo_params[&#39;dry_containers&#39;].to_dict())

    @abstractmethod
    def run_simulation(self):
        pass

    @abstractmethod
    def run_protocol(self,simulate):
        pass


    def _error_handler(self, e):
        &#39;&#39;&#39;
        When an error is thrown from a public method, it will be sent here and handled
        &#39;&#39;&#39;
        #handle the error
        if self.portal.state == 1:
            #Armchair recieved an error packet, so eve had a problem
            try:
                eve_error = self.portal.error_payload[0]
                print(&#39;&#39;&#39;&lt;&lt;controller&gt;&gt;----------------Eve Error----------------
                Eve threw error &#39;{}&#39;
                Attempting to save state on exit
                &#39;&#39;&#39;.format(eve_error))
                self.portal.reset_error()
                self.close_connection()
                self.pr.shutdown()
            finally:
                raise eve_error
        else:
            try:
                print(&#39;&#39;&#39;&lt;&lt;controller&gt;&gt; ----------------Controller Error----------------
                &lt;&lt;controller&gt;&gt; Attempting to save state on exit&#39;&#39;&#39;)
                self.close_connection()
                self.pr.shutdown()
            finally:
                time.sleep(.5) #this is just for printing format. Not critical
                raise e

    def _load_rxn_df(self, input_data):
        &#39;&#39;&#39;
        reaches out to google sheets and loads the reaction protocol into a df and formats the df
        adds a chemical name (primary key for lots of things. e.g. robot dictionaries)
        renames some columns to code friendly as opposed to human friendly names  
        params:  
            list&lt;list&lt;str&gt;&gt; input_data: as recieved in excel  
        returns:  
            pd.DataFrame: the information in the rxn_spreadsheet w range index. spreadsheet cols  
        Postconditions:  
            self._products has been initialized to hold the names of all the products  
        &#39;&#39;&#39;
        cols = make_unique(pd.Series(input_data[0])) 
        rxn_df = pd.DataFrame(input_data[3:], columns=cols)
        #rename some of the clunkier columns 
        rxn_df.rename({&#39;operation&#39;:&#39;op&#39;, &#39;dilution concentration&#39;:&#39;dilution_conc&#39;,&#39;concentration (mM)&#39;:&#39;conc&#39;, &#39;reagent (must be uniquely named)&#39;:&#39;reagent&#39;, &#39;plot protocol&#39;:&#39;plot_protocol&#39;, &#39;pause time (s)&#39;:&#39;pause_time&#39;, &#39;comments (e.g. new bottle)&#39;:&#39;comments&#39;,&#39;scan protocol&#39;:&#39;scan_protocol&#39;, &#39;scan filename (no extension)&#39;:&#39;scan_filename&#39;, &#39;plot filename (no extension)&#39;:&#39;plot_filename&#39;}, axis=1, inplace=True)
        rxn_df.drop(columns=[&#39;comments&#39;], inplace=True)#comments are for humans
        rxn_df.replace(&#39;&#39;, np.nan,inplace=True)
        rxn_df[[&#39;pause_time&#39;,&#39;dilution_conc&#39;,&#39;conc&#39;]] = rxn_df[[&#39;pause_time&#39;,&#39;dilution_conc&#39;,&#39;conc&#39;]].astype(float)
        #rename chemical names
        rxn_df[&#39;chemical_name&#39;] = rxn_df[[&#39;conc&#39;, &#39;reagent&#39;]].apply(self._get_chemical_name,axis=1)
        self._rename_products(rxn_df)
        #go back for some non numeric columns
        rxn_df[&#39;callbacks&#39;].fillna(&#39;&#39;,inplace=True)
        self._products = rxn_df.loc[:,&#39;reagent&#39;:&#39;chemical_name&#39;].drop(columns=[&#39;chemical_name&#39;, &#39;reagent&#39;]).columns
        #make the reagent columns floats
        rxn_df.loc[:,self._products] =  rxn_df[self._products].astype(float)
        rxn_df.loc[:,self._products] = rxn_df[self._products].fillna(0)
        return rxn_df

    @abstractmethod
    def _rename_products(self, rxn_df):
        &#39;&#39;&#39;
        Different for Protocol Executor vs auto
        renames dilutions acording to the reagent that created them
        and renames rxns to have a concentration  
        Preconditions:  
            dilution cols are named dilution_1/2 etc  
            callback is the last column in the dataframe  
            rxn_df is not expected to be initialized yet. This is a helper for the initialization  
        params:  
            df rxn_df: the dataframe with all the reactions  
        Postconditions:  
            the df has had it&#39;s dilution columns renamed to a chemical name
        &#39;&#39;&#39;
        pass

    def _get_products_to_labware(self, input_data):
        &#39;&#39;&#39;
        create a dictionary mapping products to their requested labware/containers  
        Preconditions:  
            self.rxn_df must have been initialized already  
        params:  
            list&lt;list&lt;str&gt;&gt; input data: the data from the excel sheet  
        returns:  
            Dict&lt;str,list&lt;str,str&gt;&gt;: effectively the 2nd and 3rd rows in excel. Gives 
                    labware and container preferences for products  
        &#39;&#39;&#39;
        cols = self.rxn_df.columns.to_list()
        product_start_i = cols.index(&#39;reagent&#39;)+1
        requested_containers = input_data[2][product_start_i+1:]
        requested_labware = input_data[1][product_start_i+1:]#add one to account for the first col (labware)
        #in df this is an index, so size cols is one less
        products_to_labware = {product:[labware,container] for product, labware, container in zip(self._products, requested_labware,requested_containers)}
        return products_to_labware

    def _query_reagents(self, spreadsheet_key, credentials):
        &#39;&#39;&#39;
        query the user with a reagent sheet asking for more details on locations of reagents, mass
        etc  
        Preconditions:  
            self.rxn_df should be initialized  
        params:  
            str spreadsheet_key: this is the a unique id for google sheet used for i/o with sheets
            ServiceAccount Credentials credentials: to access sheets  
        PostConditions:  
            reagent_sheet has been constructed  
        &#39;&#39;&#39;
        rxn_names = self.rxn_df.loc[:, &#39;reagent&#39;:&#39;chemical_name&#39;].drop(columns=[&#39;reagent&#39;,&#39;chemical_name&#39;]).columns
        #you might make a reaction you don&#39;t want to specify at the start
        reagent_df = self.rxn_df.loc[self.rxn_df[&#39;op&#39;] != &#39;make&#39;, [&#39;chemical_name&#39;, &#39;conc&#39;]\
                ].groupby(&#39;chemical_name&#39;).first()
        reagent_df.drop(rxn_names, errors=&#39;ignore&#39;, inplace=True) #not all rxns are reagents
        reagent_df[[&#39;loc&#39;, &#39;deck_pos&#39;, &#39;mass&#39;, &#39;molar_mass (for dry only)&#39;, &#39;comments&#39;]] = &#39;&#39;
        if not self.use_cache:
            if reagent_df.empty:
                #d2g has weird upload behavior so must add a blank row
                blanks = [&#39;&#39; for i in range(reagent_df.shape[1])]
                reagent_df = reagent_df.append(pd.DataFrame([blanks],
                        columns=reagent_df.columns,index=pd.Index([&#39;&#39;],name=&#39;chemical_name&#39;)))
            d2g.upload(reagent_df.reset_index(),spreadsheet_key,wks_name = &#39;reagent_info&#39;, row_names=False , credentials = credentials)

    def _get_product_df(self, products_to_labware):
        &#39;&#39;&#39;
        Creates a df to be used by robot to initialize containers for the products it will make  
        params:  
            df products_to_labware: as passed to init_robot  
        returns:  
            df products:  
                + INDEX:  
                + str chemical_name: the name of this rxn  
                + COLS:  
                + str labware: the labware to put this rxn in or None if no preference  
                + float max_vol: the maximum volume that will ever ocupy this container  
        &#39;&#39;&#39;
        products = products_to_labware.keys()
        max_vols = [self._get_rxn_max_vol(product, products) for product in products]
        product_df = pd.DataFrame(products_to_labware, index=[&#39;labware&#39;,&#39;container&#39;]).T
        product_df[&#39;max_vol&#39;] = max_vols
        return product_df

    @abstractmethod
    def _get_rxn_max_vol(self, name, products):
        &#39;&#39;&#39;
        This needs to be implemented to as a helper for _get_product_df.
        It calculates the maximum volume that a container will hold at a time
        &#39;&#39;&#39;
        pass

    def execute_protocol_df(self):
        &#39;&#39;&#39;
        takes a protocol df and sends every step to robot to execute  
        params:  
            int buff: the number of commands allowed in flight at a time  
        Postconditions:  
            every step in the protocol has been sent to the robot  
        &#39;&#39;&#39;
        for i, row in self.rxn_df.iterrows():
            if row[&#39;op&#39;] == &#39;transfer&#39;:
                self._send_transfer_command(row,i)
            elif row[&#39;op&#39;] == &#39;pause&#39;:
                cid = self.portal.send_pack(&#39;pause&#39;,row[&#39;pause_time&#39;])
            elif row[&#39;op&#39;] == &#39;stop&#39;:
                #read through the inflight packets
                self.portal.send_pack(&#39;stop&#39;)
                self._stop(i)
            elif row[&#39;op&#39;] == &#39;scan&#39;:
                self._execute_scan(row, i)
            elif row[&#39;op&#39;] == &#39;dilution&#39;:
                self._send_dilution_commands(row, i)
            elif row[&#39;op&#39;] == &#39;mix&#39;:
                self._mix(row, i)
            elif row[&#39;op&#39;] == &#39;make&#39;:
                self._send_make(row, i)
            elif row[&#39;op&#39;] == &#39;save&#39;:
                self.save()
            elif row[&#39;op&#39;] == &#39;plot&#39;:
                self._create_plot(row, i)
            else:
                raise Exception(&#39;invalid operation {}&#39;.format(row[&#39;op&#39;]))

    def _create_plot(self, row, i):
        &#39;&#39;&#39;
        exectues a plot command  
        params:  
            pd.Series row: a row of self.rxn_df  
            int i: index of this row  
        &#39;&#39;&#39;
        wellnames = row[self._products][row[self._products].astype(bool)].index
        plot_type = row[&#39;plot_protocol&#39;]
        filename = row[&#39;plot_filename&#39;]
        #make sure you have mapping for all files

        self._update_cached_locs(wellnames)
        pr_dict = {entry.loc:chem_name 
                    for chem_name, entry 
                    in self._cached_reader_locs.items() 
                    if entry.deck_pos in [4,7]}
        #it&#39;s not safe to plot in simulation because the scan file may not exist yet
        df, metadata = self.pr.load_reader_data(&#39;{}.csv&#39;.format(row[&#39;scan_filename&#39;]), pr_dict)
        #execute the plot depending on what was specified
        if plot_type == &#39;single_kin&#39;:
            for wellname in wellnames:
                self.plot_single_kin(df, metadata[&#39;n_cycles&#39;], wellname, &#34;{}_{}&#34;.format(wellname, filename))
        elif plot_type == &#39;overlay&#39;:
            self.plot_LAM_overlay(df, wellnames, filename)
        elif plot_type == &#39;multi_kin&#39;:
            self.plot_kin_subplots(df, metadata[&#39;n_cycles&#39;], wellnames, filename)

    def _download_reagent_data(self, spreadsheet_key, credentials):
        &#39;&#39;&#39;
        This is almost line for line inherited, but we need to input in the middle. 
        What can you do?  
        params:  
            str spreadsheet_key: this is the a unique id for google sheet used for i/o with sheets  
            ServiceAccount Credentials credentials: to access sheets  
        returns:  
            df reagent_info: dataframe as pulled from gsheets (with comments dropped)  
        &#39;&#39;&#39;
        
        if self.use_cache:
            #if you&#39;ve already seen this don&#39;t pull it
            with open(os.path.join(self.cache_path, &#39;reagent_info_sheet.pkl&#39;), &#39;rb&#39;) as reagent_info_cache:
                reagent_info = dill.load(reagent_info_cache)
        else:
            input(&#34;&lt;&lt;controller&gt;&gt; please press enter when you&#39;ve completed the reagent sheet&#34;)
            #pull down from the cloud
            reagent_info = g2d.download(spreadsheet_key, &#39;reagent_info&#39;, col_names = True, 
                row_names = True, credentials=credentials).drop(columns=[&#39;comments&#39;])
            #cache the data
            #DEBUG
            with open(os.path.join(self.cache_path, &#39;reagent_info_sheet.pkl&#39;), &#39;wb&#39;) as reagent_info_cache:
                dill.dump(reagent_info, reagent_info_cache)
        reagent_info.rename(columns={&#39;molar_mass (for dry only)&#39;: &#39;molar_mass&#39;}, inplace=True)
        return reagent_info

    def _send_make(self, row, i):
        &#39;&#39;&#39;
        sends a make command to the robot  
        params:  
            pd.Series row: a row of self.rxn_df  
            int i: index of this row  
        &#39;&#39;&#39;
        self.portal.send_pack(&#39;make&#39;, row[&#39;reagent&#39;].replace(&#39; &#39;,&#39;_&#39;), row[&#39;conc&#39;])

    def _execute_scan(self,row,i):
        &#39;&#39;&#39;
        There are a few things entailed in a scan command  
        1) send home to robot  
        2) block until you run out of waits  
        3) figure out what wells you want to scan  
        4) query the robot for those wells, or use cache if you have it  
            a) if you had to query robot, send request of reagents  
            b) wait on robot response  
            c) translate robot response to human readable  
        5) update layout to scanner and scan  
        params:  
            pd.Series row: a row of self.rxn_df  
            int i: index of this row  
        &#39;&#39;&#39;
        #1)
        self.portal.send_pack(&#39;home&#39;)
        #2)
        self.portal.burn_pipe()
        #3)
        wellnames = row[self._products][row[self._products].astype(bool)].index
        self._update_cached_locs(wellnames)
        #4)
        #update the locs on the well
        well_locs = []
        for well, entry in [(well, self._cached_reader_locs[well]) for well in wellnames]:
            assert (entry.deck_pos in [4,7]), &#34;tried to scan {}, but {} is on {} in deck pos {}&#34;.format(well, well, entry.deck_pos, entry.loc)
            assert (math.isclose(entry.vol, 200)), &#34;tried to scan {}, but {} has a bad volume. Vol was {}, but 200 is required for a scan&#34;.format(well, well, entry.vol)
            well_locs.append(entry.loc)
        #5
        self.pr.exec_macro(&#39;PlateIn&#39;)
        self.pr.run_protocol(row[&#39;scan_protocol&#39;], row[&#39;scan_filename&#39;], layout=well_locs)
        self.pr.exec_macro(&#39;PlateOut&#39;)

    def _update_cached_locs(self, wellnames):
        &#39;&#39;&#39;
        A query will be
        made to Eve for the wellnames, and data for those will be stored in the cache  
        params:  
            listlike&lt;str&gt; wellnames: the names of the wells you want to lookup  
        Postconditions:  
            The wellnames are in the cache  
        &#39;&#39;&#39;
        #couldn&#39;t find in the cache, so we got to make a query
        self.portal.send_pack(&#39;loc_req&#39;, [wellname for wellname in wellnames])
        pack_type, _, payload = self.portal.recv_pack()
        assert (pack_type == &#39;loc_resp&#39;), &#39;was expecting loc_resp but recieved {}&#39;.format(pack_type)
        returned_well_locs = payload[0]
        #update the cache
        for well_entry in returned_well_locs:
            if well_entry[2] in [4,7]:
                #is on reader. Need to translate index
                self._cached_reader_locs[well_entry[0]] = self.ChemCacheEntry(*(self.PLATEREADER_INDEX_TRANSLATOR.inv[(well_entry[1],&#39;platereader{}&#39;.format(well_entry[2]))],)+well_entry[2:])
            else:
                #not on reader, just use vanilla index
                self._cached_reader_locs[well_entry[0]] = self.ChemCacheEntry(*well_entry[1:])

    def _mix(self,row,i):
        &#39;&#39;&#39;
        For now this function just shakes the whole plate.
        In the future, we may want to mix
        things that aren&#39;t on the platereader, in which case a new argument should be made in 
        excel for the wells to scan, and we should make a function to pipette mix.
        &#39;&#39;&#39;
        wells_to_mix = row[self._products].loc[row[self._products].astype(bool)].astype(int)
        wells_to_mix.name = &#39;mix_code&#39;
        #wells_to_mix = [t for t in wells_to_mix.astype(int).iteritems()]
        self._update_cached_locs(wells_to_mix.index)
        deck_poses = pd.Series({wellname:self._cached_reader_locs[wellname].deck_pos for 
                wellname in wells_to_mix.index}, name=&#39;deck_pos&#39;)
        wells_to_mix_df = pd.concat((wells_to_mix, deck_poses),axis=1)
        #get platereader rows. true if pr
        wells_to_mix_df[&#39;platereader&#39;] = wells_to_mix_df[&#39;deck_pos&#39;].apply(lambda x: x in [4,7]) 
        if wells_to_mix_df[&#39;platereader&#39;].sum() &gt; 0:
            #TODO technically, you could be mixing the other stuff by hand while you&#39;re mixing
            #the stuff in the reader, but if you miscalculated and accidently hand mix on the
            #platereader because of a bug, Mark will be mad, so apart for now. After testing
            #you should burn pipe, then send the handmix command, then mix the platereader
            #to multitask

            #at least one well nees a shake
            self.portal.send_pack(&#39;home&#39;)
            self.portal.burn_pipe() # can&#39;t be pulling plate in if you&#39;re still mixing
            self.pr.exec_macro(&#39;PlateIn&#39;)
            self.pr.shake()
            self.pr.exec_macro(&#39;PlateOut&#39;)
        if (~wells_to_mix_df[&#39;platereader&#39;]).sum() &gt; 0:
            #at least one needs to be mixed by hand
            #still df
            hand_mix_wells = wells_to_mix_df.loc[~wells_to_mix_df[&#39;platereader&#39;]].reset_index()
            #convert to list of tuples
            hand_mix_wells = [tuple(t) for t in hand_mix_wells[[&#39;index&#39;,&#39;mix_code&#39;]].itertuples(index=False)]
            self.portal.send_pack(&#39;mix&#39;, hand_mix_wells)

    def _send_dilution_commands(self,row,i):
        &#39;&#39;&#39;
        used to execute a dilution. This is analogous to microcode. This function will send two
          commands. Water is always added first.
            transfer: transfer water into the container
            transfer: transfer reagent into the container  
        params:  
            pd.Series row: a row of self.rxn_df  
            int i: index of this row  
        Preconditions:  
            The buffer has room for at least one command  
        Postconditions:  
            Two transfer commands have been sent to the robot to: 1) add water. 2) add reagent.  
            Will block on ready if the buffer is filled  
        &#39;&#39;&#39;
        water_transfer_row, reagent_transfer_row = self._get_dilution_transfer_rows(row)
        self._send_transfer_command(water_transfer_row, i)
        self._send_transfer_command(reagent_transfer_row, i)

    def _get_dilution_transfer_rows(self, row):
        &#39;&#39;&#39;
        Takes in a dilution row and builds two transfer rows to be used by the transfer command  
        params:  
            pd.Series row: a row of self.rxn_df  
        returns:  
            tuple&lt;pd.Series&gt;: rows to be passed to the send transfer command. water first, then
              reagent
              see self._construct_dilution_transfer_row for details  
        &#39;&#39;&#39;
        reagent = row[&#39;chemical_name&#39;]
        reagent_conc = row[&#39;conc&#39;]
        product_cols = row.loc[self._products]
        dilution_name_vol = product_cols.loc[~product_cols.apply(lambda x: math.isclose(x,0,abs_tol=1e-9))]
        #assert (dilution_name_vol.size == 1), &#34;Failure on row {} of the protocol. It seems you tried to dilute into multiple containers&#34;
        total_vol = dilution_name_vol.iloc[0]
        target_name = dilution_name_vol.index[0]
        target_conc = row[&#39;dilution_conc&#39;]
        vol_water, vol_reagent = self._get_dilution_transfer_vols(target_conc, reagent_conc, total_vol)
        water_transfer_row = self._construct_dilution_transfer_row(&#39;WaterC1.0&#39;, target_name, vol_water)
        reagent_transfer_row = self._construct_dilution_transfer_row(reagent, target_name, vol_reagent)
        return water_transfer_row, reagent_transfer_row

    def _construct_dilution_transfer_row(self, reagent_name, target_name, vol):
        &#39;&#39;&#39;
        The transfer command expects a nicely formated row of the rxn_df, so here we create a row
        with everything in it to ship to the transfer command.  
        params:  
            str reagent_name: used as the chemical_name field  
            str target_name: used as the product_name field  
            str vol: the volume to transfer  
        returns:  
            pd.Series: has all the fields of a regular row, but only [chemical_name, target_name,
              op] have been initialized. The other fields are empty/NaN  
        &#39;&#39;&#39;
        template = self.rxn_df.iloc[0].copy()
        template[:] = np.nan
        template[self._products] = 0.0
        template[&#39;op&#39;] = &#39;transfer&#39;
        template[&#39;chemical_name&#39;] = reagent_name
        template[target_name] = vol
        template[&#39;callbacks&#39;] = &#39;&#39;
        return template

    def _stop(self, i):
        &#39;&#39;&#39;
        used to execute a stop operation. reads through buffer and then waits on user input  
        params:  
            int i: the index of the row in the protocol you&#39;re stopped on  
        Postconditions:  
            self._inflight_packs has been cleaned  
        &#39;&#39;&#39;
        pack_type, _, _ = self.portal.recv_pack()
        assert (pack_type == &#39;stopped&#39;), &#34;sent stop command and expected to recieve stopped, but instead got {}&#34;.format(pack_type)
        if not self.simulate:
            input(&#34;stopped on line {} of protocol. Please press enter to continue execution&#34;.format(i+1))
        self.portal.send_pack(&#39;continue&#39;)

    def _send_transfer_command(self, row, i):
        &#39;&#39;&#39;
        params:  
            pd.Series row: a row of self.rxn_df
              uses the chemical_name, callbacks (and associated args), product_columns  
            int i: index of this row  
        returns:  
            int: the cid of this command  
        Postconditions:  
            a transfer command has been sent to the robot  
        &#39;&#39;&#39;
        src = row[&#39;chemical_name&#39;]
        containers = row[self._products].loc[row[self._products] != 0]
        transfer_steps = [name_vol_pair for name_vol_pair in containers.iteritems()]
        #temporarilly just the raw callbacks
        callbacks = row[&#39;callbacks&#39;].replace(&#39; &#39;, &#39;&#39;).split(&#39;,&#39;) if row[&#39;callbacks&#39;] else []
        has_stop = &#39;stop&#39; in callbacks
        callbacks = [(callback, self._get_callback_args(row, callback)) for callback in callbacks]
        cid = self.portal.send_pack(&#39;transfer&#39;, src, transfer_steps, callbacks)
        if has_stop:
            n_stops = containers.shape[0]
            for _ in range(n_stops):
                self._stop(i)

    
    def _get_callback_args(self, row, callback):
        &#39;&#39;&#39;
        params:  
            pd.Series row: a row of self.rxn_df  
        returns:  
            list&lt;object&gt;: the arguments associated with the callback or None if no arguments  
        &#39;&#39;&#39;
        if callback == &#39;pause&#39;:
            return [row[&#39;pause_time&#39;]]
        return None
    

    def _get_dilution_transfer_vols(self, target_conc, reagent_conc, total_vol):
        &#39;&#39;&#39;
        calculates the amount of reagent volume needed for a dilution  
        params:  
            float target_conc: the concentration desired at the end  
            float reagent_conc: the concentration of the reagent  
            float total_vol: the total volume requested  
        returns:  
            tuple&lt;float&gt;: size 2
                volume of water to transfer
                volume of reagent to transfer  
        &#39;&#39;&#39;
        mols_reagent = total_vol*target_conc #mols (not really mols if not milimolar. whatever)
        vol_reagent = mols_reagent/reagent_conc
        vol_water = total_vol - vol_reagent
        return vol_water, vol_reagent

    def _get_chemical_name(self,row):
        &#39;&#39;&#39;
        create a chemical name
        from a row in a pandas df. (can be just the two columns, [&#39;conc&#39;, &#39;reagent&#39;])  
        params:  
            pd.Series row: a row in the rxn_df  
        returns:  
            chemical_name: the name for the chemical &#34;{}C{}&#34;.format(name, conc) or name if
              has no concentration, or nan if no name  
        &#39;&#39;&#39;
        if pd.isnull(row[&#39;reagent&#39;]) or pd.isnull(row[&#39;conc&#39;]):
            #this must not be a transfer. this operation has no chemical name
            return np.nan
        else:
            #this uses a chemical with a conc. Probably a stock solution
            return &#34;{}C{}&#34;.format(row[&#39;reagent&#39;], row[&#39;conc&#39;]).replace(&#39; &#39;, &#39;_&#39;)
        return pd.Series(new_cols)

    @abstractmethod
    def run_all_checks(self):
        &#39;&#39;&#39;
        it is expected that each subclass will implement a version of this method based
        on the checks that they need to run.  
        run_all_checks should run every appropriate pre rxn check  
        &#39;&#39;&#39;
        pass

    def check_labware(self):
        &#39;&#39;&#39;
        checks to ensure that the labware has been correctly initialized  
        returns  
            int found_errors:  
                code:  
                0: OK.  
                1: Some Errors, but could run  
                2: Critical. Abort  
        &#39;&#39;&#39;
        found_errors = 0
        for i, r in self.robo_params[&#39;labware_df&#39;].iterrows():
            #check that everything has afirst well if it&#39;s not a tube
            if not &#39;tube&#39; in r[&#39;name&#39;] and not r[&#39;first_usable&#39;]:
                print(&#39;&lt;&lt;controller&gt;&gt; specified labware {} on deck_pos {}, but did not specify first usable tip/well.&#39;.format(r[&#39;name&#39;], r[&#39;deck_pos&#39;]))
                found_errors = max(found_errors,2)
            #if you&#39;re not a tube and you have an empty_list, that&#39;s also bad
            if not &#39;tube&#39; in r[&#39;name&#39;] and r[&#39;empty_list&#39;]:
                print(&#39;&lt;&lt;controller&gt;&gt; An empty list for {} on deck pos {} was specified, but {} takes only a first usable tip/well.&#39;.format(r[&#39;name&#39;], r[&#39;deck_pos&#39;], r[&#39;name&#39;]))
                found_errors = max(found_errors,2)
            #check for no duplicates in the empty list
            if r[&#39;empty_list&#39;]:
                locs = r[&#39;empty_list&#39;].replace(&#39; &#39;,&#39;&#39;).split(&#39;,&#39;)
                if len(set(locs)) &lt; len(locs):
                    print(&#39;&lt;&lt;controller&gt;&gt; empty list for {} on deck pos {} had duplicates. List was {}&#39;.format(r[&#39;name&#39;],r[&#39;deck_pos&#39;], r[&#39;empty_list&#39;]))
                    found_errors = max(found_errors,2)
        return found_errors 

    def check_reagents(self):
        &#39;&#39;&#39;
        checks to ensure that you&#39;ve specified reagents correctly, and also checks that
        you did not double book empty containers onto reagents  
        returns  
            int found_errors:  
                code:  
                0: OK.  
                1: Some Errors, but could run  
                2: Critical. Abort  
        &#39;&#39;&#39;
        found_errors = 0
        #This is a little hefty. We&#39;re checking to see if any reagents/empty containers 
        #were double booked onto the same location on the same deck position
        labware_w_empties = self.robo_params[&#39;labware_df&#39;].loc[self.robo_params[&#39;labware_df&#39;][&#39;empty_list&#39;].astype(bool)]
        loc_pos_empty_pairs = [] # will become series
        for i, row in labware_w_empties.iterrows():
            for loc in row[&#39;empty_list&#39;].replace(&#39; &#39;,&#39;&#39;).split(&#39;,&#39;):
                loc_pos_empty_pairs.append((loc, row[&#39;deck_pos&#39;]))
        loc_pos_empty_pairs = pd.Series(loc_pos_empty_pairs, dtype=object)
        loc_deck_pos_pairs = self.robo_params[&#39;reagent_df&#39;].apply(lambda r: (r[&#39;loc&#39;], r[&#39;deck_pos&#39;]),axis=1)
        loc_deck_pos_pairs = loc_deck_pos_pairs.append(loc_pos_empty_pairs)
        val_counts = loc_deck_pos_pairs.value_counts()
        for i in val_counts.loc[val_counts &gt; 2].index:
            print(&#39;&lt;&lt;controller&gt;&gt; location {} on deck position has multiple reagents/empty containers assigned to it&#39;)
            found_errors = max(found_errors,2)
        return found_errors

    def check_rxn_df(self):
        &#39;&#39;&#39;
        Runs error checks on the reaction df to ensure that formating is correct. Illegal/Ill 
        Advised options are printed and if an error code is returned
        Will run through and check all rows, even if errors are found
        returns  
            int found_errors:  
                code:  
                0: OK.  
                1: Some Errors, but could run  
                2: Critical. Abort  
        &#39;&#39;&#39;
        found_errors = 0
        for i, r in self.rxn_df.iterrows():
            r_num = i+1
            #check pauses
            if (not (&#39;pause&#39; in r[&#39;op&#39;] or &#39;pause&#39; in r[&#39;callbacks&#39;])) == (not pd.isna(r[&#39;pause_time&#39;])):
                print(&#34;&lt;&lt;controller&gt;&gt; You asked for a pause in row {}, but did not specify the pause_time or vice versa&#34;.format(r_num))
                found_errors = max(found_errors, 2)
            #check that there&#39;s always a volume when you transfer
            if (r[&#39;op&#39;] == &#39;transfer&#39; and math.isclose(r[self._products].sum(), 0,abs_tol=1e-9)):
                print(&#34;&lt;&lt;controller&gt;&gt; You executed a transfer step in row {}, but you did not transfer any volume.&#34;.format(r_num))
                found_errors = max(found_errors, 1)
            #check that you have a reagent if you&#39;re transfering
            if r[&#39;op&#39;] == &#39;transfer&#39; and pd.isna(r[&#39;reagent&#39;]):
                print(&#39;&lt;&lt;controller&gt;&gt; transfer specified without reagent in row {}&#39;.format(r_num))
                found_errors = max(found_errors,2)
        return found_errors

class AutoContr(Controller):
    &#39;&#39;&#39;
    This is a completely automated controller. It takes as input a layout sheet, and then does
    it&#39;s own experiments, pulling data etc  
    We&#39;re adding in self.rxn_df_template, which uses the same parsing style as rxn_df
    but it&#39;s only a template, so we give it a new name and use self.rxn_df to change for the current batch we&#39;re trying to make
    &#39;&#39;&#39;
    def __init__(self, rxn_sheet_name, my_ip, server_ip, buff_size=4, use_cache=False, cache_path=&#39;Cache&#39;):
        super().__init__(rxn_sheet_name, my_ip, server_ip, buff_size, use_cache, cache_path)
        self.rxn_df_template = self.rxn_df
        self.reagent_order = self.robo_params[&#39;reagent_df&#39;].index.to_numpy()
        self.well_count = 0 #used internally for unique wellnames
        self.batch_num = 0 #used internally for unique filenames

    def run_simulation(self):
        &#39;&#39;&#39;
        runs a full simulation of the protocol on local machine
        Temporarilly overwrites the self.server_ip with loopback, but will restore it at
        end of function  
        params:
            MLModel model: the model to use when training and predicting  
        Returns:  
            bool: True if all tests were passed  
        &#39;&#39;&#39;
        #cache some things before you overwrite them for the simulation
        stored_server_ip = self.server_ip
        stored_simulate = self.simulate
        self.server_ip = &#39;127.0.0.1&#39;
        self.simulate = True

        model = DummyMLModel(2, self.reagent_order.shape[0])

        print(&#39;&lt;&lt;controller&gt;&gt; ENTERING SIMULATION&#39;)
        port = 50000
        #launch an eve server in background for simulation purposes
        b = threading.Barrier(2,timeout=20)
        eve_thread = threading.Thread(target=launch_eve_server, kwargs={&#39;my_ip&#39;:&#39;&#39;,&#39;barrier&#39;:b},name=&#39;eve_thread&#39;)
        eve_thread.start()

        #do create a connection
        b.wait()
        self._run(port, True, model)

        #collect the eve thread
        eve_thread.join()

        #restore changed vars
        self.server_ip = stored_server_ip
        self.simulate = stored_simulate
        print(&#39;&lt;&lt;controller&gt;&gt; EXITING SIMULATION&#39;)
        return True

    def run_protocol(self, model, simulate=False, port=50000):
        &#39;&#39;&#39;
        The real deal. Input a server addr and port if you choose and protocol will be run  
        params:  
            str simulate: (this should never be used in normal operation. It is for debugging
              on the robot)  
            MLModel model: the model to use when training and predicting  
        NOTE: the simulate here is a little different than running run_simulation(). This simulate
          is sent to the robot to tell it to simulate the reaction, but that it all. The other
          simulate changes some things about how code is run from the controller
        &#39;&#39;&#39;
        print(&#39;&lt;&lt;controller&gt;&gt; RUNNING&#39;)
        if simulate and model == None:
            #you&#39;re simulating with a dummy model.
            print(&#39;&lt;&lt;controller&gt;&gt; running simulation with dummy ml&#39;)
            model = DummyMLModel(2, self.reagent_order.shape[0])
        self._run(port, simulate, model)
        print(&#39;&lt;&lt;controller&gt;&gt; EXITING&#39;)

    def _rename_products(self, rxn_df):
        &#39;&#39;&#39;
        required for class compatibility, but not used by the Auto
        &#39;&#39;&#39;
        pass

    def _get_product_df(self, products_to_labware):
        &#39;&#39;&#39;
        required for class compatibility, but not used by Auto
        TODO would be nice to return something that would blow up if accessed
        &#39;&#39;&#39;
        return np.nan

    @error_exit
    def _run(self, port, simulate, model):
        &#39;&#39;&#39;
        private function to run
        Returns:  
            bool: True if all tests were passed  
        &#39;&#39;&#39;
        self._init_pr(simulate)
        #create a connection
        sock = socket.socket(socket.AF_INET)
        sock.connect((self.server_ip, port))
        buffered_sock = BufferedSocket(sock, maxsize=1e9, timeout=None)
        print(&#34;&lt;&lt;controller&gt;&gt; connected&#34;)
        self.portal = Armchair(buffered_sock,&#39;controller&#39;,&#39;Armchair_Logs&#39;, buffsize=4)
        
        self.init_robot(simulate)
        while not model.quit:
            recipes = model.predict(5)
            #generate new wellnames for next batch
            wellnames = [self._generate_wellname() for i in range(recipes.shape[0])]
            #plan and execute a reaction
            self._create_samples(wellnames, recipes)
            #pull in the scan data
            scan_data = self._get_sample_data(wellnames, self.rxn_df[&#39;scan_filename&#39;]) 
            #train on scans
            model.train(scan_data.T.to_numpy(),recipes)
            self.batch_num += 1
        self.close_connection()
        self.pr.shutdown()
        return
    
    def _get_sample_data(self,wellnames, filename):
        &#39;&#39;&#39;
        TODO
        SKELETON
        scans a sample of wells specified by wellnames, and returns their spectra  
        params:  
            list&lt;str&gt; wellnames: the names of the wells to be scanned  
            str filename: the name of the file that holds the scans  
        returns:  
            df: n_wells, by size of spectra, the scan data.  
        &#39;&#39;&#39; 
        self._update_cached_locs(wellnames)
        pr_dict = {self._cached_reader_locs[wellname].loc: wellname for wellname in wellnames}
        unordered_data, metadata = self.pr.load_reader_data(filename, pr_dict)
        #reorder according to order of wellnames
        return unordered_data[wellnames]

    def _create_samples(self, wellnames, recipes):
        &#39;&#39;&#39;
        creates the desired reactions on the platereader  
        params:  
            str wellnames: the ordered names of the wells you want to produce  
            np.array recipes: shape(n_predicted, n_reagents). Holds ratios of all the reagents
              you can use for each reaction you want to perform  
        returns:  
            list&lt;str&gt; wellnames: the names of the wells produced ordered in accordance to the
              order of recipes
        &#39;&#39;&#39;
        self.portal.send_pack(&#39;init_containers&#39;, pd.DataFrame({&#39;labware&#39;:&#39;platereader&#39;,
                &#39;container&#39;:&#39;Well96&#39;, &#39;max_vol&#39;:200.0}, index=wellnames).to_dict())
        self.rxn_df = self._build_rxn_df(wellnames, recipes)
        self._products = wellnames
        self.execute_protocol_df()

    def _generate_wellname(self):
        &#39;&#39;&#39;
        returns:  
            str: a unique name for a new well
        &#39;&#39;&#39;
        wellname = &#34;autowell{}&#34;.format(self.well_count)
        self.well_count += 1
        return wellname

    def _get_rxn_max_vol(self, name, products):
        &#39;&#39;&#39;
        This is used right now because it&#39;s best I&#39;ve got. Ideally, you could drop the part 
        of init that constructs product_df
        &#39;&#39;&#39;
        return 200.0

    def _build_rxn_df(self,wellnames,recipes):
        &#39;&#39;&#39;
        used to construct a rxn_df for this batch of reactions
        TODO test bejesus out of this method
        TODO need some sort of key to map from name of reagent to index of the 
        recipes, and then mul by 200 and then lookup to mul by the percentages in the reagent df
        &#39;&#39;&#39;
        rxn_df = self.rxn_df_template.copy() #starting point. still neeeds products
        recipe_df = pd.DataFrame(recipes, index=wellnames, columns=self.reagent_order)
        def build_product_rows(row):
            &#39;&#39;&#39;
            params:  
                pd.Series row: a row of the template df  
            returns:  
                pd.Series: a row for the new df
            &#39;&#39;&#39;
            d = {}
            if row[&#39;op&#39;] == &#39;transfer&#39;:
                #is a transfer, so we want to lookup the volume of that reagent in recipe_df
                return recipe_df.loc[:, row[&#39;chemical_name&#39;]] * row[&#39;Template&#39;] * 200.0
            else:
                #if not a tranfer, we want to keep whatever value was there
                return pd.Series(row[&#39;Template&#39;], index=recipe_df.index)
        rxn_df = rxn_df.join(self.rxn_df_template.apply(build_product_rows, axis=1)).drop(
                columns=&#39;Template&#39;)
        rxn_df[&#39;scan_filename&#39;] = rxn_df[&#39;scan_filename&#39;].apply(lambda x: &#34;{}-{}&#34;.format(
                x, self.batch_num))
        rxn_df[&#39;plot_filename&#39;] = rxn_df[&#39;plot_filename&#39;].apply(lambda x: &#34;{}-{}&#34;.format(
                x, self.batch_num))
        return rxn_df

    def run_all_checks(self):
        found_errors = 0
        found_errors = max(found_errors, self.check_rxn_df())
        found_errors = max(found_errors, self.check_labware())
        found_errors = max(found_errors, self.check_reagents())
        if found_errors == 0:
            print(&#34;&lt;&lt;controller&gt;&gt; All prechecks passed!&#34;)
            return
        elif found_errors == 1:
            if &#39;y&#39;==input(&#34;&lt;&lt;controller&gt;&gt; Please check the above errors and if you would like to ignore them and continue enter &#39;y&#39; else any key&#34;):
                return
            else:
                raise Exception(&#39;Aborting base on user input&#39;)
        elif found_errors == 2:
            raise Exception(&#39;Critical Errors encountered during prechecks. Aborting&#39;)

    def check_rxn_df(self):
        &#39;&#39;&#39;
        Runs error checks on the reaction df to ensure that formating is correct. Illegal/Ill 
        Advised options are printed and if an error code is returned
        Will run through and check all rows, even if errors are found
        Preconditions:
            self.rxn_df is rxn_df template at this point  
        returns  
            int found_errors:  
                code:  
                0: OK.  
                1: Some Errors, but could run  
                2: Critical. Abort  
        &#39;&#39;&#39;
        #at this point self.rxn_df
        found_errors = super().check_rxn_df()
        reagent_ratios  = self.rxn_df.loc[self.rxn_df[&#39;op&#39;] == &#39;transfer&#39;,\
                [&#39;Template&#39;,&#39;chemical_name&#39;]].groupby(&#39;chemical_name&#39;).sum()[&#39;Template&#39;]
        has_invalid_ratio = reagent_ratios.apply(lambda x: not math.isclose(x, 1.0,
                abs_tol=1e-9)).any()
        if has_invalid_ratio:
            print(&#39;&lt;&lt;controller&gt;&gt; precheck error: invalid ratio of reagents (doesn\&#39;t add to 1)&#39;)
            print(&#39;  ratios were {}&#39;.format(reagent_ratios))
            found_errors = max(found_errors, 2)
        return found_errors

class ProtocolExecutor(Controller): 
    &#39;&#39;&#39;
    class to execute a protocol from the docs  
    ATTRIBUTES:  
        df rxn_df: the reaction df. Not passed in, but created in init  
    INHERITED ATTRIBUTES:  
        armchair.Armchair portal, str rxn_sheet_name, str cache_path, bool use_cache,   
        str eve_files_path, str debug_path, str my_ip, str server_ip,  
        dict&lt;str:object&gt; robo_params, bool simulate, int buff_size  
    PRIVATE ATTRS:  
        pd.index _products: the product columns  
    INHERITED PRIVATE ATTRS:  
        dict&lt;str:tuple&lt;obj&gt;&gt; _cached_reader_locs  
    METHODS:  
        execute_protocol_df() void: used to execute a single row of the reaction df  
        run_all_checks() void: wrapper for pre rxn error checking to handle any found errors
          run automatically when you run your simulation  
        CHECKS: all print messages for errors and return error codes  
        check_rxn_df() int: checks for errors in input.  
        check_labware() int: checks for errors in labware/labware assignments.   
        check_products() int: checks for errors in the product placement.  
        check_reagents() int: checks for errors in the reagent_info tab.  
        TESTS: These are run after a reaction concludes to make sure things went well  
        run_all_tests() bool: True if you passed, else false. run when at end of simulation  
        test_vol_lab_cont() bool: tests that labware volume and containers are correct  
        test_contents() bool: tests that the contents of each container is ok  
    INHERITED METHODS:  
        run_protocol(simulate, port) void, close_connection() void, init_robot(simulate), 
        translate_wellmap() void, run_simulation() bool  
    &#39;&#39;&#39;

    def __init__(self, rxn_sheet_name, my_ip, server_ip, buff_size=4, use_cache=False):
        &#39;&#39;&#39;
        Note that init does not initialize the portal. This must be done explicitly or by calling
        a run function that creates a portal. The portal is not passed to init because although
        the code must not use more than one portal at a time, the portal may change over the 
        lifetime of the class
        NOte that pr cannot be initialized until you know if you&#39;re simulating or not, so it
        is instantiated in run
        &#39;&#39;&#39;
        super().__init__(rxn_sheet_name, my_ip, server_ip, buff_size, use_cache)

    def run_simulation(self):
        &#39;&#39;&#39;
        runs a full simulation of the protocol with
        Temporarilly overwrites the self.server_ip with loopback, but will restore it at
        end of function  
        Returns:  
            bool: True if all tests were passed  
        &#39;&#39;&#39;
        #cache some things before you overwrite them for the simulation
        stored_server_ip = self.server_ip
        stored_simulate = self.simulate
        self.server_ip = &#39;127.0.0.1&#39;
        self.simulate = True

        print(&#39;&lt;&lt;controller&gt;&gt; ENTERING SIMULATION&#39;)
        port = 50000
        #launch an eve server in background for simulation purposes
        b = threading.Barrier(2,timeout=20)
        eve_thread = threading.Thread(target=launch_eve_server, kwargs={&#39;my_ip&#39;:&#39;&#39;,&#39;barrier&#39;:b},name=&#39;eve_thread&#39;)
        eve_thread.start()

        #do create a connection
        b.wait()
        self._run(port, simulate=True)

        #run post execution tests
        tests_passed = self.run_all_tests()

        #collect the eve thread
        eve_thread.join()

        #restore changed vars
        self.server_ip = stored_server_ip
        self.simulate = stored_simulate
        print(&#39;&lt;&lt;controller&gt;&gt; EXITING SIMULATION&#39;)
        return tests_passed

    def run_protocol(self, simulate=False, port=50000):
        &#39;&#39;&#39;
        The real deal. Input a server addr and port if you choose and protocol will be run  
        params:  
            str simulate: (this should never be used in normal operation. It is for debugging
              on the robot)  
        NOTE: the simulate here is a little different than running run_simulation(). This simulate
          is sent to the robot to tell it to simulate the reaction, but that it all. The other
          simulate changes some things about how code is run from the controller
        &#39;&#39;&#39;
        print(&#39;&lt;&lt;controller&gt;&gt; RUNNING PROTOCOL&#39;)
        self._run(port, simulate=simulate)
        print(&#39;&lt;&lt;controller&gt;&gt; EXITING PROTOCOL&#39;)
        
    @error_exit
    def _run(self, port, simulate):
        &#39;&#39;&#39;
        Returns:  
            bool: True if all tests were passed  
        &#39;&#39;&#39;
        self._init_pr(simulate)
        #create a connection
        sock = socket.socket(socket.AF_INET)
        sock.connect((self.server_ip, port))
        buffered_sock = BufferedSocket(sock, maxsize=1e9, timeout=None)
        print(&#34;&lt;&lt;controller&gt;&gt; connected&#34;)
        self.portal = Armchair(buffered_sock,&#39;controller&#39;,&#39;Armchair_Logs&#39;, buffsize=4)

        self.init_robot(simulate)
        self.execute_protocol_df()
        self.close_connection()
        self.pr.shutdown()

    def init_robot(self,simulate):
        &#39;&#39;&#39;
        calls super init robot, and then sends an init_containers command to initialize all the
        prodcuts  
        params:  
            bool simulate: whether the robot should run a simulation  
        &#39;&#39;&#39;
        super().init_robot(simulate)
        #send robot data to initialize empty product containers. Because we know things like total
        #vol and desired labware, this makes sense for a planned experiment
        self.portal.send_pack(&#39;init_containers&#39;, self.robo_params[&#39;product_df&#39;].to_dict())
    
    def _rename_products(self, rxn_df):
        &#39;&#39;&#39;
        renames dilutions acording to the reagent that created them
        and renames rxns to have a concentration  
        Preconditions:  
            dilution cols are named dilution_1/2 etc  
            callback is the last column in the dataframe  
            rxn_df is not expected to be initialized yet. This is a helper for the initialization  
        params:  
            df rxn_df: the dataframe with all the reactions  
        Postconditions:  
            the df has had it&#39;s dilution columns renamed to the chemical used to produce it + C&lt;conc&gt;  
            rxn columns have C1 appended to them  
        &#39;&#39;&#39;
        dilution_cols = [col for col in rxn_df.columns if &#39;dilution_placeholder&#39; in col]
        #get the rxn col names
        rxn_cols = rxn_df.loc[:, &#39;reagent&#39;:&#39;chemical_name&#39;].drop(columns=[&#39;reagent&#39;,&#39;chemical_name&#39;]).columns
        rename_key = {}
        for col in rxn_cols:
            if &#39;dilution_placeholder&#39; in col:
                row = rxn_df.loc[~rxn_df[col].isna()].squeeze()
                reagent_name = row[&#39;chemical_name&#39;]
                name = reagent_name[:reagent_name.rfind(&#39;C&#39;)+1]+str(row[&#39;dilution_conc&#39;])
                rename_key[col] = name
            else:
                rename_key[col] = &#34;{}C1.0&#34;.format(col).replace(&#39; &#39;,&#39;_&#39;)
        rxn_df.rename(rename_key, axis=1, inplace=True)

    def _get_rxn_max_vol(self, name, products):
        &#39;&#39;&#39;
        Preconditions:  
            volume in a container can change only during a &#39;transfer&#39; or &#39;dilution&#39;. Easy to add more
            by changing the vol_change_rows
            self.rxn_df is initialized  
        params:  
            str name: the column name to be searched  
            list&lt;str&gt; products: the column names of all reagents (we could look this up in rxn_df, but
              convenient to pass it in)  
        returns:  
            float: the maximum volume that this container will ever hold at one time, not taking into 
              account aspirations for dilutions  
        &#39;&#39;&#39;
        vol_change_rows = self.rxn_df.loc[self.rxn_df[&#39;op&#39;].apply(lambda x: x in [&#39;transfer&#39;,&#39;dilution&#39;])]
        aspirations = vol_change_rows[&#39;chemical_name&#39;] == name
        max_vol = 0
        current_vol = 0
        for i, is_aspiration in aspirations.iteritems():
            if is_aspiration and self.rxn_df.loc[i,&#39;op&#39;] == &#39;transfer&#39;:
                #This is a row where we&#39;re transfering from this well
                current_vol -= self.rxn_df.loc[i, products].sum()
            elif is_aspiration and self.rxn_df.loc[i, &#39;op&#39;] == &#39;dilution&#39;:
                _, transfer_row = self._get_dilution_transfer_rows(self.rxn_df.loc[i])
                vol = transfer_row[self._products].sum() 
                current_vol -= vol
            else:
                current_vol += self.rxn_df.loc[i,name]
                max_vol = max(max_vol, current_vol)
        return max_vol

    
    #TESTING
    #PRE Simulation
    def run_all_checks(self):
        found_errors = 0
        found_errors = max(found_errors, self.check_rxn_df())
        found_errors = max(found_errors, self.check_labware())
        found_errors = max(found_errors, self.check_reagents())
        found_errors = max(found_errors, self.check_products())
        if found_errors == 0:
            print(&#34;&lt;&lt;controller&gt;&gt; All prechecks passed!&#34;)
            return
        elif found_errors == 1:
            if &#39;y&#39;==input(&#34;&lt;&lt;controller&gt;&gt; Please check the above errors and if you would like to ignore them and continue enter &#39;y&#39; else any key&#34;):
                return
            else:
                raise Exception(&#39;Aborting base on user input&#39;)
        elif found_errors == 2:
            raise Exception(&#39;Critical Errors encountered during prechecks. Aborting&#39;)

                
    def check_products(self):
        &#39;&#39;&#39;
        checks to ensure that the products were correctly initialized  
        returns  
            int found_errors:  
                code:  
                0: OK.  
                1: Some Errors, but could run  
                2: Critical. Abort  
        &#39;&#39;&#39;
        found_errors = 0
        for i, r in self.robo_params[&#39;product_df&#39;].loc[\
                ~self.robo_params[&#39;product_df&#39;][&#39;labware&#39;].astype(bool) &amp; \
                ~self.robo_params[&#39;product_df&#39;][&#39;container&#39;].astype(bool)].iterrows():
            found_errors = max(found_errors,1)
            print(&#39;&lt;&lt;controller&gt;&gt; {} has no specified labware or container. It could end up in anything that has enough volume to contain it. Are you sure that\&#39;s what you want? &#39;.format(i))
        return found_errors

    #POST Simulation
    def run_all_tests(self):
        &#39;&#39;&#39;
        runs all post rxn tests  
        Returns:  
            bool: True if all tests were passed  
        &#39;&#39;&#39;
        print(&#39;&lt;&lt;controller&gt;&gt; running post execution tests&#39;)
        valid = True
        valid = valid and self.test_vol_lab_cont()
        valid = valid and self.test_contents()
        return valid

    def test_vol_lab_cont(self):
        &#39;&#39;&#39;
        tests that vol, labware, and containers are correct for a row of a side by side df with
        those attributes  
        Preconditions:  
            labware_df, reagent_df, and products_df are all initialized as vals in robo_params  
            self.rxn_df is initialized  
            df labware_df:  
            df rxn_df: as from excel  
            df reagent_df: info on reagents. columns from sheet. See excel specification  
            df product_df:  
            self.eve_files_path + wellmap.tsv exists (this is a file output by eve that is shipped
              over in close step  
        Postconditions:  
            Any errors will be printed to the screen.  
            If errors were found, a pkl of the sbs will be written  
        Returns:  
            bool: True if all tests were passed  
        &#39;&#39;&#39;
        sbs = self._get_vol_lab_cont_sbs()
        sbs[&#39;flag&#39;] = sbs.apply(lambda row: self._is_valid_vol_lab_cont_sbs(row), axis=1)
        filtered_sbs = sbs.loc[~sbs[&#39;flag&#39;]]
        if filtered_sbs.empty:
            print(&#39;&lt;&lt;controller&gt;&gt; congrats! Volumes, labware, containers, and deck_poses look good!&#39;)
        else:
            print(&#39;&lt;&lt;controller&gt;&gt; volume/deck pos/labware/container errors&#39;)
            with open(os.path.join(self.debug_path,&#39;vol_lab_cont_sbs.pkl&#39;), &#39;wb&#39;) as sbs_pkl:
                dill.dump(sbs, sbs_pkl)
            if input(&#39;&lt;&lt;controller&gt;&gt; would you like to view the full sbs? [yn] &#39;).lower() == &#39;y&#39;:
                print(sbs)
            return False
        return True

    def test_contents(self):
        &#39;&#39;&#39;
        tests to ensure that the contents of each container is correct
        note does not work for dilutions, and does not check reagents  
        params:  
            df rxn_df: from excel  
            bool use_cache: True if data is cached  
            str eve_logpath: the path to the eve logfiles  
        Postconditions:  
            if a difference was found it will be displayed,  
            if no differences are found, a friendly print message will be displayed  
        Returns:  
            bool: True if all tests were passed  
        &#39;&#39;&#39;
        sbs = self._create_contents_sbs()
        sbs[&#39;flag&#39;] = sbs.apply(self._is_valid_contents_sbs,axis=1)
        filtered_sbs = sbs.loc[~sbs[&#39;flag&#39;]]
        if filtered_sbs.empty:
            print(&#39;&lt;&lt;controller&gt;&gt; congrats! Contents are correct!&#39;)
        else:
            print(&#39;&lt;&lt;controller&gt;&gt; there ere some content errors&#39;)
            with open(os.path.join(self.debug_path,&#39;contents_sbs.pkl&#39;), &#39;wb&#39;) as sbs_pkl:
                dill.dump(sbs, sbs_pkl)
            if input(&#39;&lt;&lt;controller&gt;&gt; would you like to view the full sbs? [yn] &#39;).lower() == &#39;y&#39;:
                print(sbs)
            return False
        return True

    def _is_valid_vol_lab_cont_sbs(self, row):
        &#39;&#39;&#39;
        params:  
            pd.Series row: a row of a sbs dataframe:  
        returns:  
            Bool: True if it is a valid row  
        &#39;&#39;&#39;
        if row[&#39;deck_pos_t&#39;] != &#39;any&#39; and row[&#39;deck_pos&#39;] not in row[&#39;deck_pos_t&#39;]:
            print(&#39;&lt;&lt;controller&gt;&gt; deck_pos_error:&#39;)
            print(row.to_frame().T)
            print()
            return False
        if row[&#39;vol_t&#39;] != &#39;any&#39; and not math.isclose(row[&#39;vol&#39;],row[&#39;vol_t&#39;], abs_tol=1e-9):
            print(&#39;&lt;&lt;controller&gt;&gt; volume error:&#39;)
            print(row.to_frame().T)
            print()
            return False
        if row[&#39;container_t&#39;] != &#39;any&#39; and not row[&#39;container&#39;] == row[&#39;container_t&#39;]:
            print(&#39;&lt;&lt;controller&gt;&gt; container error:&#39;)
            print(row.to_frame().T)
            print()
            return False
        if row[&#39;loc_t&#39;] != &#39;any&#39; and row[&#39;loc&#39;] not in row[&#39;loc_t&#39;]:
            print(&#39;&lt;&lt;controller&gt;&gt; loc error:&#39;)
            print(row.to_frame().T)
            print()
            return False
        return True
    
    def _get_vol_lab_cont_sbs(self):
        &#39;&#39;&#39;
        This is for comparing the volumes, labwares, and containers  
        params:  
        Preconditions:  
            labware_df, reagent_df, and products_df are all initialized as vals in robo_params  
            self.rxn_df is initialized  
            df labware_df:  
            df rxn_df: as from excel  
            df reagent_df: info on reagents. columns from sheet. See excel specification  
            df product_df:  
            self.eve_files_path + wellmap.tsv exists (this is a file output by eve that is shipped
              over in close step  
        returns  
            df  
                + INDEX
                + chemical_name: the containers name
                + COLS: symmetric. Theoretical are suffixed _t
                + str deck_pos: position on deck
                + float vol: the volume in the container
                + list&lt;tuple&lt;str, float&gt;&gt; history: the chem_name paired with the amount or
                  keyword &#39;aspirate&#39; and vol
        &#39;&#39;&#39;
        #copy the locals cause we&#39;re changing them
        labware_df = self.robo_params[&#39;labware_df&#39;].set_index(&#39;name&#39;).rename(index={&#39;platereader7&#39;:&#39;platereader&#39;,&#39;platereader4&#39;:&#39;platereader&#39;}) #converting to dict like
        product_df = self.robo_params[&#39;product_df&#39;].copy()
        reagent_df = self.robo_params[&#39;reagent_df&#39;].copy()
        #create a df with sets of allowable locs and deck_poses
        def get_dry_container_cols(df):
            &#39;&#39;&#39;
            apply helper func to combine the rows of the dry_containers_df
            &#39;&#39;&#39;
            d = {&#39;loc&#39;:set(),&#39;deck_pos&#39;:set()}
            for i, r in df.iterrows():
                d[&#39;loc&#39;].add(r[&#39;loc&#39;])
                d[&#39;deck_pos&#39;].add(r[&#39;deck_pos&#39;])
            return pd.Series(d)
        dry_containers = self.robo_params[&#39;dry_containers&#39;].groupby(&#39;index&#39;).apply(get_dry_container_cols)
        def get_deck_pos(labware):
            &#39;&#39;&#39;
            apply helper func to get the deck position for products
            &#39;&#39;&#39;
            if labware:
                deck_pos = labware_df.loc[labware,&#39;deck_pos&#39;]
                if isinstance(deck_pos,np.int64):
                    return [deck_pos]
                else:
                    #for platereader with two indices
                    return deck_pos.to_list()
            else:
                return &#39;any&#39;
        product_df[&#39;deck_pos&#39;] = product_df[&#39;labware&#39;].apply(get_deck_pos)
        product_df[&#39;vol&#39;] = [self._vol_calc(name) for name in product_df.index]
        product_df[&#39;loc&#39;] = &#39;any&#39;
        product_df.replace(&#39;&#39;,&#39;any&#39;, inplace=True)

        #because reagents can be built, we now need to ensure that you end up with something 
        #that could be on a new set of labware for reagents
        reagent_df[&#39;deck_pos&#39;] = reagent_df[&#39;deck_pos&#39;].apply(lambda x: {x})
        reagent_df[&#39;loc&#39;] = reagent_df[&#39;loc&#39;].apply(lambda x: {x})
        reagent_df[&#39;vol&#39;] = &#39;any&#39; #I&#39;m not checking this because it&#39;s harder to check, and works fine
        reagent_df[&#39;container&#39;] = &#39;any&#39; #actually fixed, but checked by combo deck_pos and loc
        def merge_dry(row):
            &#39;&#39;&#39;
            apply helper to merge a reagent_df with a dry_container_df  
            Note, this is meant to be applied to the reagent_df, so it doesn&#39;t generate
            new rows if necessary. That must be done seperately.  
            &#39;&#39;&#39;
            d = {&#39;loc&#39;:{}, &#39;deck_pos&#39;:{}}
            found_match = False
            for name in dry_containers.index.unique():
                if name in row.name:
                    d[&#39;loc&#39;] = dry_containers.loc[name,&#39;loc&#39;].union(row[&#39;loc&#39;])
                    d[&#39;deck_pos&#39;] = dry_containers.loc[name,&#39;deck_pos&#39;].union(row[&#39;deck_pos&#39;])
                    found_match = True
            if not found_match:
                d[&#39;loc&#39;] = row[&#39;loc&#39;]
                d[&#39;deck_pos&#39;] = row[&#39;deck_pos&#39;]
            return pd.Series(d)
        reagent_df[[&#39;loc&#39;, &#39;deck_pos&#39;]] = reagent_df.apply(merge_dry, axis=1)
                    
        theoretical_df = pd.concat((reagent_df.loc[:,[&#39;loc&#39;, &#39;deck_pos&#39;,\
                &#39;vol&#39;,&#39;container&#39;]], product_df.loc[:,[&#39;loc&#39;, &#39;deck_pos&#39;,&#39;vol&#39;,&#39;container&#39;]]))
        result_df = pd.read_csv(os.path.join(self.eve_files_path,&#39;wellmap.tsv&#39;), sep=&#39;\t&#39;).set_index(&#39;chem_name&#39;)
        sbs = result_df.join(theoretical_df, rsuffix=&#39;_t&#39;) #side by side
        #could still have NaNs if a dry reagent was made, but not specified at start
        sbs_rows_w_nan = sbs.loc[sbs.isna().any(axis=1)].index
        for chem_name in sbs_rows_w_nan:
            for dry_name in dry_containers.index:
                if dry_name in chem_name:
                    sbs.at[chem_name,&#39;loc_t&#39;] = dry_containers.at[dry_name,&#39;loc&#39;]
                    sbs.at[chem_name,&#39;deck_pos_t&#39;] = dry_containers.at[dry_name,&#39;deck_pos&#39;]
                    sbs.at[chem_name,&#39;vol_t&#39;] = &#39;any&#39;
                    sbs.at[chem_name,&#39;container_t&#39;] = &#39;any&#39;
        return sbs

    def _vol_calc(self, name):
        &#39;&#39;&#39;
        params:
            str name: chem_name
        returns:
            volume at end in that name
        &#39;&#39;&#39;
        dispenses = self.rxn_df.loc[(self.rxn_df[&#39;op&#39;] == &#39;dilution&#39;) |
                (self.rxn_df[&#39;op&#39;] == &#39;transfer&#39;)][name].sum()
        transfer_aspirations = self.rxn_df.loc[(self.rxn_df[&#39;op&#39;]==&#39;transfer&#39;) &amp;\
                (self.rxn_df[&#39;chemical_name&#39;] == name),self._products].sum().sum()
        dilution_rows = self.rxn_df.loc[(self.rxn_df[&#39;op&#39;]==&#39;dilution&#39;) &amp;\
                (self.rxn_df[&#39;chemical_name&#39;] == name),:]
        def calc_dilution_vol(row):
            _, reagent_transfer_row = self._get_dilution_transfer_rows(row) #the _ is water
            return reagent_transfer_row[self._products].sum()

        if dilution_rows.empty:
            dilution_aspirations = 0.0
        else:
            dilution_vols = dilution_rows.apply(lambda r: calc_dilution_vol(r),axis=1)
            dilution_aspirations = dilution_vols.sum()
        return dispenses - transfer_aspirations - dilution_aspirations
    
    def _is_valid_contents_sbs(self, row):
        &#39;&#39;&#39;
        tests if a row of contents sbs is valid
        params:  
            pd.Series row: has vol_t and vol  
        returns:  
            False if vol_t!=vol else True  
        Postconditions:  
            If vol_t!=vol the row will be printed  
            
        &#39;&#39;&#39;
        if not math.isclose(row[&#39;vol_t&#39;], row[&#39;vol&#39;]):
            print(&#39;&lt;&lt;controller&gt;&gt; contents error:&#39;)
            print(row.to_frame().T)
            print()
            return False
        return True


        if not sbs.loc[~sbs[&#39;flag&#39;]].empty:
            print(&#39;&lt;&lt;controller&gt;&gt; found some invalid contents. Displaying rows&#39;)
            container_index = sbs.loc[~sbs[&#39;flag&#39;]].index.get_level_values(&#39;container&#39;)
            print(sbs.loc[container_index])
        else:
            print(&#39;&lt;&lt;controller&gt;&gt; Well done! Product have correct ratios of reagents&#39;)

    def _create_contents_sbs(self):
        &#39;&#39;&#39;
        constructs a side by side frame from the history in well_history.tsv and the reaction
        df
        NOTE: completely ignores aspiration, but if all of your dispenses are correct, and your
        final contents are correct you&#39;re looking pretty good
        &#39;&#39;&#39;
        history = pd.read_csv(os.path.join(self.eve_files_path, &#39;well_history.tsv&#39;),na_filter=False,sep=&#39;\t&#39;).rename(columns={&#39;chemical&#39;:&#39;chem_name&#39;})
        disp_hist = history.loc[history[&#39;chem_name&#39;].astype(bool)]
        contents = disp_hist.groupby([&#39;container&#39;,&#39;chem_name&#39;]).sum()
        theoretical_his_list = []
        for _, row in self.rxn_df.loc[(self.rxn_df[&#39;op&#39;] == &#39;transfer&#39;) | \
                (self.rxn_df[&#39;op&#39;] == &#39;dilution&#39;)].iterrows():
            if row[&#39;op&#39;] == &#39;transfer&#39;:
                for product in self._products:
                    theoretical_his_list.append((product, row[product], row[&#39;chemical_name&#39;]))
            else: #row[&#39;op&#39;] == &#39;dilution&#39;
                water_transfer_row, reagent_transfer_row = self._get_dilution_transfer_rows(row) #the _ is water
                product_vols = water_transfer_row[self._products]
                target_reagent = product_vols.loc[~product_vols.apply(lambda x: \
                        math.isclose(x,0,abs_tol=1e-9))].index[0]
                theoretical_his_list.append((target_reagent, water_transfer_row[target_reagent], \
                        &#39;WaterC1.0&#39;))
                theoretical_his_list.append((target_reagent, \
                        reagent_transfer_row[target_reagent], \
                        reagent_transfer_row[&#39;chemical_name&#39;]))
        theoretical_his = pd.DataFrame(theoretical_his_list, \
                columns=[&#39;container&#39;, &#39;vol&#39;, &#39;chem_name&#39;])
        theoretical_contents = theoretical_his.groupby([&#39;container&#39;,&#39;chem_name&#39;]).sum()
        theoretical_contents = theoretical_contents.loc[~theoretical_contents[&#39;vol&#39;].apply(lambda x:\
                math.isclose(x,0))]
        sbs = theoretical_contents.join(contents, how=&#39;left&#39;,lsuffix=&#39;_t&#39;)
        return sbs

class AbstractPlateReader(ABC):
    &#39;&#39;&#39;
    This class is responsible for executing platereader commands. When instantiated, this
    class changes the config file  
    METHODS:  
        edit_layout(protocol_name, layout) void: changes the layout for a protocol  
        run_protocol(protocol_name, filename, data_path, layout) void: executes a protocol  
        shutdown() void: kills the platereader and restores default config  
        shake() void: shakes the platereader  
        exec_macro(macro, *args) void: low level method to send a command to platereader with
          arguments  
        load_reader_data(str filename, dict&lt;str:str&gt; loc_to_name, str path) tuple&lt;df, dict&gt;:
          reads the platereader data into a df and returns a dictionary of interesting 
          metadata.  
    ATTRIBUTES:
        str data_path: a linux path to where all the data is 
    &#39;&#39;&#39;
    SPECTRO_ROOT_PATH = None
    PROTOCOL_PATH = None

    def __init__(self, data_path):
        pass
        
    def exec_macro(self, macro, *args):
        &#39;&#39;&#39;
        sends a macro command to the platereader and blocks waiting for response. If response
        not ok, it&#39;ll crash and burn  
        params:  
            str macro: should be a macro from the documentation  
            *args: associated arguments of the macto  
        Postconditions:  
            The command has been sent to the PlateReader, if the return status was not 0 (good)  
            an error will be thrown  
        &#39;&#39;&#39;
        pass

    def shake(self):
        &#39;&#39;&#39;
        executes a shake
        &#39;&#39;&#39;
        pass

    def edit_layout(self, protocol_name, layout):
        &#39;&#39;&#39;
        params:  
            str protocol_name: the name of the protocol that will be edited  
            list&lt;str&gt; wells: the wells that you want to be used for the protocol ordered.
              (first will be X1, second X2 etc. If layout is all, all wells will be made X  
        Postcondtions:  
            The protocol has had it&#39;s layout updated to include only the wells specified  
        &#39;&#39;&#39;
        pass

    def run_protocol(self, protocol_name, filename, layout=None):
        r&#39;&#39;&#39;
        params:  
            str protocol_name: the name of the protocol that will be edited  
            list&lt;str&gt; layout: the wells that you want to be used for the protocol ordered.
              (first will be X1, second X2 etc. If not specified will not alter layout)  
        &#39;&#39;&#39;
        pass

    def shutdown(self):
        &#39;&#39;&#39;
        closes connection. Use this if you&#39;re done with this object at cleanup stage
        &#39;&#39;&#39;
        pass


    def load_reader_data(self, filename, loc_to_name):
        &#39;&#39;&#39;
        An new implementation should do following:  
        takes in the filename of a reader output and returns a dataframe with the scan data
        loaded, and a dictionary with relevant metadata.  
        This implementation generates 701 dummy 1s for each row
        params:  
            str filename: the name of the file to read  
            dict&lt;str:str&gt; loc_to_name: maps location to name of reaction  
        returns:  
            df: the scan data for that file  
            dict&lt;str:obj&gt;: holds the metadata  
                str filename: the filename as you passed in  
                int n_cycles: the number of cycles  
        &#39;&#39;&#39;
        print(&#39;&lt;&lt;Reader&gt;&gt; generating dummy data&#39;)
        wellnames = loc_to_name.values()
        metadata = {&#39;filename&#39;:filename, &#39;n_cycles&#39;:1}
        #.42 is a nice number to show up on plots. Also, 42 ...
        return pd.DataFrame(.42*np.ones((701,len(wellnames))), columns=wellnames), metadata

class DummyReader(AbstractPlateReader):
    &#39;&#39;&#39;
    Inherits from AbstractPlateReader, so it has all of it&#39;s methods, but doesn&#39;t actually do
    anything. useful for some simulations
    &#39;&#39;&#39;
    pass


class PlateReader(AbstractPlateReader):
    &#39;&#39;&#39;
    This class handles all platereader interactions. Inherits from the interface
    &#39;&#39;&#39;
    SPECTRO_ROOT_PATH = &#34;/mnt/c/Program Files/SPECTROstar Nano V5.50/&#34;
    PROTOCOL_PATH = r&#34;C:\Program Files\SPECTROstar Nano V5.50\User\Definit&#34;
    SPECTRO_DATA_PATH = &#34;/mnt/c/Hendricks Lab/Plate Reader Data Backup&#34;

    def __init__(self, data_path, simulate=False):
        self.data_path = data_path
        self.simulate = simulate
        if not os.path.exists(self.data_path):
            os.makedirs(self.data_path)
        self._set_config_attr(&#39;Configuration&#39;,&#39;SimulationMode&#39;, str(int(simulate)))
        self._set_config_attr(&#39;ControlApp&#39;,&#39;AsDDEserver&#39;, &#39;True&#39;)
        self.exec_macro(&#34;dummy&#34;)
        self.exec_macro(&#34;init&#34;)
        self.exec_macro(&#39;PlateOut&#39;)
        
    def exec_macro(self, macro, *args):
        &#39;&#39;&#39;
        sends a macro command to the platereader and blocks waiting for response. If response
        not ok, it&#39;ll crash and burn  
        params:  
            str macro: should be a macro from the documentation  
            *args: associated arguments of the macto  
        Postconditions:  
            The command has been sent to the PlateReader, if the return status was not 0 (good)
            an error will be thrown  
        &#39;&#39;&#39;
        exec_str = &#34;&#39;{}Cln/DDEClient.exe&#39; {}&#34;.format(self.SPECTRO_ROOT_PATH, macro)
        #add arguments
        for arg in args:
            exec_str += &#34; &#39;{}&#39;&#34;.format(arg)
        print(&#39;&lt;&lt;Reader&gt;&gt; executing: {}&#39;.format(exec_str))
        exit_code = os.system(exec_str)
        try:
            assert (exit_code == 0)
        except:
            if exit_code &lt; 1000:
                raise Exception(&#34;PlateReader rejected command Error&#34;)
            elif exit_code == 1000:
                raise Exception(&#34;PlateReader Nonexistent Protocol Name Error&#34;)
            elif exit_code == 2000:
                raise Exception(&#34;PlateReader Communication Error&#34;)
            else:
                raise Exception(&#34;PlateReader Error. Exited with code {}&#34;.format(exit_code))

    def shake(self):
        &#39;&#39;&#39;
        executes a shake
        &#39;&#39;&#39;
        macro = &#34;Shake&#34;
        shake_type = 2
        shake_freq = 300
        shake_time = 60
        self.exec_macro(macro, shake_type, shake_freq, shake_time)

    def load_reader_data(self,filename, loc_to_name):
        &#39;&#39;&#39;
        takes in the filename of a reader output and returns a dataframe with the scan data
        loaded, and a dictionary with relevant metadata.  
        params:  
            str filename: the name of the file to read  
            dict&lt;str:str&gt; loc_to_name: maps location to name of reaction  
        returns:  
            df: the scan data for that file  
            dict&lt;str:obj&gt;: holds the metadata  
                str filename: the filename as you passed in  
                int n_cycles: the number of cycles  
        &#39;&#39;&#39;
        if self.simulate:
            return super().load_reader_data(filename, loc_to_name) #return dummy data
        else:
            #parse the metadata
            start_i, metadata = self._parse_metadata(filename, self.data_path)
            # Read data ignoring first metadata lines
            df = pd.read_csv(os.path.join(self.data_path,filename), skiprows=start_i,
                    header=None,index_col=0,na_values=[&#34;       -&#34;],encoding = &#39;latin1&#39;).T
            headers = [loc_to_name[x[:-1]] for x in df.columns]
            df.columns = headers
            df.dropna(inplace=True)
            df = df.astype(float)
            return df, metadata

    def _parse_metadata(self, filename):
        &#39;&#39;&#39;
        parses the meta data of a platereader output, and returns a dataframe of the scans
        and a dictionary of parameters  
        params:  
            str filename: the name of the file to be read  
        returns:  
            int: the index to start reading the dataframe at  
            dict&lt;str:obj&gt;: holds the metadata  
                str filename: the filename as you passed in  
                int n_cycles: the number of cycles  
        &#39;&#39;&#39;
        found_start = False
        i = 0
        n_cycles = None
        line = &#39;dowhile&#39;
        with open(os.path.join(self.data_path,filename), &#39;r&#39;,encoding=&#39;latin1&#39;) as file:
            while not found_start and line != &#39;&#39;:
                line = file.readline()
                if bool(re.match(r&#39;No\. of Cycles:&#39;,line)):
                    #is number of cycles
                    n_cycles = int((re.search(r&#39;\d+&#39;, line)).group(0))
                if line[:6] == &#39;T[Â°C]:&#39;:
                    while not bool(re.match(&#39;\D\d&#39;,line)) and line != &#39;&#39;:
                        #is not of form A1/B03 etc
                        line = file.readline()
                        i += 1
                    i -= 1 #cause you will increment once more 
                    found_start = True
                i+=1
        assert (line != &#39;&#39;), &#34;corrupt reader file. ran out of file to read before finding a scanned well&#34;
        assert (n_cycles != None), &#34;corrupt reader file. num cycles not found.&#34;
        return i, {&#39;n_cycles&#39;:n_cycles,&#39;filename&#39;:filename}

    def edit_layout(self, protocol_name, layout):
        &#39;&#39;&#39;
        This protocol creates a temporary file, .temp_ot2_bmg_layout.lb
        in the SPECTROstar root. It is also possible (theoretically) to 
        send a literal &#39;edit_layout&#39; command, but this fails for long
        strings. (not sure why, maybe windows limited sized strings?
        but the file works). It removes the file after importing  
        params:  
            str protocol_name: the name of the protocol that will be edited  
            list&lt;str&gt; wells: the wells that you want to be used for the protocol ordered.
              (first will be X1, second X2 etc. If layout is all, all wells will be made X  
        Postcondtions:  
            The protocol has had it&#39;s layout updated to include only the wells specified  
        &#39;&#39;&#39;
        if layout == &#39;all&#39;:
            #get a list of all the wellanmes
            layout = [a+str(i) for a in list(&#39;ABCDEFGH&#39;) for i in range(1,13,1)]
        well_entries = []
        for i, well in enumerate(layout):
            well_entries.append(&#34;{}=X{}&#34;.format(well, i+1))
        filepath_lin = os.path.join(self.SPECTRO_ROOT_PATH,&#39;.temp_ot2_bmg_layout.lb&#39;)
        filepath_win = os.path.join(wslpath(self.SPECTRO_ROOT_PATH,&#39;w&#39;),&#39;.temp_ot2_bmg_layout.lb&#39;)
        with open(filepath_lin, &#39;w+&#39;) as layout:
            layout.write(&#39;EmptyLayout&#39;)
            for entry in well_entries:
                layout.write(&#34;\n{}&#34;.format(entry))
        self.exec_macro(&#39;ImportLayout&#39;, protocol_name, self.PROTOCOL_PATH, filepath_win)
        os.remove(filepath_lin)

    def run_protocol(self, protocol_name, filename, layout=None):
        r&#39;&#39;&#39;
        params:  
            str protocol_name: the name of the protocol that will be edited  
            list&lt;str&gt; layout: the wells that you want to be used for the protocol ordered.
              (first will be X1, second X2 etc. If not specified will not alter layout)  
        &#39;&#39;&#39;
        if layout:
            self.edit_layout(protocol_name, layout)
        macro = &#39;run&#39;
        #three &#39;&#39; are plate ids to pad. data_path specified once for ascii and once for other
        self.exec_macro(macro, protocol_name, self.PROTOCOL_PATH, wslpath(self.SPECTRO_DATA_PATH,&#39;w&#39;), &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, filename)
        #Note, here I am clearly passing in a save path for the file, but BMG tends to ignore
        #that, so we move it from the default landing zone to where I actually want it
        if not self.simulate:
            shutil.move(os.path.join(self.SPECTRO_DATA_PATH, &#34;{}.csv&#34;.format(filename)), 
                    os.path.join(self.data_path, &#34;{}.csv&#34;.format(filename)))


    def _set_config_attr(self, header, attr, val):
        &#39;&#39;&#39;
        opens the Spectrostar nano config file and replaces the value of attr under header
        with val
        There are better ways to build this function, but it&#39;s not something you&#39;ll use much
        so I&#39;m leaving it here  
        params:  
            str header: the header in the config file [header]  
            str attr: the attribute you want to change  
            obj val: the value to set the attribute to  
        Postconditions:  
            The SPECTROstar Nano.ini has had the attribute under the header overwritten with val
            or appended to end if it wasn&#39;t found   
        &#39;&#39;&#39;
        with open(os.path.join(self.SPECTRO_ROOT_PATH, r&#39;SPECTROstar Nano.ini&#39;), &#39;r&#39;) as config:
            file_str = config.readlines()
            write_str = &#39;&#39;
            header_exists = False
            i = 0
            while i &lt; len(file_str): #iterating through lines
                line = file_str[i]
                write_str += line
                if line[1:-2] == header:
                    header_exists = True#you found the appropriate header
                    i += 1
                    found_attr = False
                    line = file_str[i] #do
                    while &#39;[&#39; != line[0] and i &lt; len(file_str): #not a header and not EOF
                        if line[:line.find(&#39;=&#39;)] == attr:
                            found_attr = True
                            write_str += &#39;{}={}\n&#39;.format(attr, val)
                        else:
                            write_str += line
                        i += 1
                        if i &lt; len(file_str):
                            line = file_str[i]
                    if not found_attr:
                        write_str += &#39;{}={}\n&#39;.format(attr, val)
                else:
                    i += 1
            if not header_exists:
                write_str += &#39;[{}]\n&#39;.format(header)
                write_str += &#39;{}={}\n&#39;.format(attr, val)

        with open(os.path.join(self.SPECTRO_ROOT_PATH, r&#39;SPECTROstar Nano.ini&#39;), &#39;w+&#39;) as config:
            config.write(write_str)

    def shutdown(self):
        &#39;&#39;&#39;
        closes connection. Use this if you&#39;re done with this object at cleanup stage
        &#39;&#39;&#39;
        self.exec_macro(&#39;PlateIn&#39;)
        self.exec_macro(&#39;Terminate&#39;)
        self._set_config_attr(&#39;ControlApp&#39;,&#39;AsDDEserver&#39;,&#39;False&#39;)
        self._set_config_attr(&#39;ControlApp&#39;, &#39;DisablePlateCmds&#39;,&#39;False&#39;)
        self._set_config_attr(&#39;Configuration&#39;,&#39;SimulationMode&#39;, str(0))


if __name__ == &#39;__main__&#39;:
    SERVERADDR = &#34;10.25.16.146&#34;
    main(SERVERADDR)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="controller.init_parser"><code class="name flex">
<span>def <span class="ident">init_parser</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def init_parser():
    parser = argparse.ArgumentParser()
    mode_help_str = &#39;mode=auto runs in ml, mode=protocol or not supplied runs protocol&#39;
    parser.add_argument(&#39;-m&#39;,&#39;--mode&#39;,help=mode_help_str,default=&#39;protocol&#39;)
    parser.add_argument(&#39;-n&#39;,&#39;--name&#39;,help=&#39;the name of the google sheet&#39;)
    parser.add_argument(&#39;-c&#39;,&#39;--cache&#39;,help=&#39;flag. if supplied, uses cache&#39;,action=&#39;store_true&#39;)
    parser.add_argument(&#39;-s&#39;,&#39;--simulate&#39;,help=&#39;runs robot and pr in simulation mode&#39;,action=&#39;store_true&#39;)
    return parser</code></pre>
</details>
</dd>
<dt id="controller.launch_auto"><code class="name flex">
<span>def <span class="ident">launch_auto</span></span>(<span>serveraddr, rxn_sheet_name, use_cache, simulate)</span>
</code></dt>
<dd>
<div class="desc"><p>main function to launch an auto scientist that designs it's own experiments</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def launch_auto(serveraddr, rxn_sheet_name, use_cache, simulate):
    &#39;&#39;&#39;
    main function to launch an auto scientist that designs it&#39;s own experiments
    &#39;&#39;&#39;
    if not rxn_sheet_name:
        rxn_sheet_name = input(&#39;&lt;&lt;controller&gt;&gt; please input the sheet name &#39;)
    if not use_cache:
        #using the cache bypasses google docs communication and uses the last rxn you loaded
        use_cache = &#39;y&#39; == input(&#39;&lt;&lt;controller&gt;&gt; would you like to use spreadsheet cache? [yn] &#39;)
    my_ip = socket.gethostbyname(socket.gethostname())
    auto = AutoContr(rxn_sheet_name, my_ip, serveraddr, use_cache=use_cache)
    auto.run_simulation()
    if input(&#39;would you like to run on robot and pr? [yn] &#39;).lower() == &#39;y&#39;:
        #need a new model because last is fit to sim
        model = None
        auto.run_protocol(model, simulate)</code></pre>
</details>
</dd>
<dt id="controller.launch_protocol_exec"><code class="name flex">
<span>def <span class="ident">launch_protocol_exec</span></span>(<span>serveraddr, rxn_sheet_name=None, use_cache=False, simulate=False)</span>
</code></dt>
<dd>
<div class="desc"><p>main function to launch a controller and execute a protocol</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def launch_protocol_exec(serveraddr, rxn_sheet_name=None, use_cache=False, simulate=False):
    &#39;&#39;&#39;
    main function to launch a controller and execute a protocol
    &#39;&#39;&#39;
    #instantiate a controller
    if not rxn_sheet_name:
        rxn_sheet_name = input(&#39;&lt;&lt;controller&gt;&gt; please input the sheet name &#39;)
    if not use_cache:
        #using the cache bypasses google docs communication and uses the last rxn you loaded
        use_cache = &#39;y&#39; == input(&#39;&lt;&lt;controller&gt;&gt; would you like to use spreadsheet cache? [yn] &#39;)
    my_ip = socket.gethostbyname(socket.gethostname())
    controller = ProtocolExecutor(rxn_sheet_name, my_ip, serveraddr, use_cache=use_cache)

    tests_passed = controller.run_simulation()

    if tests_passed:
        if input(&#39;would you like to run the protocol? [yn] &#39;).lower() == &#39;y&#39;:
            controller.run_protocol(simulate)
    else:
        print(&#39;Failed Some Tests. Please fix your errors and try again&#39;)</code></pre>
</details>
</dd>
<dt id="controller.main"><code class="name flex">
<span>def <span class="ident">main</span></span>(<span>serveraddr)</span>
</code></dt>
<dd>
<div class="desc"><p>prompts for input and then calls appropriate launcher</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def main(serveraddr):
    &#39;&#39;&#39;
    prompts for input and then calls appropriate launcher
    &#39;&#39;&#39;
    parser = init_parser()
    args = parser.parse_args()
    if args.mode == &#39;protocol&#39;:
        print(&#39;launching in protocol mode&#39;)
        launch_protocol_exec(serveraddr,args.name,args.cache,args.simulate)
    elif args.mode == &#39;auto&#39;:
        print(&#39;launching in auto mode&#39;)
        launch_auto(serveraddr,args.name,args.cache,args.simulate)
    else:
        print(&#34;invalid argument to mode, &#39;{}&#39;&#34;.format(args.mode))
        parser.print_help()</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="controller.AbstractPlateReader"><code class="flex name class">
<span>class <span class="ident">AbstractPlateReader</span></span>
<span>(</span><span>data_path)</span>
</code></dt>
<dd>
<div class="desc"><p>This class is responsible for executing platereader commands. When instantiated, this
class changes the config file<br>
METHODS:<br>
edit_layout(protocol_name, layout) void: changes the layout for a protocol<br>
run_protocol(protocol_name, filename, data_path, layout) void: executes a protocol<br>
shutdown() void: kills the platereader and restores default config<br>
shake() void: shakes the platereader<br>
exec_macro(macro, *args) void: low level method to send a command to platereader with
arguments<br>
load_reader_data(str filename, dict<str:str> loc_to_name, str path) tuple<df, dict>:
reads the platereader data into a df and returns a dictionary of interesting
metadata.
</p>
<h2 id="attributes">Attributes</h2>
<p>str data_path: a linux path to where all the data is</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AbstractPlateReader(ABC):
    &#39;&#39;&#39;
    This class is responsible for executing platereader commands. When instantiated, this
    class changes the config file  
    METHODS:  
        edit_layout(protocol_name, layout) void: changes the layout for a protocol  
        run_protocol(protocol_name, filename, data_path, layout) void: executes a protocol  
        shutdown() void: kills the platereader and restores default config  
        shake() void: shakes the platereader  
        exec_macro(macro, *args) void: low level method to send a command to platereader with
          arguments  
        load_reader_data(str filename, dict&lt;str:str&gt; loc_to_name, str path) tuple&lt;df, dict&gt;:
          reads the platereader data into a df and returns a dictionary of interesting 
          metadata.  
    ATTRIBUTES:
        str data_path: a linux path to where all the data is 
    &#39;&#39;&#39;
    SPECTRO_ROOT_PATH = None
    PROTOCOL_PATH = None

    def __init__(self, data_path):
        pass
        
    def exec_macro(self, macro, *args):
        &#39;&#39;&#39;
        sends a macro command to the platereader and blocks waiting for response. If response
        not ok, it&#39;ll crash and burn  
        params:  
            str macro: should be a macro from the documentation  
            *args: associated arguments of the macto  
        Postconditions:  
            The command has been sent to the PlateReader, if the return status was not 0 (good)  
            an error will be thrown  
        &#39;&#39;&#39;
        pass

    def shake(self):
        &#39;&#39;&#39;
        executes a shake
        &#39;&#39;&#39;
        pass

    def edit_layout(self, protocol_name, layout):
        &#39;&#39;&#39;
        params:  
            str protocol_name: the name of the protocol that will be edited  
            list&lt;str&gt; wells: the wells that you want to be used for the protocol ordered.
              (first will be X1, second X2 etc. If layout is all, all wells will be made X  
        Postcondtions:  
            The protocol has had it&#39;s layout updated to include only the wells specified  
        &#39;&#39;&#39;
        pass

    def run_protocol(self, protocol_name, filename, layout=None):
        r&#39;&#39;&#39;
        params:  
            str protocol_name: the name of the protocol that will be edited  
            list&lt;str&gt; layout: the wells that you want to be used for the protocol ordered.
              (first will be X1, second X2 etc. If not specified will not alter layout)  
        &#39;&#39;&#39;
        pass

    def shutdown(self):
        &#39;&#39;&#39;
        closes connection. Use this if you&#39;re done with this object at cleanup stage
        &#39;&#39;&#39;
        pass


    def load_reader_data(self, filename, loc_to_name):
        &#39;&#39;&#39;
        An new implementation should do following:  
        takes in the filename of a reader output and returns a dataframe with the scan data
        loaded, and a dictionary with relevant metadata.  
        This implementation generates 701 dummy 1s for each row
        params:  
            str filename: the name of the file to read  
            dict&lt;str:str&gt; loc_to_name: maps location to name of reaction  
        returns:  
            df: the scan data for that file  
            dict&lt;str:obj&gt;: holds the metadata  
                str filename: the filename as you passed in  
                int n_cycles: the number of cycles  
        &#39;&#39;&#39;
        print(&#39;&lt;&lt;Reader&gt;&gt; generating dummy data&#39;)
        wellnames = loc_to_name.values()
        metadata = {&#39;filename&#39;:filename, &#39;n_cycles&#39;:1}
        #.42 is a nice number to show up on plots. Also, 42 ...
        return pd.DataFrame(.42*np.ones((701,len(wellnames))), columns=wellnames), metadata</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="controller.DummyReader" href="#controller.DummyReader">DummyReader</a></li>
<li><a title="controller.PlateReader" href="#controller.PlateReader">PlateReader</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="controller.AbstractPlateReader.PROTOCOL_PATH"><code class="name">var <span class="ident">PROTOCOL_PATH</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="controller.AbstractPlateReader.SPECTRO_ROOT_PATH"><code class="name">var <span class="ident">SPECTRO_ROOT_PATH</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="controller.AbstractPlateReader.edit_layout"><code class="name flex">
<span>def <span class="ident">edit_layout</span></span>(<span>self, protocol_name, layout)</span>
</code></dt>
<dd>
<div class="desc"><p>params:<br>
str protocol_name: the name of the protocol that will be edited<br>
list<str> wells: the wells that you want to be used for the protocol ordered.
(first will be X1, second X2 etc. If layout is all, all wells will be made X<br>
Postcondtions:<br>
The protocol has had it's layout updated to include only the wells specified</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def edit_layout(self, protocol_name, layout):
    &#39;&#39;&#39;
    params:  
        str protocol_name: the name of the protocol that will be edited  
        list&lt;str&gt; wells: the wells that you want to be used for the protocol ordered.
          (first will be X1, second X2 etc. If layout is all, all wells will be made X  
    Postcondtions:  
        The protocol has had it&#39;s layout updated to include only the wells specified  
    &#39;&#39;&#39;
    pass</code></pre>
</details>
</dd>
<dt id="controller.AbstractPlateReader.exec_macro"><code class="name flex">
<span>def <span class="ident">exec_macro</span></span>(<span>self, macro, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>sends a macro command to the platereader and blocks waiting for response. If response
not ok, it'll crash and burn<br>
params:<br>
str macro: should be a macro from the documentation<br>
*args: associated arguments of the macto<br>
Postconditions:<br>
The command has been sent to the PlateReader, if the return status was not 0 (good)<br>
an error will be thrown</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def exec_macro(self, macro, *args):
    &#39;&#39;&#39;
    sends a macro command to the platereader and blocks waiting for response. If response
    not ok, it&#39;ll crash and burn  
    params:  
        str macro: should be a macro from the documentation  
        *args: associated arguments of the macto  
    Postconditions:  
        The command has been sent to the PlateReader, if the return status was not 0 (good)  
        an error will be thrown  
    &#39;&#39;&#39;
    pass</code></pre>
</details>
</dd>
<dt id="controller.AbstractPlateReader.load_reader_data"><code class="name flex">
<span>def <span class="ident">load_reader_data</span></span>(<span>self, filename, loc_to_name)</span>
</code></dt>
<dd>
<div class="desc"><p>An new implementation should do following:<br>
takes in the filename of a reader output and returns a dataframe with the scan data
loaded, and a dictionary with relevant metadata.<br>
This implementation generates 701 dummy 1s for each row
params:<br>
str filename: the name of the file to read<br>
dict<str:str> loc_to_name: maps location to name of reaction<br>
returns:<br>
df: the scan data for that file<br>
dict<str:obj>: holds the metadata<br>
str filename: the filename as you passed in<br>
int n_cycles: the number of cycles</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_reader_data(self, filename, loc_to_name):
    &#39;&#39;&#39;
    An new implementation should do following:  
    takes in the filename of a reader output and returns a dataframe with the scan data
    loaded, and a dictionary with relevant metadata.  
    This implementation generates 701 dummy 1s for each row
    params:  
        str filename: the name of the file to read  
        dict&lt;str:str&gt; loc_to_name: maps location to name of reaction  
    returns:  
        df: the scan data for that file  
        dict&lt;str:obj&gt;: holds the metadata  
            str filename: the filename as you passed in  
            int n_cycles: the number of cycles  
    &#39;&#39;&#39;
    print(&#39;&lt;&lt;Reader&gt;&gt; generating dummy data&#39;)
    wellnames = loc_to_name.values()
    metadata = {&#39;filename&#39;:filename, &#39;n_cycles&#39;:1}
    #.42 is a nice number to show up on plots. Also, 42 ...
    return pd.DataFrame(.42*np.ones((701,len(wellnames))), columns=wellnames), metadata</code></pre>
</details>
</dd>
<dt id="controller.AbstractPlateReader.run_protocol"><code class="name flex">
<span>def <span class="ident">run_protocol</span></span>(<span>self, protocol_name, filename, layout=None)</span>
</code></dt>
<dd>
<div class="desc"><p>params:<br>
str protocol_name: the name of the protocol that will be edited<br>
list<str> layout: the wells that you want to be used for the protocol ordered.
(first will be X1, second X2 etc. If not specified will not alter layout)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_protocol(self, protocol_name, filename, layout=None):
    r&#39;&#39;&#39;
    params:  
        str protocol_name: the name of the protocol that will be edited  
        list&lt;str&gt; layout: the wells that you want to be used for the protocol ordered.
          (first will be X1, second X2 etc. If not specified will not alter layout)  
    &#39;&#39;&#39;
    pass</code></pre>
</details>
</dd>
<dt id="controller.AbstractPlateReader.shake"><code class="name flex">
<span>def <span class="ident">shake</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>executes a shake</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def shake(self):
    &#39;&#39;&#39;
    executes a shake
    &#39;&#39;&#39;
    pass</code></pre>
</details>
</dd>
<dt id="controller.AbstractPlateReader.shutdown"><code class="name flex">
<span>def <span class="ident">shutdown</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>closes connection. Use this if you're done with this object at cleanup stage</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def shutdown(self):
    &#39;&#39;&#39;
    closes connection. Use this if you&#39;re done with this object at cleanup stage
    &#39;&#39;&#39;
    pass</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="controller.AutoContr"><code class="flex name class">
<span>class <span class="ident">AutoContr</span></span>
<span>(</span><span>rxn_sheet_name, my_ip, server_ip, buff_size=4, use_cache=False, cache_path='Cache')</span>
</code></dt>
<dd>
<div class="desc"><p>This is a completely automated controller. It takes as input a layout sheet, and then does
it's own experiments, pulling data etc<br>
We're adding in self.rxn_df_template, which uses the same parsing style as rxn_df
but it's only a template, so we give it a new name and use self.rxn_df to change for the current batch we're trying to make</p>
<p>Note that init does not initialize the portal. This must be done explicitly or by calling
a run function that creates a portal. The portal is not passed to init because although
the code must not use more than one portal at a time, the portal may change over the
lifetime of the class
NOte that pr cannot be initialized until you know if you're simulating or not, so it
is instantiated in run</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AutoContr(Controller):
    &#39;&#39;&#39;
    This is a completely automated controller. It takes as input a layout sheet, and then does
    it&#39;s own experiments, pulling data etc  
    We&#39;re adding in self.rxn_df_template, which uses the same parsing style as rxn_df
    but it&#39;s only a template, so we give it a new name and use self.rxn_df to change for the current batch we&#39;re trying to make
    &#39;&#39;&#39;
    def __init__(self, rxn_sheet_name, my_ip, server_ip, buff_size=4, use_cache=False, cache_path=&#39;Cache&#39;):
        super().__init__(rxn_sheet_name, my_ip, server_ip, buff_size, use_cache, cache_path)
        self.rxn_df_template = self.rxn_df
        self.reagent_order = self.robo_params[&#39;reagent_df&#39;].index.to_numpy()
        self.well_count = 0 #used internally for unique wellnames
        self.batch_num = 0 #used internally for unique filenames

    def run_simulation(self):
        &#39;&#39;&#39;
        runs a full simulation of the protocol on local machine
        Temporarilly overwrites the self.server_ip with loopback, but will restore it at
        end of function  
        params:
            MLModel model: the model to use when training and predicting  
        Returns:  
            bool: True if all tests were passed  
        &#39;&#39;&#39;
        #cache some things before you overwrite them for the simulation
        stored_server_ip = self.server_ip
        stored_simulate = self.simulate
        self.server_ip = &#39;127.0.0.1&#39;
        self.simulate = True

        model = DummyMLModel(2, self.reagent_order.shape[0])

        print(&#39;&lt;&lt;controller&gt;&gt; ENTERING SIMULATION&#39;)
        port = 50000
        #launch an eve server in background for simulation purposes
        b = threading.Barrier(2,timeout=20)
        eve_thread = threading.Thread(target=launch_eve_server, kwargs={&#39;my_ip&#39;:&#39;&#39;,&#39;barrier&#39;:b},name=&#39;eve_thread&#39;)
        eve_thread.start()

        #do create a connection
        b.wait()
        self._run(port, True, model)

        #collect the eve thread
        eve_thread.join()

        #restore changed vars
        self.server_ip = stored_server_ip
        self.simulate = stored_simulate
        print(&#39;&lt;&lt;controller&gt;&gt; EXITING SIMULATION&#39;)
        return True

    def run_protocol(self, model, simulate=False, port=50000):
        &#39;&#39;&#39;
        The real deal. Input a server addr and port if you choose and protocol will be run  
        params:  
            str simulate: (this should never be used in normal operation. It is for debugging
              on the robot)  
            MLModel model: the model to use when training and predicting  
        NOTE: the simulate here is a little different than running run_simulation(). This simulate
          is sent to the robot to tell it to simulate the reaction, but that it all. The other
          simulate changes some things about how code is run from the controller
        &#39;&#39;&#39;
        print(&#39;&lt;&lt;controller&gt;&gt; RUNNING&#39;)
        if simulate and model == None:
            #you&#39;re simulating with a dummy model.
            print(&#39;&lt;&lt;controller&gt;&gt; running simulation with dummy ml&#39;)
            model = DummyMLModel(2, self.reagent_order.shape[0])
        self._run(port, simulate, model)
        print(&#39;&lt;&lt;controller&gt;&gt; EXITING&#39;)

    def _rename_products(self, rxn_df):
        &#39;&#39;&#39;
        required for class compatibility, but not used by the Auto
        &#39;&#39;&#39;
        pass

    def _get_product_df(self, products_to_labware):
        &#39;&#39;&#39;
        required for class compatibility, but not used by Auto
        TODO would be nice to return something that would blow up if accessed
        &#39;&#39;&#39;
        return np.nan

    @error_exit
    def _run(self, port, simulate, model):
        &#39;&#39;&#39;
        private function to run
        Returns:  
            bool: True if all tests were passed  
        &#39;&#39;&#39;
        self._init_pr(simulate)
        #create a connection
        sock = socket.socket(socket.AF_INET)
        sock.connect((self.server_ip, port))
        buffered_sock = BufferedSocket(sock, maxsize=1e9, timeout=None)
        print(&#34;&lt;&lt;controller&gt;&gt; connected&#34;)
        self.portal = Armchair(buffered_sock,&#39;controller&#39;,&#39;Armchair_Logs&#39;, buffsize=4)
        
        self.init_robot(simulate)
        while not model.quit:
            recipes = model.predict(5)
            #generate new wellnames for next batch
            wellnames = [self._generate_wellname() for i in range(recipes.shape[0])]
            #plan and execute a reaction
            self._create_samples(wellnames, recipes)
            #pull in the scan data
            scan_data = self._get_sample_data(wellnames, self.rxn_df[&#39;scan_filename&#39;]) 
            #train on scans
            model.train(scan_data.T.to_numpy(),recipes)
            self.batch_num += 1
        self.close_connection()
        self.pr.shutdown()
        return
    
    def _get_sample_data(self,wellnames, filename):
        &#39;&#39;&#39;
        TODO
        SKELETON
        scans a sample of wells specified by wellnames, and returns their spectra  
        params:  
            list&lt;str&gt; wellnames: the names of the wells to be scanned  
            str filename: the name of the file that holds the scans  
        returns:  
            df: n_wells, by size of spectra, the scan data.  
        &#39;&#39;&#39; 
        self._update_cached_locs(wellnames)
        pr_dict = {self._cached_reader_locs[wellname].loc: wellname for wellname in wellnames}
        unordered_data, metadata = self.pr.load_reader_data(filename, pr_dict)
        #reorder according to order of wellnames
        return unordered_data[wellnames]

    def _create_samples(self, wellnames, recipes):
        &#39;&#39;&#39;
        creates the desired reactions on the platereader  
        params:  
            str wellnames: the ordered names of the wells you want to produce  
            np.array recipes: shape(n_predicted, n_reagents). Holds ratios of all the reagents
              you can use for each reaction you want to perform  
        returns:  
            list&lt;str&gt; wellnames: the names of the wells produced ordered in accordance to the
              order of recipes
        &#39;&#39;&#39;
        self.portal.send_pack(&#39;init_containers&#39;, pd.DataFrame({&#39;labware&#39;:&#39;platereader&#39;,
                &#39;container&#39;:&#39;Well96&#39;, &#39;max_vol&#39;:200.0}, index=wellnames).to_dict())
        self.rxn_df = self._build_rxn_df(wellnames, recipes)
        self._products = wellnames
        self.execute_protocol_df()

    def _generate_wellname(self):
        &#39;&#39;&#39;
        returns:  
            str: a unique name for a new well
        &#39;&#39;&#39;
        wellname = &#34;autowell{}&#34;.format(self.well_count)
        self.well_count += 1
        return wellname

    def _get_rxn_max_vol(self, name, products):
        &#39;&#39;&#39;
        This is used right now because it&#39;s best I&#39;ve got. Ideally, you could drop the part 
        of init that constructs product_df
        &#39;&#39;&#39;
        return 200.0

    def _build_rxn_df(self,wellnames,recipes):
        &#39;&#39;&#39;
        used to construct a rxn_df for this batch of reactions
        TODO test bejesus out of this method
        TODO need some sort of key to map from name of reagent to index of the 
        recipes, and then mul by 200 and then lookup to mul by the percentages in the reagent df
        &#39;&#39;&#39;
        rxn_df = self.rxn_df_template.copy() #starting point. still neeeds products
        recipe_df = pd.DataFrame(recipes, index=wellnames, columns=self.reagent_order)
        def build_product_rows(row):
            &#39;&#39;&#39;
            params:  
                pd.Series row: a row of the template df  
            returns:  
                pd.Series: a row for the new df
            &#39;&#39;&#39;
            d = {}
            if row[&#39;op&#39;] == &#39;transfer&#39;:
                #is a transfer, so we want to lookup the volume of that reagent in recipe_df
                return recipe_df.loc[:, row[&#39;chemical_name&#39;]] * row[&#39;Template&#39;] * 200.0
            else:
                #if not a tranfer, we want to keep whatever value was there
                return pd.Series(row[&#39;Template&#39;], index=recipe_df.index)
        rxn_df = rxn_df.join(self.rxn_df_template.apply(build_product_rows, axis=1)).drop(
                columns=&#39;Template&#39;)
        rxn_df[&#39;scan_filename&#39;] = rxn_df[&#39;scan_filename&#39;].apply(lambda x: &#34;{}-{}&#34;.format(
                x, self.batch_num))
        rxn_df[&#39;plot_filename&#39;] = rxn_df[&#39;plot_filename&#39;].apply(lambda x: &#34;{}-{}&#34;.format(
                x, self.batch_num))
        return rxn_df

    def run_all_checks(self):
        found_errors = 0
        found_errors = max(found_errors, self.check_rxn_df())
        found_errors = max(found_errors, self.check_labware())
        found_errors = max(found_errors, self.check_reagents())
        if found_errors == 0:
            print(&#34;&lt;&lt;controller&gt;&gt; All prechecks passed!&#34;)
            return
        elif found_errors == 1:
            if &#39;y&#39;==input(&#34;&lt;&lt;controller&gt;&gt; Please check the above errors and if you would like to ignore them and continue enter &#39;y&#39; else any key&#34;):
                return
            else:
                raise Exception(&#39;Aborting base on user input&#39;)
        elif found_errors == 2:
            raise Exception(&#39;Critical Errors encountered during prechecks. Aborting&#39;)

    def check_rxn_df(self):
        &#39;&#39;&#39;
        Runs error checks on the reaction df to ensure that formating is correct. Illegal/Ill 
        Advised options are printed and if an error code is returned
        Will run through and check all rows, even if errors are found
        Preconditions:
            self.rxn_df is rxn_df template at this point  
        returns  
            int found_errors:  
                code:  
                0: OK.  
                1: Some Errors, but could run  
                2: Critical. Abort  
        &#39;&#39;&#39;
        #at this point self.rxn_df
        found_errors = super().check_rxn_df()
        reagent_ratios  = self.rxn_df.loc[self.rxn_df[&#39;op&#39;] == &#39;transfer&#39;,\
                [&#39;Template&#39;,&#39;chemical_name&#39;]].groupby(&#39;chemical_name&#39;).sum()[&#39;Template&#39;]
        has_invalid_ratio = reagent_ratios.apply(lambda x: not math.isclose(x, 1.0,
                abs_tol=1e-9)).any()
        if has_invalid_ratio:
            print(&#39;&lt;&lt;controller&gt;&gt; precheck error: invalid ratio of reagents (doesn\&#39;t add to 1)&#39;)
            print(&#39;  ratios were {}&#39;.format(reagent_ratios))
            found_errors = max(found_errors, 2)
        return found_errors</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="controller.Controller" href="#controller.Controller">Controller</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="controller.AutoContr.check_rxn_df"><code class="name flex">
<span>def <span class="ident">check_rxn_df</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Runs error checks on the reaction df to ensure that formating is correct. Illegal/Ill
Advised options are printed and if an error code is returned
Will run through and check all rows, even if errors are found</p>
<h2 id="preconditions">Preconditions</h2>
<p>self.rxn_df is rxn_df template at this point<br>
returns<br>
int found_errors:<br>
code:<br>
0: OK.<br>
1: Some Errors, but could run<br>
2: Critical. Abort</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_rxn_df(self):
    &#39;&#39;&#39;
    Runs error checks on the reaction df to ensure that formating is correct. Illegal/Ill 
    Advised options are printed and if an error code is returned
    Will run through and check all rows, even if errors are found
    Preconditions:
        self.rxn_df is rxn_df template at this point  
    returns  
        int found_errors:  
            code:  
            0: OK.  
            1: Some Errors, but could run  
            2: Critical. Abort  
    &#39;&#39;&#39;
    #at this point self.rxn_df
    found_errors = super().check_rxn_df()
    reagent_ratios  = self.rxn_df.loc[self.rxn_df[&#39;op&#39;] == &#39;transfer&#39;,\
            [&#39;Template&#39;,&#39;chemical_name&#39;]].groupby(&#39;chemical_name&#39;).sum()[&#39;Template&#39;]
    has_invalid_ratio = reagent_ratios.apply(lambda x: not math.isclose(x, 1.0,
            abs_tol=1e-9)).any()
    if has_invalid_ratio:
        print(&#39;&lt;&lt;controller&gt;&gt; precheck error: invalid ratio of reagents (doesn\&#39;t add to 1)&#39;)
        print(&#39;  ratios were {}&#39;.format(reagent_ratios))
        found_errors = max(found_errors, 2)
    return found_errors</code></pre>
</details>
</dd>
<dt id="controller.AutoContr.run_protocol"><code class="name flex">
<span>def <span class="ident">run_protocol</span></span>(<span>self, model, simulate=False, port=50000)</span>
</code></dt>
<dd>
<div class="desc"><p>The real deal. Input a server addr and port if you choose and protocol will be run<br>
params:<br>
str simulate: (this should never be used in normal operation. It is for debugging
on the robot)<br>
MLModel model: the model to use when training and predicting<br>
NOTE: the simulate here is a little different than running run_simulation(). This simulate
is sent to the robot to tell it to simulate the reaction, but that it all. The other
simulate changes some things about how code is run from the controller</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_protocol(self, model, simulate=False, port=50000):
    &#39;&#39;&#39;
    The real deal. Input a server addr and port if you choose and protocol will be run  
    params:  
        str simulate: (this should never be used in normal operation. It is for debugging
          on the robot)  
        MLModel model: the model to use when training and predicting  
    NOTE: the simulate here is a little different than running run_simulation(). This simulate
      is sent to the robot to tell it to simulate the reaction, but that it all. The other
      simulate changes some things about how code is run from the controller
    &#39;&#39;&#39;
    print(&#39;&lt;&lt;controller&gt;&gt; RUNNING&#39;)
    if simulate and model == None:
        #you&#39;re simulating with a dummy model.
        print(&#39;&lt;&lt;controller&gt;&gt; running simulation with dummy ml&#39;)
        model = DummyMLModel(2, self.reagent_order.shape[0])
    self._run(port, simulate, model)
    print(&#39;&lt;&lt;controller&gt;&gt; EXITING&#39;)</code></pre>
</details>
</dd>
<dt id="controller.AutoContr.run_simulation"><code class="name flex">
<span>def <span class="ident">run_simulation</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>runs a full simulation of the protocol on local machine
Temporarilly overwrites the self.server_ip with loopback, but will restore it at
end of function<br>
params:
MLModel model: the model to use when training and predicting<br>
Returns:<br>
bool: True if all tests were passed</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_simulation(self):
    &#39;&#39;&#39;
    runs a full simulation of the protocol on local machine
    Temporarilly overwrites the self.server_ip with loopback, but will restore it at
    end of function  
    params:
        MLModel model: the model to use when training and predicting  
    Returns:  
        bool: True if all tests were passed  
    &#39;&#39;&#39;
    #cache some things before you overwrite them for the simulation
    stored_server_ip = self.server_ip
    stored_simulate = self.simulate
    self.server_ip = &#39;127.0.0.1&#39;
    self.simulate = True

    model = DummyMLModel(2, self.reagent_order.shape[0])

    print(&#39;&lt;&lt;controller&gt;&gt; ENTERING SIMULATION&#39;)
    port = 50000
    #launch an eve server in background for simulation purposes
    b = threading.Barrier(2,timeout=20)
    eve_thread = threading.Thread(target=launch_eve_server, kwargs={&#39;my_ip&#39;:&#39;&#39;,&#39;barrier&#39;:b},name=&#39;eve_thread&#39;)
    eve_thread.start()

    #do create a connection
    b.wait()
    self._run(port, True, model)

    #collect the eve thread
    eve_thread.join()

    #restore changed vars
    self.server_ip = stored_server_ip
    self.simulate = stored_simulate
    print(&#39;&lt;&lt;controller&gt;&gt; EXITING SIMULATION&#39;)
    return True</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="controller.Controller" href="#controller.Controller">Controller</a></b></code>:
<ul class="hlist">
<li><code><a title="controller.Controller.ChemCacheEntry" href="#controller.Controller.ChemCacheEntry">ChemCacheEntry</a></code></li>
<li><code><a title="controller.Controller.check_labware" href="#controller.Controller.check_labware">check_labware</a></code></li>
<li><code><a title="controller.Controller.check_reagents" href="#controller.Controller.check_reagents">check_reagents</a></code></li>
<li><code><a title="controller.Controller.close_connection" href="#controller.Controller.close_connection">close_connection</a></code></li>
<li><code><a title="controller.Controller.execute_protocol_df" href="#controller.Controller.execute_protocol_df">execute_protocol_df</a></code></li>
<li><code><a title="controller.Controller.init_robot" href="#controller.Controller.init_robot">init_robot</a></code></li>
<li><code><a title="controller.Controller.plot_LAM_overlay" href="#controller.Controller.plot_LAM_overlay">plot_LAM_overlay</a></code></li>
<li><code><a title="controller.Controller.plot_kin_subplots" href="#controller.Controller.plot_kin_subplots">plot_kin_subplots</a></code></li>
<li><code><a title="controller.Controller.plot_single_kin" href="#controller.Controller.plot_single_kin">plot_single_kin</a></code></li>
<li><code><a title="controller.Controller.run_all_checks" href="#controller.Controller.run_all_checks">run_all_checks</a></code></li>
<li><code><a title="controller.Controller.translate_wellmap" href="#controller.Controller.translate_wellmap">translate_wellmap</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="controller.Controller"><code class="flex name class">
<span>class <span class="ident">Controller</span></span>
<span>(</span><span>rxn_sheet_name, my_ip, server_ip, buff_size=4, use_cache=False, cache_path='Cache')</span>
</code></dt>
<dd>
<div class="desc"><p>This class is a shared interface for the ProtocolExecutor and the <strong><em>_</em>_AI</strong>Executor___
</p>
<p>ATTRIBUTES:<br>
armchair.Armchair portal: the Armchair object to ship files across<br>
rxn_sheet_name: the name of the reaction sheet<br>
str cache_path: path to a directory for all cache files<br>
bool use_cache: read from cache if possible<br>
str eve_files_path: the path to put files from eve<br>
str debug_path: the path to place debugging information<br>
str my_ip: the ip of this controller<br>
str server_ip: the ip of the server. This is modified for simulation, but returned to
original state at the end of simulation<br>
dict<str:object> robo_params: convenient place for the parameters for the robot<br>
+ bool using_temp_ctrl: True if the temperature control is being used<br>
+ float temp: the temperature in celcius to keep the temp control at<br>
+ df reagent_df: holds information about reagents<br>
+ float conc: the concentration<br>
+ str loc: location on labware<br>
+ int deck_pos: the position on the deck<br>
+ float mass: the mass of the tube with reagent and cap<br>
dict<str:str> instruments: maps 'left' and 'right' to the pipette names<br>
df labware_df<br>
+ int deck_pos: the position of the labware on the deck<br>
+ str name: the name of the labware<br>
+ str first_usable: a location of the first usable tip/well on labware<br>
+ list<str> empty_list: a list of locations on the labware that have empty tubes<br>
df product_df: This information is used to figure out where to put chemicals<br>
+ INDEX<br>
+ str chemical_name: the name of the chemical<br>
+ COLS<br>
+ str labware: the requested labware you want to put it in<br>
+ str container: the container you want to put it in<br>
+ float max_vol: the maximum volume you will put in the container<br>
bool simulate: whether a simulation is being run or not. False by default. changed true
temporarily when simulating<br>
int buff_size: this is the size of the buffer between Armchair commands. It's size
corresponds to the number of commands you want to pile up in the socket buffer.
Really more for developers<br>
PRIVATE ATTRS:<br>
dict<str:ChemCacheEntry> _cached_reader_locs: chemical information from the robot
ChemCacheEntry is a named tuple with below attributes
The tuple has following structure:<br>
str loc: the loc of the well on it's labware (translated to human if on pr)<br>
int deck_pos: the position of the labware it's on<br>
float vol: the volume in the container<br>
float aspiratible_vol: the volume minus dead vol<br>
CONSTANTS:<br>
bidict<str:tuple\<str,str>> PLATEREADER_INDEX_TRANSLATOR: used to translate from locs on
wellplate to locs on the opentrons object. Use a json viewer for more structural info<br>
METHODS:<br>
run_protocol(simulate, port) void: both args have good defaults. simulate can be used to
simulate on the plate reader and robot, but generally you want false to actually run
the protocol. port can be configured, but 50000 is default<br>
run_simulation() int: runs a simulation on local machine. Tries plate reader, but
not necessary. returns an error code<br>
close_connection() void: automatically called by run_protocol. used to terminate a
connection with eve<br>
init_robot(simulate): used to initialize the robot. called automatically in run. simulate
is the same as used by the robot protocol<br>
translate_wellmap() void: used to convert a wellmap.tsv from robot to wells locs
that correspond to platereader
</p>
<p>Note that init does not initialize the portal. This must be done explicitly or by calling
a run function that creates a portal. The portal is not passed to init because although
the code must not use more than one portal at a time, the portal may change over the
lifetime of the class
NOte that pr cannot be initialized until you know if you're simulating or not, so it
is instantiated in run</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Controller(ABC):
    &#39;&#39;&#39;
    This class is a shared interface for the ProtocolExecutor and the ______AI__Executor___  

    ATTRIBUTES:  
        armchair.Armchair portal: the Armchair object to ship files across  
        rxn_sheet_name: the name of the reaction sheet  
        str cache_path: path to a directory for all cache files  
        bool use_cache: read from cache if possible  
        str eve_files_path: the path to put files from eve  
        str debug_path: the path to place debugging information  
        str my_ip: the ip of this controller  
        str server_ip: the ip of the server. This is modified for simulation, but returned to 
          original state at the end of simulation  
        dict&lt;str:object&gt; robo_params: convenient place for the parameters for the robot  
            + bool using_temp_ctrl: True if the temperature control is being used  
            + float temp: the temperature in celcius to keep the temp control at  
            + df reagent_df: holds information about reagents  
                + float conc: the concentration  
                + str loc: location on labware  
                + int deck_pos: the position on the deck  
                + float mass: the mass of the tube with reagent and cap  
            dict&lt;str:str&gt; instruments: maps &#39;left&#39; and &#39;right&#39; to the pipette names  
            df labware_df  
                + int deck_pos: the position of the labware on the deck  
                + str name: the name of the labware  
                + str first_usable: a location of the first usable tip/well on labware  
                + list&lt;str&gt; empty_list: a list of locations on the labware that have empty tubes  
            df product_df: This information is used to figure out where to put chemicals  
                + INDEX  
                + str chemical_name: the name of the chemical  
                + COLS  
                + str labware: the requested labware you want to put it in  
                + str container: the container you want to put it in  
                + float max_vol: the maximum volume you will put in the container  
        bool simulate: whether a simulation is being run or not. False by default. changed true 
          temporarily when simulating  
        int buff_size: this is the size of the buffer between Armchair commands. It&#39;s size
          corresponds to the number of commands you want to pile up in the socket buffer.
          Really more for developers  
    PRIVATE ATTRS:  
        dict&lt;str:ChemCacheEntry&gt; _cached_reader_locs: chemical information from the robot
            ChemCacheEntry is a named tuple with below attributes
            The tuple has following structure:  
            str loc: the loc of the well on it&#39;s labware (translated to human if on pr)  
            int deck_pos: the position of the labware it&#39;s on  
            float vol: the volume in the container  
            float aspiratible_vol: the volume minus dead vol  
    CONSTANTS:  
        bidict&lt;str:tuple&lt;str,str&gt;&gt; PLATEREADER_INDEX_TRANSLATOR: used to translate from locs on
        wellplate to locs on the opentrons object. Use a json viewer for more structural info  
    METHODS:  
        run_protocol(simulate, port) void: both args have good defaults. simulate can be used to
          simulate on the plate reader and robot, but generally you want false to actually run
          the protocol. port can be configured, but 50000 is default  
        run_simulation() int: runs a simulation on local machine. Tries plate reader, but
          not necessary. returns an error code  
        close_connection() void: automatically called by run_protocol. used to terminate a 
          connection with eve  
        init_robot(simulate): used to initialize the robot. called automatically in run. simulate
          is the same as used by the robot protocol  
        translate_wellmap() void: used to convert a wellmap.tsv from robot to wells locs 
          that correspond to platereader  
    &#39;&#39;&#39;
    #this has two keys, &#39;deck_pos&#39; and &#39;loc&#39;. They map to the plate reader and the loc on that plate
    #reader given a regular loc for a 96well plate.
    #Please do not read this. paste it into a nice json viewer.
    PLATEREADER_INDEX_TRANSLATOR = bidict({&#39;A1&#39;: (&#39;E1&#39;, &#39;platereader4&#39;), &#39;A2&#39;: (&#39;D1&#39;, &#39;platereader4&#39;), &#39;A3&#39;: (&#39;C1&#39;, &#39;platereader4&#39;), &#39;A4&#39;: (&#39;B1&#39;, &#39;platereader4&#39;), &#39;A5&#39;: (&#39;A1&#39;, &#39;platereader4&#39;), &#39;A12&#39;: (&#39;A1&#39;, &#39;platereader7&#39;), &#39;A11&#39;: (&#39;B1&#39;, &#39;platereader7&#39;), &#39;A10&#39;: (&#39;C1&#39;, &#39;platereader7&#39;), &#39;A9&#39;: (&#39;D1&#39;, &#39;platereader7&#39;), &#39;A8&#39;: (&#39;E1&#39;, &#39;platereader7&#39;), &#39;A7&#39;: (&#39;F1&#39;, &#39;platereader7&#39;), &#39;A6&#39;: (&#39;G1&#39;, &#39;platereader7&#39;), &#39;B1&#39;: (&#39;E2&#39;, &#39;platereader4&#39;), &#39;B2&#39;: (&#39;D2&#39;, &#39;platereader4&#39;), &#39;B3&#39;: (&#39;C2&#39;, &#39;platereader4&#39;), &#39;B4&#39;: (&#39;B2&#39;, &#39;platereader4&#39;), &#39;B5&#39;: (&#39;A2&#39;, &#39;platereader4&#39;), &#39;B6&#39;: (&#39;G2&#39;, &#39;platereader7&#39;), &#39;B7&#39;: (&#39;F2&#39;, &#39;platereader7&#39;), &#39;B8&#39;: (&#39;E2&#39;, &#39;platereader7&#39;), &#39;B9&#39;: (&#39;D2&#39;, &#39;platereader7&#39;), &#39;B10&#39;: (&#39;C2&#39;, &#39;platereader7&#39;), &#39;B11&#39;: (&#39;B2&#39;, &#39;platereader7&#39;), &#39;B12&#39;: (&#39;A2&#39;, &#39;platereader7&#39;), &#39;C1&#39;: (&#39;E3&#39;, &#39;platereader4&#39;), &#39;C2&#39;: (&#39;D3&#39;, &#39;platereader4&#39;), &#39;C3&#39;: (&#39;C3&#39;, &#39;platereader4&#39;), &#39;C4&#39;: (&#39;B3&#39;, &#39;platereader4&#39;), &#39;C5&#39;: (&#39;A3&#39;, &#39;platereader4&#39;), &#39;C6&#39;: (&#39;G3&#39;, &#39;platereader7&#39;), &#39;C7&#39;: (&#39;F3&#39;, &#39;platereader7&#39;), &#39;C8&#39;: (&#39;E3&#39;, &#39;platereader7&#39;), &#39;C9&#39;: (&#39;D3&#39;, &#39;platereader7&#39;), &#39;C10&#39;: (&#39;C3&#39;, &#39;platereader7&#39;), &#39;C11&#39;: (&#39;B3&#39;, &#39;platereader7&#39;), &#39;C12&#39;: (&#39;A3&#39;, &#39;platereader7&#39;), &#39;D1&#39;: (&#39;E4&#39;, &#39;platereader4&#39;), &#39;D2&#39;: (&#39;D4&#39;, &#39;platereader4&#39;), &#39;D3&#39;: (&#39;C4&#39;, &#39;platereader4&#39;), &#39;D4&#39;: (&#39;B4&#39;, &#39;platereader4&#39;), &#39;D5&#39;: (&#39;A4&#39;, &#39;platereader4&#39;), &#39;D6&#39;: (&#39;G4&#39;, &#39;platereader7&#39;), &#39;D7&#39;: (&#39;F4&#39;, &#39;platereader7&#39;), &#39;D8&#39;: (&#39;E4&#39;, &#39;platereader7&#39;), &#39;D9&#39;: (&#39;D4&#39;, &#39;platereader7&#39;), &#39;D10&#39;: (&#39;C4&#39;, &#39;platereader7&#39;), &#39;D11&#39;: (&#39;B4&#39;, &#39;platereader7&#39;), &#39;D12&#39;: (&#39;A4&#39;, &#39;platereader7&#39;), &#39;E1&#39;: (&#39;E5&#39;, &#39;platereader4&#39;), &#39;E2&#39;: (&#39;D5&#39;, &#39;platereader4&#39;), &#39;E3&#39;: (&#39;C5&#39;, &#39;platereader4&#39;), &#39;E4&#39;: (&#39;B5&#39;, &#39;platereader4&#39;), &#39;E5&#39;: (&#39;A5&#39;, &#39;platereader4&#39;), &#39;E6&#39;: (&#39;G5&#39;, &#39;platereader7&#39;), &#39;E7&#39;: (&#39;F5&#39;, &#39;platereader7&#39;), &#39;E8&#39;: (&#39;E5&#39;, &#39;platereader7&#39;), &#39;E9&#39;: (&#39;D5&#39;, &#39;platereader7&#39;), &#39;E10&#39;: (&#39;C5&#39;, &#39;platereader7&#39;), &#39;E11&#39;: (&#39;B5&#39;, &#39;platereader7&#39;), &#39;E12&#39;: (&#39;A5&#39;, &#39;platereader7&#39;), &#39;F1&#39;: (&#39;E6&#39;, &#39;platereader4&#39;), &#39;F2&#39;: (&#39;D6&#39;, &#39;platereader4&#39;), &#39;F3&#39;: (&#39;C6&#39;, &#39;platereader4&#39;), &#39;F4&#39;: (&#39;B6&#39;, &#39;platereader4&#39;), &#39;F5&#39;: (&#39;A6&#39;, &#39;platereader4&#39;), &#39;F6&#39;: (&#39;G6&#39;, &#39;platereader7&#39;), &#39;F7&#39;: (&#39;F6&#39;, &#39;platereader7&#39;), &#39;F8&#39;: (&#39;E6&#39;, &#39;platereader7&#39;), &#39;F9&#39;: (&#39;D6&#39;, &#39;platereader7&#39;), &#39;F10&#39;: (&#39;C6&#39;, &#39;platereader7&#39;), &#39;F11&#39;: (&#39;B6&#39;, &#39;platereader7&#39;), &#39;F12&#39;: (&#39;A6&#39;, &#39;platereader7&#39;), &#39;G1&#39;: (&#39;E7&#39;, &#39;platereader4&#39;), &#39;G2&#39;: (&#39;D7&#39;, &#39;platereader4&#39;), &#39;G3&#39;: (&#39;C7&#39;, &#39;platereader4&#39;), &#39;G4&#39;: (&#39;B7&#39;, &#39;platereader4&#39;), &#39;G5&#39;: (&#39;A7&#39;, &#39;platereader4&#39;), &#39;G6&#39;: (&#39;G7&#39;, &#39;platereader7&#39;), &#39;G7&#39;: (&#39;F7&#39;, &#39;platereader7&#39;), &#39;G8&#39;: (&#39;E7&#39;, &#39;platereader7&#39;), &#39;G9&#39;: (&#39;D7&#39;, &#39;platereader7&#39;), &#39;G10&#39;: (&#39;C7&#39;, &#39;platereader7&#39;), &#39;G11&#39;: (&#39;B7&#39;, &#39;platereader7&#39;), &#39;G12&#39;: (&#39;A7&#39;, &#39;platereader7&#39;), &#39;H1&#39;: (&#39;E8&#39;, &#39;platereader4&#39;), &#39;H2&#39;: (&#39;D8&#39;, &#39;platereader4&#39;), &#39;H3&#39;: (&#39;C8&#39;, &#39;platereader4&#39;), &#39;H4&#39;: (&#39;B8&#39;, &#39;platereader4&#39;), &#39;H5&#39;: (&#39;A8&#39;, &#39;platereader4&#39;), &#39;H6&#39;: (&#39;G8&#39;, &#39;platereader7&#39;), &#39;H7&#39;: (&#39;F8&#39;, &#39;platereader7&#39;), &#39;H8&#39;: (&#39;E8&#39;, &#39;platereader7&#39;), &#39;H9&#39;: (&#39;D8&#39;, &#39;platereader7&#39;), &#39;H10&#39;: (&#39;C8&#39;, &#39;platereader7&#39;), &#39;H11&#39;: (&#39;B8&#39;, &#39;platereader7&#39;), &#39;H12&#39;: (&#39;A8&#39;, &#39;platereader7&#39;)})

    ChemCacheEntry = namedtuple(&#39;ChemCacheEntry&#39;,[&#39;loc&#39;,&#39;deck_pos&#39;,&#39;vol&#39;,&#39;aspirable_vol&#39;])

    def __init__(self, rxn_sheet_name, my_ip, server_ip, buff_size=4, use_cache=False, cache_path=&#39;Cache&#39;):
        &#39;&#39;&#39;
        Note that init does not initialize the portal. This must be done explicitly or by calling
        a run function that creates a portal. The portal is not passed to init because although
        the code must not use more than one portal at a time, the portal may change over the 
        lifetime of the class
        NOte that pr cannot be initialized until you know if you&#39;re simulating or not, so it
        is instantiated in run
        &#39;&#39;&#39;
        #set according to input
        self.cache_path=cache_path
        self._make_cache()
        self.use_cache = use_cache
        self.my_ip = my_ip
        self.server_ip = server_ip
        self.buff_size=4
        self.simulate = False #by default will be changed if a simulation is run
        self._cached_reader_locs = {} #maps wellname to loc on platereader
        #this will be gradually filled
        self.robo_params = {}
        #necessary helper params
        self._check_cache_metadata(rxn_sheet_name)
        credentials = self._init_credentials(rxn_sheet_name)
        wks_key = self._get_wks_key(credentials, rxn_sheet_name)
        rxn_spreadsheet = self._open_sheet(rxn_sheet_name, credentials)
        header_data = self._download_sheet(rxn_spreadsheet,0)
        input_data = self._download_sheet(rxn_spreadsheet,1)
        deck_data = self._download_sheet(rxn_spreadsheet, 2)
        self._init_robo_header_params(header_data)
        self._make_out_dirs(header_data)
        self.rxn_df = self._load_rxn_df(input_data)
        self._query_reagents(wks_key, credentials)
        raw_reagent_df = self._download_reagent_data(wks_key, credentials)#will be replaced soon
        #with a parsed reagent_df. This is exactly as is pulled from gsheets
        empty_containers = self._get_empty_containers(raw_reagent_df)
        self.robo_params[&#39;dry_containers&#39;] = self._get_dry_containers(raw_reagent_df)
        products_to_labware = self._get_products_to_labware(input_data)
        self.robo_params[&#39;reagent_df&#39;] = self._parse_raw_reagent_df(raw_reagent_df)
        self.robo_params[&#39;instruments&#39;] = self._get_instrument_dict(deck_data)
        self.robo_params[&#39;labware_df&#39;] = self._get_labware_df(deck_data, empty_containers)
        self.robo_params[&#39;product_df&#39;] = self._get_product_df(products_to_labware)
        self.run_all_checks()

    def _check_cache_metadata(self, rxn_sheet_name):
        &#39;&#39;&#39;
        Checks a file, .metadata.txt with the cache path.
        Postconditions:
            If use_cache is true:
                reads .metadata.txt
                asserts that the rxn_sheet_name matches the name in sheet
                prints the timestamp that the cache was last written
            If use_cache is false:
                writes .metadata.txt with the sheet name and a timestamp
        &#39;&#39;&#39;
        if self.use_cache:
            assert (os.path.exists(os.path.join(self.cache_path, &#39;.metadata.json&#39;))), \
                    &#34;tried to read metadata in cache, but file does not exist&#34;
            with open(os.path.join(self.cache_path, &#39;.metadata.json&#39;), &#39;r&#39;) as file:
                metadata = json.load(file)
            assert (metadata[&#39;name&#39;] == rxn_sheet_name), &#34;desired sheet was, &#39;{}&#39;, but cached data is for &#39;{}&#39;&#34;.format(rxn_sheet_name, metadata[&#39;name&#39;])
            print(&#34;&lt;&lt;controller&gt;&gt; using cached data for &#39;{}&#39;, last updated &#39;{}&#39;&#34;.format(
                    metadata[&#39;name&#39;],metadata[&#39;timestamp&#39;]))
        else:
            metadata = {&#39;timestamp&#39;:datetime.now().strftime(&#39;%d-%b-%Y %H:%M:%S:%f&#39;),
                        &#39;name&#39;:rxn_sheet_name}
            with open(os.path.join(self.cache_path, &#39;.metadata.json&#39;), &#39;w&#39;) as file:
                json.dump(metadata, file)

    def _get_wks_key_pairs(self, credentials, rxn_sheet_name):
        &#39;&#39;&#39;
        open and search a sheet that tells you which sheet is associated with the reaction
        Or read from cache if cache is enabled  
        params:  
            ServiceAccountCredentials credentials: to access the sheets  
            str rxn_sheet_name: the name of sheet  
        returns:  
            list&lt;list&lt;str&gt;&gt; name_key_pairs: the data in the wks_key spreadsheet  
        Postconditions:  
            If cached data could not be found, will dump spreadsheet data to name_key_pairs.pkl 
            in cache path  
        &#39;&#39;&#39;
        if self.use_cache:
            #load cache
            with open(os.path.join(self.cache_path, &#39;name_key_pairs.pkl&#39;), &#39;rb&#39;) as name_key_pairs_cache:
                name_key_pairs = dill.load(name_key_pairs_cache)
        else:
            #pull down data
            gc = gspread.authorize(credentials)
            name_key_wks = gc.open_by_url(&#39;https://docs.google.com/spreadsheets/d/1m2Uzk8z-qn2jJ2U1NHkeN7CJ8TQpK3R0Ai19zlAB1Ew/edit#gid=0&#39;).get_worksheet(0)
            name_key_pairs = name_key_wks.get_all_values() #list&lt;list&lt;str name, str key&gt;&gt;
            #Note the key is a unique identifier that can be used to access the sheet
            #d2g uses it to access the worksheet
            #dump to cache
            with open(os.path.join(self.cache_path, &#39;name_key_pairs.pkl&#39;), &#39;wb&#39;) as name_key_pairs_cache:
                dill.dump(name_key_pairs, name_key_pairs_cache)
        return name_key_pairs

    def _init_pr(self,simulate):
        try:
            self.pr = PlateReader(os.path.join(self.out_path, &#39;pr_data&#39;),simulate)
        except:
            print(&#39;&lt;&lt;controller&gt;&gt; failed to initialize platereader, initializing dummy reader&#39;)
            self.pr = DummyReader(os.path.join(self.out_path, &#39;pr_data&#39;))

    def _download_sheet(self, rxn_spreadsheet, index):
        &#39;&#39;&#39;
        pulls down the sheet at the index  
        params:  
            gspread.Spreadsheet rxn_spreadsheet: the sheet with all the reactions  
            int index: the index of the sheet to pull down  
        returns:  
            list&lt;list&lt;str&gt;&gt; data: the input template sheet pulled down into a list  
        &#39;&#39;&#39;
        if self.use_cache:
            with open(os.path.join(self.cache_path,&#39;wks_data{}.pkl&#39;.format(index)), &#39;rb&#39;) as rxn_wks_data_cache:
                data = dill.load(rxn_wks_data_cache)
        else:
            rxn_wks = rxn_spreadsheet.get_worksheet(index)
            data = rxn_wks.get_all_values()
            with open(os.path.join(self.cache_path,&#39;wks_data{}.pkl&#39;.format(index)),&#39;wb&#39;) as rxn_wks_data_cache:
                dill.dump(data, rxn_wks_data_cache)
        return data


    def _make_out_dirs(self, header_data):
        &#39;&#39;&#39;
        params:  
            list&lt;list&lt;str&gt;&gt; header_data: data from the header  
        Postconditions:  
            All paths used by this class have been initialized if they were not before
            They are not overwritten if they already exist. paths variables of this class
            have also been initialized
        &#39;&#39;&#39;

        out_path = &#39;Ideally this would be a gdrive path, but for now everything is local&#39;
        if not os.path.exists(out_path):
            #not on the laptop
            out_path = &#39;./Controller_Out&#39;
        #get the root folder
        header_dict = {row[0]:row[1] for row in header_data[1:]}
        data_dir = header_dict[&#39;data_dir&#39;]
        self.out_path = os.path.join(out_path, data_dir)
        #if the folder doesn&#39;t exist yet, make it
        self.eve_files_path = os.path.join(self.out_path, &#39;Eve_Files&#39;)
        self.debug_path = os.path.join(self.out_path, &#39;Debug&#39;)
        self.plot_path = os.path.join(self.out_path, &#39;Plots&#39;)
        paths = [self.out_path, self.eve_files_path, self.debug_path, self.plot_path]
        for path in paths:
            if not os.path.exists(path):
                os.makedirs(path)

    def _make_cache(self):
        if not os.path.exists(self.cache_path):
            os.makedirs(self.cache_path)

    def _init_credentials(self, rxn_sheet_name):
        &#39;&#39;&#39;
        this function reads a local json file to get the credentials needed to access other funcs  
        params:  
            str rxn_sheet_name: the name of the reaction sheet to run  
        returns:  
            ServiceAccountCredentials: the credentials to access that sheet  
        &#39;&#39;&#39;
        scope = [&#39;https://spreadsheets.google.com/feeds&#39;,
                 &#39;https://www.googleapis.com/auth/drive&#39;]
        #get login credentials from local file. Your json file here
        path = &#39;Credentials/hendricks-lab-jupyter-sheets-5363dda1a7e0.json&#39;
        credentials = ServiceAccountCredentials.from_json_keyfile_name(path, scope) 
        return credentials

    def _get_wks_key(self, credentials, rxn_sheet_name):
        &#39;&#39;&#39;
        open and search a sheet that tells you which sheet is associated with the reaction  
        params:  
            ServiceAccountCredentials credentials: to access the sheets  
            str rxn_sheet_name: the name of sheet  
        returns:  
            if self.use_cache:  
                str wks_key: the key associated with the sheet. It functions similar to a url  
            else:  
                None: this is ok because the wks key will not be used if caching  
        &#39;&#39;&#39;
        name_key_pairs = self._get_wks_key_pairs(credentials, rxn_sheet_name)
        try:
            i=0
            wks_key = None
            while not wks_key and i &lt;= len(name_key_pairs):
                row = name_key_pairs[i]
                if row[0] == rxn_sheet_name:
                    wks_key = row[1]
                i+=1
        except IndexError:
            raise Exception(&#39;Spreadsheet Name/Key pair was not found. Check the dict spreadsheet \
            and make sure the spreadsheet name is spelled exactly the same as the reaction \
            spreadsheet.&#39;)
        return wks_key

    def _open_sheet(self, rxn_sheet_name, credentials):
        &#39;&#39;&#39;
        open the google sheet  
        params:  
            str rxn_sheet_name: the title of the sheet to be opened  
            oauth2client.ServiceAccountCredentials credentials: credentials read from a local json  
        returns:  
            if self.use_cache:  
                gspread.Spreadsheet the spreadsheet (probably of all the reactions)  
            else:  
                None: this is fine because the wks should never be used if cache is true  
        &#39;&#39;&#39;
        gc = gspread.authorize(credentials)
        try:
            if self.use_cache:
                wks = None
            else:
                wks = gc.open(rxn_sheet_name)
        except: 
            raise Exception(&#39;Spreadsheet Not Found: Make sure the spreadsheet name is spelled correctly and that it is shared with the robot &#39;)
        return wks

    def _init_robo_header_params(self, header_data):
        &#39;&#39;&#39;
        loads the header data into self.robo_params  
        params:  
            list&lt;list&lt;str&gt; header_data: as in gsheets  
        Postconditions:  
            simulate, using_temp_ctrl, and temp have been initialized according to values in 
            excel  
        &#39;&#39;&#39;
        header_dict = {row[0]:row[1] for row in header_data[1:]}
        self.robo_params[&#39;using_temp_ctrl&#39;] = header_dict[&#39;using_temp_ctrl&#39;] == &#39;yes&#39;
        self.robo_params[&#39;temp&#39;] = float(header_dict[&#39;temp&#39;]) if self.robo_params[&#39;using_temp_ctrl&#39;] else None

    def _plot_setup_overlay(self,title):
        &#39;&#39;&#39;
        Sets up a figure for an overlay plot  
        params:  
            str title: the title of the reaction  
        &#39;&#39;&#39;
        #formats the figure nicely
        plt.figure(num=None, figsize=(4, 4),dpi=300, facecolor=&#39;w&#39;, edgecolor=&#39;k&#39;)
        plt.legend(loc=&#34;upper right&#34;,frameon = False, prop={&#34;size&#34;:7},labelspacing = 0.5)
        plt.rc(&#39;axes&#39;, linewidth = 2)
        plt.xlabel(&#39;Wavelength (nm)&#39;,fontsize = 16)
        plt.ylabel(&#39;Absorbance (a.u.)&#39;, fontsize = 16)
        plt.tick_params(axis = &#34;both&#34;, width = 2)
        plt.tick_params(axis = &#34;both&#34;, width = 2)
        plt.xticks([300,400,500,600,700,800,900,1000])
        plt.yticks([i/10 for i in range(0,11,1)])
        plt.axis([300, 1000, 0.0 , 1.0])
        plt.xticks(fontsize = 10)
        plt.yticks(fontsize = 10)
        plt.title(str(title), fontsize = 16, pad = 20)
        
    def plot_LAM_overlay(self,df,wells,filename=None):
        &#39;&#39;&#39;
        plots overlayed spectra of wells in the order that they are specified  
        params:  
            df df: dataframe with columns = chem_names, and values of each column is a series
              of scans in 701 intervals.  
            str filename: the title of the plot, and the file  
            list&lt;str&gt; wells: an ordered list of all of the chem_names you want to plot.  
        Postconditions:  
            plot has been written with name &#34;overlay.png&#34; to the plotting dir. or 
            {filename}.png if filename was supplied  
        &#39;&#39;&#39;
        if not filename:
            filename = &#34;overlay&#34;
        x_vals = list(range(300,1001))
        #overlays only things you specify
        y = []
        #df = df[df_reorder]
        #headers = [well_key[k] for k in df.columns]
        #legend_colors = []
        for chem_name in wells:
            y.append(df[chem_name].iloc[-701:].to_list())
        self._plot_setup_overlay(filename)
        colors = list(cm.rainbow(np.linspace(0, 1,len(y))))
        for i in range(len(y)):
            plt.plot(x_vals,y[i],color = tuple(colors[i]))
        patches = [mpatches.Patch(color=color, label=label) for label, color in zip(wells, colors)]
        plt.legend(patches, wells, loc=&#39;upper right&#39;, frameon=False,prop={&#39;size&#39;:3})
        legend = pd.DataFrame({&#39;Color&#39;:patches,&#39;Labels&#39;: wells})
        plt.savefig(os.path.join(self.plot_path, &#39;{}.png&#39;.format(filename)))
        plt.close()
       
    # below until ~end is all not used yet needs to be worked up
    def plot_kin_subplots(self,df,n_cycles,wells,filename=None):
        &#39;&#39;&#39;
        TODO this function doesn&#39;t save properly, but it does show. Don&#39;t know issue  
        plots kinetics for each well in the order given by wells.  
        params:  
            df df: the scan data  
            int n_cycles: the number of cycles for the scan data  
            list&lt;str&gt; wells: the wells you want to plot in order
        Postconditions:  
            plot has been written with name &#34;{filename}_overlay.png&#34; to the plotting dir.  
            If filename is not supplied, name is kin_subplots
        &#39;&#39;&#39;
        if not filename:
            filename=kin_subplots
        x_vals = list(range(300,1001))
        colors = list(cm.rainbow(np.linspace(0, 1, n_cycles)))
        fig, axes = plt.subplots(8, 12, dpi=300, figsize=(50, 50),subplot_kw=dict(box_aspect=1,sharex = True,sharey = True))
        for idx, (chem_name, ax) in enumerate(zip(wells, axes.flatten())):
            ax.set_title(chem_name)
            self._plot_kin(ax, df, n_cycles, chem_name)
            plt.subplots_adjust(wspace=0.3, hspace= -0.1)
        
            ax.tick_params(
                which=&#39;both&#39;,
                bottom=&#39;off&#39;,
                left=&#39;off&#39;,
                right=&#39;off&#39;,
                top=&#39;off&#39;
            )
            ax.set_xlim((300,1000))
            ax.set_ylim((0,1.0))
            ax.set_xlabel(&#34;Wavlength (nm)&#34;)
            ax.set_ylabel(&#34;Absorbance (A.U.)&#34;)
            ax.set_xticks(range(301, 1100, 100))
            #ax.set_aspect(adjustable=&#39;box&#39;)
            #ax.set_yticks(range(0,1))
        else:
            [ax.set_visible(False) for ax in axes.flatten()[idx+1:]]
        plt.savefig(os.path.join(self.plot_path, &#39;{}.png&#39;.format(filename)))
        plt.close()

    def _plot_kin(self, ax, df, n_cycles, chem_name):
        &#39;&#39;&#39;
        helper method for kinetics plotting methods  
        params:  
            plt.axes ax: or anything with a plot func. the place you want ot plot  
            df df: the scan data  
            int n_cycles: the number of cycles in per well scanned  
            str chem_name: the name of the chemical to be plotted  
        Postconditions:  
            a kinetics plot of the well has been plotted on ax  
        &#39;&#39;&#39;
        x_vals = list(range(300,1001))
        colors = list(cm.rainbow(np.linspace(0, 1, n_cycles)))
        kin = 0
        col = df[chem_name]
        for kin in range(n_cycles):
            ax.plot(x_vals, df[chem_name].iloc[kin*701:(kin+1)*701],color=tuple(colors[kin]))
        
    
    def plot_single_kin(self, df, n_cycles, chem_name, filename=None):
        &#39;&#39;&#39;
        plots one kinetics trace. 
        params:  
            df df: the scan data  
            int n_cycles: the number of cycles in per well scanned  
            str chem_name: the name of the chemical to be plotted  
            str filename: the name of the file to write  
        Postconditions:  
            A kinetics trace of the well has been written to the Plots directory.
            under the name filename. If filename was None, the filename will be 
            {chem_name}_kinetics.png
        &#39;&#39;&#39;
        if not filename:
            filename = &#39;{}_kinetics&#39;.format(chem_name)
        self._plot_setup_overlay(&#39;Kinetics {}: &#39;.format(chem_name))
        self._plot_kin(plt,df, n_cycles, chem_name)
        plt.savefig(os.path.join(self.plot_path, &#39;{}.png&#39;.format(filename)))
        plt.close()

    def _get_empty_containers(self, raw_reagent_df):
        &#39;&#39;&#39;
        only one line, but there&#39;s a lot going on. extracts the empty lines from the raw_reagent_df  
        params:  
            df raw_reagent_df: as in reagent_info of excel  
        returns:  
            df empty_containers:  
                + INDEX:  
                + int deck_pos: the position on the deck  
                + COLS:  
                + str loc: location on the labware  
        &#39;&#39;&#39;
        return raw_reagent_df.loc[&#39;empty&#39; == raw_reagent_df.index].set_index(&#39;deck_pos&#39;).drop(columns=[&#39;conc&#39;, &#39;mass&#39;])

    def _get_dry_containers(self, raw_reagent_df):
        &#39;&#39;&#39;
        params:  
            df raw_reagent_df: the reagent dataframe as recieved from excel  
        returns:  
            df dry_containers:  
                note: cannot be sent over pickle as is because the index has duplicates.
                  solution is to reset the index for shipping
                + str index: the chemical name
                + float conc: the concentration once built
                + str loc: the location on the labware
                + int deck_pos: position on the deck
                + float required_vol: the volume of water needed to turn this into a reagent
        &#39;&#39;&#39;
        #other rows will be empty str unless dry
        dry_containers = raw_reagent_df.loc[raw_reagent_df[&#39;molar_mass&#39;].astype(bool)].astype(
                {&#39;deck_pos&#39;:int,&#39;mass&#39;:float,&#39;molar_mass&#39;:float})
        dry_containers.drop(columns=&#39;conc&#39;,inplace=True)
        dry_containers.reset_index(inplace=True)
        dry_containers[&#39;index&#39;] = dry_containers[&#39;index&#39;].apply(lambda x: x.replace(&#39; &#39;,&#39;_&#39;))
        return dry_containers


    
    def _parse_raw_reagent_df(self, raw_reagent_df):
        &#39;&#39;&#39;
        parses the raw_reagent_df into final form for reagent_df  
        params:  
            df raw_reagent_df: as in excel  
        returns:  
            df reagent_df: empties ignored, columns with correct types  
        &#39;&#39;&#39;
        # incase not on axis
        reagent_df = raw_reagent_df.drop([&#39;empty&#39;], errors=&#39;ignore&#39;)
        reagent_df = reagent_df.loc[~reagent_df[&#39;molar_mass&#39;].astype(bool)] #drop dry
        reagent_df.drop(columns=&#39;molar_mass&#39;,inplace=True)
        try:
            reagent_df = reagent_df.astype({&#39;conc&#39;:float,&#39;deck_pos&#39;:int,&#39;mass&#39;:float})
        except ValueError as e:
            raise ValueError(&#34;Your reagent info could not be parsed. Likely you left out a required field, or you did not specify a concentration on the input sheet&#34;)
        return reagent_df

    def _get_instrument_dict(self, deck_data):
        &#39;&#39;&#39;
        uses data from deck sheet to return the instrument params  
        Preconditions:  
            The second sheet in the worksheet must be initialized with where you&#39;ve placed reagents 
            and the first thing not being used  
        params:  
            list&lt;list&lt;str&gt;&gt;deck_data: the deck data as in excel  
        returns:  
            Dict&lt;str:str&gt;: key is &#39;left&#39; or &#39;right&#39; for the slots. val is the name of instrument  
        &#39;&#39;&#39;
        #the format google fetches this in is funky, so we convert it into a nice df
        #make instruments
        instruments = {}
        instruments[&#39;left&#39;] = deck_data[13][0]
        instruments[&#39;right&#39;] = deck_data[13][1]
        return instruments
    
    def _get_labware_df(self, deck_data, empty_containers):
        &#39;&#39;&#39;
        uses data from deck sheet to get information about labware locations, first tip, etc.  
        Preconditions:  
            The second sheet in the worksheet must be initialized with where you&#39;ve placed reagents 
            and the first thing not being used  
        params:  
            list&lt;list&lt;str&gt;&gt;deck_data: the deck data as in excel  
            df empty_containers: this is used for tubes. it holds the containers that can be used  
                + int index: deck_pos  
                + str position: the position of the empty container on the labware  
        returns:  
            df:  
                + str name: the common name of the labware  
                + str first_usable: the first tip/well to use  
                + int deck_pos: the position on the deck of this labware  
                + str empty_list: the available slots for empty tubes format &#39;A1,B2,...&#39; No specific
                  order  
        &#39;&#39;&#39;
        labware_dict = {&#39;name&#39;:[], &#39;first_usable&#39;:[],&#39;deck_pos&#39;:[]}
        for row_i in range(0,10,3):
            for col_i in range(3):
                labware_dict[&#39;name&#39;].append(deck_data[row_i+1][col_i])
                labware_dict[&#39;first_usable&#39;].append(deck_data[row_i+2][col_i])
                labware_dict[&#39;deck_pos&#39;].append(deck_data[row_i][col_i])
        labware_df = pd.DataFrame(labware_dict)
        #platereader positions need to be translated, and they shouldn&#39;t be put in both
        #slots
        platereader_rows = labware_df.loc[(labware_df[&#39;name&#39;] == &#39;platereader7&#39;) | \
                (labware_df[&#39;name&#39;] == &#39;platereader4&#39;)]
        usable_rows = platereader_rows.loc[platereader_rows[&#39;first_usable&#39;].astype(bool), &#39;first_usable&#39;]
        assert (not usable_rows.empty), &#34;please specify a first tip/well for the platereader&#34;
        assert (usable_rows.shape[0] == 1), &#34;too many first wells specified for platereader&#34;
        platereader_input_first_usable = usable_rows.iloc[0]
        platereader_name = self.PLATEREADER_INDEX_TRANSLATOR[platereader_input_first_usable][1]
        platereader_first_usable = self.PLATEREADER_INDEX_TRANSLATOR[platereader_input_first_usable][0]
        if platereader_name == &#39;platereader7&#39;:
            platereader4_first_usable = &#39;F8&#39; #anything larger than what is on plate
            platereader7_first_usable = platereader_first_usable
        else:
            platereader4_first_usable = platereader_first_usable
            platereader7_first_usable = &#39;G1&#39;
        labware_df.loc[labware_df[&#39;name&#39;]==&#39;platereader4&#39;,&#39;first_usable&#39;] = platereader4_first_usable
        labware_df.loc[labware_df[&#39;name&#39;]==&#39;platereader7&#39;,&#39;first_usable&#39;] = platereader7_first_usable
        labware_df = labware_df.loc[labware_df[&#39;name&#39;] != &#39;&#39;] #remove empty slots
        labware_df.set_index(&#39;deck_pos&#39;, inplace=True)
        #add empty containers in list form
        #there&#39;s some fancy formating here that gets you a series with deck as the index and
        #comma seperated loc strings eg &#39;A1,A3,B2&#39; as values
        grouped = empty_containers[&#39;loc&#39;].apply(lambda pos: pos+&#39;,&#39;).groupby(&#39;deck_pos&#39;)
        labware_locs = grouped.sum().apply(lambda pos: pos[:len(pos)-1])
        labware_df = labware_df.join(labware_locs, how=&#39;left&#39;)
        labware_df[&#39;loc&#39;] = labware_df[&#39;loc&#39;].fillna(&#39;&#39;)
        labware_df.rename(columns={&#39;loc&#39;:&#39;empty_list&#39;},inplace=True)
        labware_df.reset_index(inplace=True)
        labware_df[&#39;deck_pos&#39;] = pd.to_numeric(labware_df[&#39;deck_pos&#39;])
        return labware_df

    def save(self):
        self.portal.send_pack(&#39;save&#39;)
        #server will initiate file transfer
        files = self.portal.recv_ftp()
        for filename, file_bytes in files:
            with open(os.path.join(self.eve_files_path,filename), &#39;wb&#39;) as write_file:
                write_file.write(file_bytes)
        self.translate_wellmap()
        

    def close_connection(self):
        &#39;&#39;&#39;
        runs through closing procedure with robot    
        Postconditions:    
            Log files have been written to self.out_path  
            Connection has been closed  
        &#39;&#39;&#39;
        print(&#39;&lt;&lt;controller&gt;&gt; initializing breakdown&#39;)
        self.save()
        #server should now send a close command
        self.portal.send_pack(&#39;close&#39;)
        print(&#39;&lt;&lt;controller&gt;&gt; shutting down&#39;)
        self.portal.close()
    
    def translate_wellmap(self):
        &#39;&#39;&#39;
        Preconditions:  
            there exists a file wellmap.tsv in self.eve_files, and that file has eve level
            machine labels  
        Postconditions:  
            translated_wellmap.tsv has been created. translated is a copy of wellmap with   
            it&#39;s locations translated to human locs, but the labware pos remains the same  
        &#39;&#39;&#39;
        df = pd.read_csv(os.path.join(self.eve_files_path,&#39;wellmap.tsv&#39;), sep=&#39;\t&#39;)
        df[&#39;loc&#39;] = df.apply(lambda r: r[&#39;loc&#39;] if (r[&#39;deck_pos&#39;] not in [4,7]) else self.PLATEREADER_INDEX_TRANSLATOR.inv[(r[&#39;loc&#39;],&#39;platereader&#39;+str(r[&#39;deck_pos&#39;]))],axis=1)
        df.to_csv(os.path.join(self.eve_files_path,&#39;translated_wellmap.tsv&#39;),sep=&#39;\t&#39;,index=False)

    def init_robot(self, simulate):
        &#39;&#39;&#39;
        this does the dirty work of sending accumulated params over network to the robot  
        params:  
            bool simulate: whether the robot should run a simulation  
        Postconditions:  
            robot has been initialized with necessary params  
        &#39;&#39;&#39;
        #send robot data to initialize itself
        cid = self.portal.send_pack(&#39;init&#39;, simulate, 
                self.robo_params[&#39;using_temp_ctrl&#39;], self.robo_params[&#39;temp&#39;],
                self.robo_params[&#39;labware_df&#39;].to_dict(), self.robo_params[&#39;instruments&#39;],
                self.robo_params[&#39;reagent_df&#39;].to_dict(), self.my_ip,
                self.robo_params[&#39;dry_containers&#39;].to_dict())

    @abstractmethod
    def run_simulation(self):
        pass

    @abstractmethod
    def run_protocol(self,simulate):
        pass


    def _error_handler(self, e):
        &#39;&#39;&#39;
        When an error is thrown from a public method, it will be sent here and handled
        &#39;&#39;&#39;
        #handle the error
        if self.portal.state == 1:
            #Armchair recieved an error packet, so eve had a problem
            try:
                eve_error = self.portal.error_payload[0]
                print(&#39;&#39;&#39;&lt;&lt;controller&gt;&gt;----------------Eve Error----------------
                Eve threw error &#39;{}&#39;
                Attempting to save state on exit
                &#39;&#39;&#39;.format(eve_error))
                self.portal.reset_error()
                self.close_connection()
                self.pr.shutdown()
            finally:
                raise eve_error
        else:
            try:
                print(&#39;&#39;&#39;&lt;&lt;controller&gt;&gt; ----------------Controller Error----------------
                &lt;&lt;controller&gt;&gt; Attempting to save state on exit&#39;&#39;&#39;)
                self.close_connection()
                self.pr.shutdown()
            finally:
                time.sleep(.5) #this is just for printing format. Not critical
                raise e

    def _load_rxn_df(self, input_data):
        &#39;&#39;&#39;
        reaches out to google sheets and loads the reaction protocol into a df and formats the df
        adds a chemical name (primary key for lots of things. e.g. robot dictionaries)
        renames some columns to code friendly as opposed to human friendly names  
        params:  
            list&lt;list&lt;str&gt;&gt; input_data: as recieved in excel  
        returns:  
            pd.DataFrame: the information in the rxn_spreadsheet w range index. spreadsheet cols  
        Postconditions:  
            self._products has been initialized to hold the names of all the products  
        &#39;&#39;&#39;
        cols = make_unique(pd.Series(input_data[0])) 
        rxn_df = pd.DataFrame(input_data[3:], columns=cols)
        #rename some of the clunkier columns 
        rxn_df.rename({&#39;operation&#39;:&#39;op&#39;, &#39;dilution concentration&#39;:&#39;dilution_conc&#39;,&#39;concentration (mM)&#39;:&#39;conc&#39;, &#39;reagent (must be uniquely named)&#39;:&#39;reagent&#39;, &#39;plot protocol&#39;:&#39;plot_protocol&#39;, &#39;pause time (s)&#39;:&#39;pause_time&#39;, &#39;comments (e.g. new bottle)&#39;:&#39;comments&#39;,&#39;scan protocol&#39;:&#39;scan_protocol&#39;, &#39;scan filename (no extension)&#39;:&#39;scan_filename&#39;, &#39;plot filename (no extension)&#39;:&#39;plot_filename&#39;}, axis=1, inplace=True)
        rxn_df.drop(columns=[&#39;comments&#39;], inplace=True)#comments are for humans
        rxn_df.replace(&#39;&#39;, np.nan,inplace=True)
        rxn_df[[&#39;pause_time&#39;,&#39;dilution_conc&#39;,&#39;conc&#39;]] = rxn_df[[&#39;pause_time&#39;,&#39;dilution_conc&#39;,&#39;conc&#39;]].astype(float)
        #rename chemical names
        rxn_df[&#39;chemical_name&#39;] = rxn_df[[&#39;conc&#39;, &#39;reagent&#39;]].apply(self._get_chemical_name,axis=1)
        self._rename_products(rxn_df)
        #go back for some non numeric columns
        rxn_df[&#39;callbacks&#39;].fillna(&#39;&#39;,inplace=True)
        self._products = rxn_df.loc[:,&#39;reagent&#39;:&#39;chemical_name&#39;].drop(columns=[&#39;chemical_name&#39;, &#39;reagent&#39;]).columns
        #make the reagent columns floats
        rxn_df.loc[:,self._products] =  rxn_df[self._products].astype(float)
        rxn_df.loc[:,self._products] = rxn_df[self._products].fillna(0)
        return rxn_df

    @abstractmethod
    def _rename_products(self, rxn_df):
        &#39;&#39;&#39;
        Different for Protocol Executor vs auto
        renames dilutions acording to the reagent that created them
        and renames rxns to have a concentration  
        Preconditions:  
            dilution cols are named dilution_1/2 etc  
            callback is the last column in the dataframe  
            rxn_df is not expected to be initialized yet. This is a helper for the initialization  
        params:  
            df rxn_df: the dataframe with all the reactions  
        Postconditions:  
            the df has had it&#39;s dilution columns renamed to a chemical name
        &#39;&#39;&#39;
        pass

    def _get_products_to_labware(self, input_data):
        &#39;&#39;&#39;
        create a dictionary mapping products to their requested labware/containers  
        Preconditions:  
            self.rxn_df must have been initialized already  
        params:  
            list&lt;list&lt;str&gt;&gt; input data: the data from the excel sheet  
        returns:  
            Dict&lt;str,list&lt;str,str&gt;&gt;: effectively the 2nd and 3rd rows in excel. Gives 
                    labware and container preferences for products  
        &#39;&#39;&#39;
        cols = self.rxn_df.columns.to_list()
        product_start_i = cols.index(&#39;reagent&#39;)+1
        requested_containers = input_data[2][product_start_i+1:]
        requested_labware = input_data[1][product_start_i+1:]#add one to account for the first col (labware)
        #in df this is an index, so size cols is one less
        products_to_labware = {product:[labware,container] for product, labware, container in zip(self._products, requested_labware,requested_containers)}
        return products_to_labware

    def _query_reagents(self, spreadsheet_key, credentials):
        &#39;&#39;&#39;
        query the user with a reagent sheet asking for more details on locations of reagents, mass
        etc  
        Preconditions:  
            self.rxn_df should be initialized  
        params:  
            str spreadsheet_key: this is the a unique id for google sheet used for i/o with sheets
            ServiceAccount Credentials credentials: to access sheets  
        PostConditions:  
            reagent_sheet has been constructed  
        &#39;&#39;&#39;
        rxn_names = self.rxn_df.loc[:, &#39;reagent&#39;:&#39;chemical_name&#39;].drop(columns=[&#39;reagent&#39;,&#39;chemical_name&#39;]).columns
        #you might make a reaction you don&#39;t want to specify at the start
        reagent_df = self.rxn_df.loc[self.rxn_df[&#39;op&#39;] != &#39;make&#39;, [&#39;chemical_name&#39;, &#39;conc&#39;]\
                ].groupby(&#39;chemical_name&#39;).first()
        reagent_df.drop(rxn_names, errors=&#39;ignore&#39;, inplace=True) #not all rxns are reagents
        reagent_df[[&#39;loc&#39;, &#39;deck_pos&#39;, &#39;mass&#39;, &#39;molar_mass (for dry only)&#39;, &#39;comments&#39;]] = &#39;&#39;
        if not self.use_cache:
            if reagent_df.empty:
                #d2g has weird upload behavior so must add a blank row
                blanks = [&#39;&#39; for i in range(reagent_df.shape[1])]
                reagent_df = reagent_df.append(pd.DataFrame([blanks],
                        columns=reagent_df.columns,index=pd.Index([&#39;&#39;],name=&#39;chemical_name&#39;)))
            d2g.upload(reagent_df.reset_index(),spreadsheet_key,wks_name = &#39;reagent_info&#39;, row_names=False , credentials = credentials)

    def _get_product_df(self, products_to_labware):
        &#39;&#39;&#39;
        Creates a df to be used by robot to initialize containers for the products it will make  
        params:  
            df products_to_labware: as passed to init_robot  
        returns:  
            df products:  
                + INDEX:  
                + str chemical_name: the name of this rxn  
                + COLS:  
                + str labware: the labware to put this rxn in or None if no preference  
                + float max_vol: the maximum volume that will ever ocupy this container  
        &#39;&#39;&#39;
        products = products_to_labware.keys()
        max_vols = [self._get_rxn_max_vol(product, products) for product in products]
        product_df = pd.DataFrame(products_to_labware, index=[&#39;labware&#39;,&#39;container&#39;]).T
        product_df[&#39;max_vol&#39;] = max_vols
        return product_df

    @abstractmethod
    def _get_rxn_max_vol(self, name, products):
        &#39;&#39;&#39;
        This needs to be implemented to as a helper for _get_product_df.
        It calculates the maximum volume that a container will hold at a time
        &#39;&#39;&#39;
        pass

    def execute_protocol_df(self):
        &#39;&#39;&#39;
        takes a protocol df and sends every step to robot to execute  
        params:  
            int buff: the number of commands allowed in flight at a time  
        Postconditions:  
            every step in the protocol has been sent to the robot  
        &#39;&#39;&#39;
        for i, row in self.rxn_df.iterrows():
            if row[&#39;op&#39;] == &#39;transfer&#39;:
                self._send_transfer_command(row,i)
            elif row[&#39;op&#39;] == &#39;pause&#39;:
                cid = self.portal.send_pack(&#39;pause&#39;,row[&#39;pause_time&#39;])
            elif row[&#39;op&#39;] == &#39;stop&#39;:
                #read through the inflight packets
                self.portal.send_pack(&#39;stop&#39;)
                self._stop(i)
            elif row[&#39;op&#39;] == &#39;scan&#39;:
                self._execute_scan(row, i)
            elif row[&#39;op&#39;] == &#39;dilution&#39;:
                self._send_dilution_commands(row, i)
            elif row[&#39;op&#39;] == &#39;mix&#39;:
                self._mix(row, i)
            elif row[&#39;op&#39;] == &#39;make&#39;:
                self._send_make(row, i)
            elif row[&#39;op&#39;] == &#39;save&#39;:
                self.save()
            elif row[&#39;op&#39;] == &#39;plot&#39;:
                self._create_plot(row, i)
            else:
                raise Exception(&#39;invalid operation {}&#39;.format(row[&#39;op&#39;]))

    def _create_plot(self, row, i):
        &#39;&#39;&#39;
        exectues a plot command  
        params:  
            pd.Series row: a row of self.rxn_df  
            int i: index of this row  
        &#39;&#39;&#39;
        wellnames = row[self._products][row[self._products].astype(bool)].index
        plot_type = row[&#39;plot_protocol&#39;]
        filename = row[&#39;plot_filename&#39;]
        #make sure you have mapping for all files

        self._update_cached_locs(wellnames)
        pr_dict = {entry.loc:chem_name 
                    for chem_name, entry 
                    in self._cached_reader_locs.items() 
                    if entry.deck_pos in [4,7]}
        #it&#39;s not safe to plot in simulation because the scan file may not exist yet
        df, metadata = self.pr.load_reader_data(&#39;{}.csv&#39;.format(row[&#39;scan_filename&#39;]), pr_dict)
        #execute the plot depending on what was specified
        if plot_type == &#39;single_kin&#39;:
            for wellname in wellnames:
                self.plot_single_kin(df, metadata[&#39;n_cycles&#39;], wellname, &#34;{}_{}&#34;.format(wellname, filename))
        elif plot_type == &#39;overlay&#39;:
            self.plot_LAM_overlay(df, wellnames, filename)
        elif plot_type == &#39;multi_kin&#39;:
            self.plot_kin_subplots(df, metadata[&#39;n_cycles&#39;], wellnames, filename)

    def _download_reagent_data(self, spreadsheet_key, credentials):
        &#39;&#39;&#39;
        This is almost line for line inherited, but we need to input in the middle. 
        What can you do?  
        params:  
            str spreadsheet_key: this is the a unique id for google sheet used for i/o with sheets  
            ServiceAccount Credentials credentials: to access sheets  
        returns:  
            df reagent_info: dataframe as pulled from gsheets (with comments dropped)  
        &#39;&#39;&#39;
        
        if self.use_cache:
            #if you&#39;ve already seen this don&#39;t pull it
            with open(os.path.join(self.cache_path, &#39;reagent_info_sheet.pkl&#39;), &#39;rb&#39;) as reagent_info_cache:
                reagent_info = dill.load(reagent_info_cache)
        else:
            input(&#34;&lt;&lt;controller&gt;&gt; please press enter when you&#39;ve completed the reagent sheet&#34;)
            #pull down from the cloud
            reagent_info = g2d.download(spreadsheet_key, &#39;reagent_info&#39;, col_names = True, 
                row_names = True, credentials=credentials).drop(columns=[&#39;comments&#39;])
            #cache the data
            #DEBUG
            with open(os.path.join(self.cache_path, &#39;reagent_info_sheet.pkl&#39;), &#39;wb&#39;) as reagent_info_cache:
                dill.dump(reagent_info, reagent_info_cache)
        reagent_info.rename(columns={&#39;molar_mass (for dry only)&#39;: &#39;molar_mass&#39;}, inplace=True)
        return reagent_info

    def _send_make(self, row, i):
        &#39;&#39;&#39;
        sends a make command to the robot  
        params:  
            pd.Series row: a row of self.rxn_df  
            int i: index of this row  
        &#39;&#39;&#39;
        self.portal.send_pack(&#39;make&#39;, row[&#39;reagent&#39;].replace(&#39; &#39;,&#39;_&#39;), row[&#39;conc&#39;])

    def _execute_scan(self,row,i):
        &#39;&#39;&#39;
        There are a few things entailed in a scan command  
        1) send home to robot  
        2) block until you run out of waits  
        3) figure out what wells you want to scan  
        4) query the robot for those wells, or use cache if you have it  
            a) if you had to query robot, send request of reagents  
            b) wait on robot response  
            c) translate robot response to human readable  
        5) update layout to scanner and scan  
        params:  
            pd.Series row: a row of self.rxn_df  
            int i: index of this row  
        &#39;&#39;&#39;
        #1)
        self.portal.send_pack(&#39;home&#39;)
        #2)
        self.portal.burn_pipe()
        #3)
        wellnames = row[self._products][row[self._products].astype(bool)].index
        self._update_cached_locs(wellnames)
        #4)
        #update the locs on the well
        well_locs = []
        for well, entry in [(well, self._cached_reader_locs[well]) for well in wellnames]:
            assert (entry.deck_pos in [4,7]), &#34;tried to scan {}, but {} is on {} in deck pos {}&#34;.format(well, well, entry.deck_pos, entry.loc)
            assert (math.isclose(entry.vol, 200)), &#34;tried to scan {}, but {} has a bad volume. Vol was {}, but 200 is required for a scan&#34;.format(well, well, entry.vol)
            well_locs.append(entry.loc)
        #5
        self.pr.exec_macro(&#39;PlateIn&#39;)
        self.pr.run_protocol(row[&#39;scan_protocol&#39;], row[&#39;scan_filename&#39;], layout=well_locs)
        self.pr.exec_macro(&#39;PlateOut&#39;)

    def _update_cached_locs(self, wellnames):
        &#39;&#39;&#39;
        A query will be
        made to Eve for the wellnames, and data for those will be stored in the cache  
        params:  
            listlike&lt;str&gt; wellnames: the names of the wells you want to lookup  
        Postconditions:  
            The wellnames are in the cache  
        &#39;&#39;&#39;
        #couldn&#39;t find in the cache, so we got to make a query
        self.portal.send_pack(&#39;loc_req&#39;, [wellname for wellname in wellnames])
        pack_type, _, payload = self.portal.recv_pack()
        assert (pack_type == &#39;loc_resp&#39;), &#39;was expecting loc_resp but recieved {}&#39;.format(pack_type)
        returned_well_locs = payload[0]
        #update the cache
        for well_entry in returned_well_locs:
            if well_entry[2] in [4,7]:
                #is on reader. Need to translate index
                self._cached_reader_locs[well_entry[0]] = self.ChemCacheEntry(*(self.PLATEREADER_INDEX_TRANSLATOR.inv[(well_entry[1],&#39;platereader{}&#39;.format(well_entry[2]))],)+well_entry[2:])
            else:
                #not on reader, just use vanilla index
                self._cached_reader_locs[well_entry[0]] = self.ChemCacheEntry(*well_entry[1:])

    def _mix(self,row,i):
        &#39;&#39;&#39;
        For now this function just shakes the whole plate.
        In the future, we may want to mix
        things that aren&#39;t on the platereader, in which case a new argument should be made in 
        excel for the wells to scan, and we should make a function to pipette mix.
        &#39;&#39;&#39;
        wells_to_mix = row[self._products].loc[row[self._products].astype(bool)].astype(int)
        wells_to_mix.name = &#39;mix_code&#39;
        #wells_to_mix = [t for t in wells_to_mix.astype(int).iteritems()]
        self._update_cached_locs(wells_to_mix.index)
        deck_poses = pd.Series({wellname:self._cached_reader_locs[wellname].deck_pos for 
                wellname in wells_to_mix.index}, name=&#39;deck_pos&#39;)
        wells_to_mix_df = pd.concat((wells_to_mix, deck_poses),axis=1)
        #get platereader rows. true if pr
        wells_to_mix_df[&#39;platereader&#39;] = wells_to_mix_df[&#39;deck_pos&#39;].apply(lambda x: x in [4,7]) 
        if wells_to_mix_df[&#39;platereader&#39;].sum() &gt; 0:
            #TODO technically, you could be mixing the other stuff by hand while you&#39;re mixing
            #the stuff in the reader, but if you miscalculated and accidently hand mix on the
            #platereader because of a bug, Mark will be mad, so apart for now. After testing
            #you should burn pipe, then send the handmix command, then mix the platereader
            #to multitask

            #at least one well nees a shake
            self.portal.send_pack(&#39;home&#39;)
            self.portal.burn_pipe() # can&#39;t be pulling plate in if you&#39;re still mixing
            self.pr.exec_macro(&#39;PlateIn&#39;)
            self.pr.shake()
            self.pr.exec_macro(&#39;PlateOut&#39;)
        if (~wells_to_mix_df[&#39;platereader&#39;]).sum() &gt; 0:
            #at least one needs to be mixed by hand
            #still df
            hand_mix_wells = wells_to_mix_df.loc[~wells_to_mix_df[&#39;platereader&#39;]].reset_index()
            #convert to list of tuples
            hand_mix_wells = [tuple(t) for t in hand_mix_wells[[&#39;index&#39;,&#39;mix_code&#39;]].itertuples(index=False)]
            self.portal.send_pack(&#39;mix&#39;, hand_mix_wells)

    def _send_dilution_commands(self,row,i):
        &#39;&#39;&#39;
        used to execute a dilution. This is analogous to microcode. This function will send two
          commands. Water is always added first.
            transfer: transfer water into the container
            transfer: transfer reagent into the container  
        params:  
            pd.Series row: a row of self.rxn_df  
            int i: index of this row  
        Preconditions:  
            The buffer has room for at least one command  
        Postconditions:  
            Two transfer commands have been sent to the robot to: 1) add water. 2) add reagent.  
            Will block on ready if the buffer is filled  
        &#39;&#39;&#39;
        water_transfer_row, reagent_transfer_row = self._get_dilution_transfer_rows(row)
        self._send_transfer_command(water_transfer_row, i)
        self._send_transfer_command(reagent_transfer_row, i)

    def _get_dilution_transfer_rows(self, row):
        &#39;&#39;&#39;
        Takes in a dilution row and builds two transfer rows to be used by the transfer command  
        params:  
            pd.Series row: a row of self.rxn_df  
        returns:  
            tuple&lt;pd.Series&gt;: rows to be passed to the send transfer command. water first, then
              reagent
              see self._construct_dilution_transfer_row for details  
        &#39;&#39;&#39;
        reagent = row[&#39;chemical_name&#39;]
        reagent_conc = row[&#39;conc&#39;]
        product_cols = row.loc[self._products]
        dilution_name_vol = product_cols.loc[~product_cols.apply(lambda x: math.isclose(x,0,abs_tol=1e-9))]
        #assert (dilution_name_vol.size == 1), &#34;Failure on row {} of the protocol. It seems you tried to dilute into multiple containers&#34;
        total_vol = dilution_name_vol.iloc[0]
        target_name = dilution_name_vol.index[0]
        target_conc = row[&#39;dilution_conc&#39;]
        vol_water, vol_reagent = self._get_dilution_transfer_vols(target_conc, reagent_conc, total_vol)
        water_transfer_row = self._construct_dilution_transfer_row(&#39;WaterC1.0&#39;, target_name, vol_water)
        reagent_transfer_row = self._construct_dilution_transfer_row(reagent, target_name, vol_reagent)
        return water_transfer_row, reagent_transfer_row

    def _construct_dilution_transfer_row(self, reagent_name, target_name, vol):
        &#39;&#39;&#39;
        The transfer command expects a nicely formated row of the rxn_df, so here we create a row
        with everything in it to ship to the transfer command.  
        params:  
            str reagent_name: used as the chemical_name field  
            str target_name: used as the product_name field  
            str vol: the volume to transfer  
        returns:  
            pd.Series: has all the fields of a regular row, but only [chemical_name, target_name,
              op] have been initialized. The other fields are empty/NaN  
        &#39;&#39;&#39;
        template = self.rxn_df.iloc[0].copy()
        template[:] = np.nan
        template[self._products] = 0.0
        template[&#39;op&#39;] = &#39;transfer&#39;
        template[&#39;chemical_name&#39;] = reagent_name
        template[target_name] = vol
        template[&#39;callbacks&#39;] = &#39;&#39;
        return template

    def _stop(self, i):
        &#39;&#39;&#39;
        used to execute a stop operation. reads through buffer and then waits on user input  
        params:  
            int i: the index of the row in the protocol you&#39;re stopped on  
        Postconditions:  
            self._inflight_packs has been cleaned  
        &#39;&#39;&#39;
        pack_type, _, _ = self.portal.recv_pack()
        assert (pack_type == &#39;stopped&#39;), &#34;sent stop command and expected to recieve stopped, but instead got {}&#34;.format(pack_type)
        if not self.simulate:
            input(&#34;stopped on line {} of protocol. Please press enter to continue execution&#34;.format(i+1))
        self.portal.send_pack(&#39;continue&#39;)

    def _send_transfer_command(self, row, i):
        &#39;&#39;&#39;
        params:  
            pd.Series row: a row of self.rxn_df
              uses the chemical_name, callbacks (and associated args), product_columns  
            int i: index of this row  
        returns:  
            int: the cid of this command  
        Postconditions:  
            a transfer command has been sent to the robot  
        &#39;&#39;&#39;
        src = row[&#39;chemical_name&#39;]
        containers = row[self._products].loc[row[self._products] != 0]
        transfer_steps = [name_vol_pair for name_vol_pair in containers.iteritems()]
        #temporarilly just the raw callbacks
        callbacks = row[&#39;callbacks&#39;].replace(&#39; &#39;, &#39;&#39;).split(&#39;,&#39;) if row[&#39;callbacks&#39;] else []
        has_stop = &#39;stop&#39; in callbacks
        callbacks = [(callback, self._get_callback_args(row, callback)) for callback in callbacks]
        cid = self.portal.send_pack(&#39;transfer&#39;, src, transfer_steps, callbacks)
        if has_stop:
            n_stops = containers.shape[0]
            for _ in range(n_stops):
                self._stop(i)

    
    def _get_callback_args(self, row, callback):
        &#39;&#39;&#39;
        params:  
            pd.Series row: a row of self.rxn_df  
        returns:  
            list&lt;object&gt;: the arguments associated with the callback or None if no arguments  
        &#39;&#39;&#39;
        if callback == &#39;pause&#39;:
            return [row[&#39;pause_time&#39;]]
        return None
    

    def _get_dilution_transfer_vols(self, target_conc, reagent_conc, total_vol):
        &#39;&#39;&#39;
        calculates the amount of reagent volume needed for a dilution  
        params:  
            float target_conc: the concentration desired at the end  
            float reagent_conc: the concentration of the reagent  
            float total_vol: the total volume requested  
        returns:  
            tuple&lt;float&gt;: size 2
                volume of water to transfer
                volume of reagent to transfer  
        &#39;&#39;&#39;
        mols_reagent = total_vol*target_conc #mols (not really mols if not milimolar. whatever)
        vol_reagent = mols_reagent/reagent_conc
        vol_water = total_vol - vol_reagent
        return vol_water, vol_reagent

    def _get_chemical_name(self,row):
        &#39;&#39;&#39;
        create a chemical name
        from a row in a pandas df. (can be just the two columns, [&#39;conc&#39;, &#39;reagent&#39;])  
        params:  
            pd.Series row: a row in the rxn_df  
        returns:  
            chemical_name: the name for the chemical &#34;{}C{}&#34;.format(name, conc) or name if
              has no concentration, or nan if no name  
        &#39;&#39;&#39;
        if pd.isnull(row[&#39;reagent&#39;]) or pd.isnull(row[&#39;conc&#39;]):
            #this must not be a transfer. this operation has no chemical name
            return np.nan
        else:
            #this uses a chemical with a conc. Probably a stock solution
            return &#34;{}C{}&#34;.format(row[&#39;reagent&#39;], row[&#39;conc&#39;]).replace(&#39; &#39;, &#39;_&#39;)
        return pd.Series(new_cols)

    @abstractmethod
    def run_all_checks(self):
        &#39;&#39;&#39;
        it is expected that each subclass will implement a version of this method based
        on the checks that they need to run.  
        run_all_checks should run every appropriate pre rxn check  
        &#39;&#39;&#39;
        pass

    def check_labware(self):
        &#39;&#39;&#39;
        checks to ensure that the labware has been correctly initialized  
        returns  
            int found_errors:  
                code:  
                0: OK.  
                1: Some Errors, but could run  
                2: Critical. Abort  
        &#39;&#39;&#39;
        found_errors = 0
        for i, r in self.robo_params[&#39;labware_df&#39;].iterrows():
            #check that everything has afirst well if it&#39;s not a tube
            if not &#39;tube&#39; in r[&#39;name&#39;] and not r[&#39;first_usable&#39;]:
                print(&#39;&lt;&lt;controller&gt;&gt; specified labware {} on deck_pos {}, but did not specify first usable tip/well.&#39;.format(r[&#39;name&#39;], r[&#39;deck_pos&#39;]))
                found_errors = max(found_errors,2)
            #if you&#39;re not a tube and you have an empty_list, that&#39;s also bad
            if not &#39;tube&#39; in r[&#39;name&#39;] and r[&#39;empty_list&#39;]:
                print(&#39;&lt;&lt;controller&gt;&gt; An empty list for {} on deck pos {} was specified, but {} takes only a first usable tip/well.&#39;.format(r[&#39;name&#39;], r[&#39;deck_pos&#39;], r[&#39;name&#39;]))
                found_errors = max(found_errors,2)
            #check for no duplicates in the empty list
            if r[&#39;empty_list&#39;]:
                locs = r[&#39;empty_list&#39;].replace(&#39; &#39;,&#39;&#39;).split(&#39;,&#39;)
                if len(set(locs)) &lt; len(locs):
                    print(&#39;&lt;&lt;controller&gt;&gt; empty list for {} on deck pos {} had duplicates. List was {}&#39;.format(r[&#39;name&#39;],r[&#39;deck_pos&#39;], r[&#39;empty_list&#39;]))
                    found_errors = max(found_errors,2)
        return found_errors 

    def check_reagents(self):
        &#39;&#39;&#39;
        checks to ensure that you&#39;ve specified reagents correctly, and also checks that
        you did not double book empty containers onto reagents  
        returns  
            int found_errors:  
                code:  
                0: OK.  
                1: Some Errors, but could run  
                2: Critical. Abort  
        &#39;&#39;&#39;
        found_errors = 0
        #This is a little hefty. We&#39;re checking to see if any reagents/empty containers 
        #were double booked onto the same location on the same deck position
        labware_w_empties = self.robo_params[&#39;labware_df&#39;].loc[self.robo_params[&#39;labware_df&#39;][&#39;empty_list&#39;].astype(bool)]
        loc_pos_empty_pairs = [] # will become series
        for i, row in labware_w_empties.iterrows():
            for loc in row[&#39;empty_list&#39;].replace(&#39; &#39;,&#39;&#39;).split(&#39;,&#39;):
                loc_pos_empty_pairs.append((loc, row[&#39;deck_pos&#39;]))
        loc_pos_empty_pairs = pd.Series(loc_pos_empty_pairs, dtype=object)
        loc_deck_pos_pairs = self.robo_params[&#39;reagent_df&#39;].apply(lambda r: (r[&#39;loc&#39;], r[&#39;deck_pos&#39;]),axis=1)
        loc_deck_pos_pairs = loc_deck_pos_pairs.append(loc_pos_empty_pairs)
        val_counts = loc_deck_pos_pairs.value_counts()
        for i in val_counts.loc[val_counts &gt; 2].index:
            print(&#39;&lt;&lt;controller&gt;&gt; location {} on deck position has multiple reagents/empty containers assigned to it&#39;)
            found_errors = max(found_errors,2)
        return found_errors

    def check_rxn_df(self):
        &#39;&#39;&#39;
        Runs error checks on the reaction df to ensure that formating is correct. Illegal/Ill 
        Advised options are printed and if an error code is returned
        Will run through and check all rows, even if errors are found
        returns  
            int found_errors:  
                code:  
                0: OK.  
                1: Some Errors, but could run  
                2: Critical. Abort  
        &#39;&#39;&#39;
        found_errors = 0
        for i, r in self.rxn_df.iterrows():
            r_num = i+1
            #check pauses
            if (not (&#39;pause&#39; in r[&#39;op&#39;] or &#39;pause&#39; in r[&#39;callbacks&#39;])) == (not pd.isna(r[&#39;pause_time&#39;])):
                print(&#34;&lt;&lt;controller&gt;&gt; You asked for a pause in row {}, but did not specify the pause_time or vice versa&#34;.format(r_num))
                found_errors = max(found_errors, 2)
            #check that there&#39;s always a volume when you transfer
            if (r[&#39;op&#39;] == &#39;transfer&#39; and math.isclose(r[self._products].sum(), 0,abs_tol=1e-9)):
                print(&#34;&lt;&lt;controller&gt;&gt; You executed a transfer step in row {}, but you did not transfer any volume.&#34;.format(r_num))
                found_errors = max(found_errors, 1)
            #check that you have a reagent if you&#39;re transfering
            if r[&#39;op&#39;] == &#39;transfer&#39; and pd.isna(r[&#39;reagent&#39;]):
                print(&#39;&lt;&lt;controller&gt;&gt; transfer specified without reagent in row {}&#39;.format(r_num))
                found_errors = max(found_errors,2)
        return found_errors</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>abc.ABC</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="controller.AutoContr" href="#controller.AutoContr">AutoContr</a></li>
<li><a title="controller.ProtocolExecutor" href="#controller.ProtocolExecutor">ProtocolExecutor</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="controller.Controller.ChemCacheEntry"><code class="name">var <span class="ident">ChemCacheEntry</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="controller.Controller.PLATEREADER_INDEX_TRANSLATOR"><code class="name">var <span class="ident">PLATEREADER_INDEX_TRANSLATOR</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="controller.Controller.check_labware"><code class="name flex">
<span>def <span class="ident">check_labware</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>checks to ensure that the labware has been correctly initialized<br>
returns<br>
int found_errors:<br>
code:<br>
0: OK.<br>
1: Some Errors, but could run<br>
2: Critical. Abort</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_labware(self):
    &#39;&#39;&#39;
    checks to ensure that the labware has been correctly initialized  
    returns  
        int found_errors:  
            code:  
            0: OK.  
            1: Some Errors, but could run  
            2: Critical. Abort  
    &#39;&#39;&#39;
    found_errors = 0
    for i, r in self.robo_params[&#39;labware_df&#39;].iterrows():
        #check that everything has afirst well if it&#39;s not a tube
        if not &#39;tube&#39; in r[&#39;name&#39;] and not r[&#39;first_usable&#39;]:
            print(&#39;&lt;&lt;controller&gt;&gt; specified labware {} on deck_pos {}, but did not specify first usable tip/well.&#39;.format(r[&#39;name&#39;], r[&#39;deck_pos&#39;]))
            found_errors = max(found_errors,2)
        #if you&#39;re not a tube and you have an empty_list, that&#39;s also bad
        if not &#39;tube&#39; in r[&#39;name&#39;] and r[&#39;empty_list&#39;]:
            print(&#39;&lt;&lt;controller&gt;&gt; An empty list for {} on deck pos {} was specified, but {} takes only a first usable tip/well.&#39;.format(r[&#39;name&#39;], r[&#39;deck_pos&#39;], r[&#39;name&#39;]))
            found_errors = max(found_errors,2)
        #check for no duplicates in the empty list
        if r[&#39;empty_list&#39;]:
            locs = r[&#39;empty_list&#39;].replace(&#39; &#39;,&#39;&#39;).split(&#39;,&#39;)
            if len(set(locs)) &lt; len(locs):
                print(&#39;&lt;&lt;controller&gt;&gt; empty list for {} on deck pos {} had duplicates. List was {}&#39;.format(r[&#39;name&#39;],r[&#39;deck_pos&#39;], r[&#39;empty_list&#39;]))
                found_errors = max(found_errors,2)
    return found_errors </code></pre>
</details>
</dd>
<dt id="controller.Controller.check_reagents"><code class="name flex">
<span>def <span class="ident">check_reagents</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>checks to ensure that you've specified reagents correctly, and also checks that
you did not double book empty containers onto reagents<br>
returns<br>
int found_errors:<br>
code:<br>
0: OK.<br>
1: Some Errors, but could run<br>
2: Critical. Abort</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_reagents(self):
    &#39;&#39;&#39;
    checks to ensure that you&#39;ve specified reagents correctly, and also checks that
    you did not double book empty containers onto reagents  
    returns  
        int found_errors:  
            code:  
            0: OK.  
            1: Some Errors, but could run  
            2: Critical. Abort  
    &#39;&#39;&#39;
    found_errors = 0
    #This is a little hefty. We&#39;re checking to see if any reagents/empty containers 
    #were double booked onto the same location on the same deck position
    labware_w_empties = self.robo_params[&#39;labware_df&#39;].loc[self.robo_params[&#39;labware_df&#39;][&#39;empty_list&#39;].astype(bool)]
    loc_pos_empty_pairs = [] # will become series
    for i, row in labware_w_empties.iterrows():
        for loc in row[&#39;empty_list&#39;].replace(&#39; &#39;,&#39;&#39;).split(&#39;,&#39;):
            loc_pos_empty_pairs.append((loc, row[&#39;deck_pos&#39;]))
    loc_pos_empty_pairs = pd.Series(loc_pos_empty_pairs, dtype=object)
    loc_deck_pos_pairs = self.robo_params[&#39;reagent_df&#39;].apply(lambda r: (r[&#39;loc&#39;], r[&#39;deck_pos&#39;]),axis=1)
    loc_deck_pos_pairs = loc_deck_pos_pairs.append(loc_pos_empty_pairs)
    val_counts = loc_deck_pos_pairs.value_counts()
    for i in val_counts.loc[val_counts &gt; 2].index:
        print(&#39;&lt;&lt;controller&gt;&gt; location {} on deck position has multiple reagents/empty containers assigned to it&#39;)
        found_errors = max(found_errors,2)
    return found_errors</code></pre>
</details>
</dd>
<dt id="controller.Controller.check_rxn_df"><code class="name flex">
<span>def <span class="ident">check_rxn_df</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Runs error checks on the reaction df to ensure that formating is correct. Illegal/Ill
Advised options are printed and if an error code is returned
Will run through and check all rows, even if errors are found
returns<br>
int found_errors:<br>
code:<br>
0: OK.<br>
1: Some Errors, but could run<br>
2: Critical. Abort</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_rxn_df(self):
    &#39;&#39;&#39;
    Runs error checks on the reaction df to ensure that formating is correct. Illegal/Ill 
    Advised options are printed and if an error code is returned
    Will run through and check all rows, even if errors are found
    returns  
        int found_errors:  
            code:  
            0: OK.  
            1: Some Errors, but could run  
            2: Critical. Abort  
    &#39;&#39;&#39;
    found_errors = 0
    for i, r in self.rxn_df.iterrows():
        r_num = i+1
        #check pauses
        if (not (&#39;pause&#39; in r[&#39;op&#39;] or &#39;pause&#39; in r[&#39;callbacks&#39;])) == (not pd.isna(r[&#39;pause_time&#39;])):
            print(&#34;&lt;&lt;controller&gt;&gt; You asked for a pause in row {}, but did not specify the pause_time or vice versa&#34;.format(r_num))
            found_errors = max(found_errors, 2)
        #check that there&#39;s always a volume when you transfer
        if (r[&#39;op&#39;] == &#39;transfer&#39; and math.isclose(r[self._products].sum(), 0,abs_tol=1e-9)):
            print(&#34;&lt;&lt;controller&gt;&gt; You executed a transfer step in row {}, but you did not transfer any volume.&#34;.format(r_num))
            found_errors = max(found_errors, 1)
        #check that you have a reagent if you&#39;re transfering
        if r[&#39;op&#39;] == &#39;transfer&#39; and pd.isna(r[&#39;reagent&#39;]):
            print(&#39;&lt;&lt;controller&gt;&gt; transfer specified without reagent in row {}&#39;.format(r_num))
            found_errors = max(found_errors,2)
    return found_errors</code></pre>
</details>
</dd>
<dt id="controller.Controller.close_connection"><code class="name flex">
<span>def <span class="ident">close_connection</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>runs through closing procedure with robot
<br>
Postconditions:
<br>
Log files have been written to self.out_path<br>
Connection has been closed</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def close_connection(self):
    &#39;&#39;&#39;
    runs through closing procedure with robot    
    Postconditions:    
        Log files have been written to self.out_path  
        Connection has been closed  
    &#39;&#39;&#39;
    print(&#39;&lt;&lt;controller&gt;&gt; initializing breakdown&#39;)
    self.save()
    #server should now send a close command
    self.portal.send_pack(&#39;close&#39;)
    print(&#39;&lt;&lt;controller&gt;&gt; shutting down&#39;)
    self.portal.close()</code></pre>
</details>
</dd>
<dt id="controller.Controller.execute_protocol_df"><code class="name flex">
<span>def <span class="ident">execute_protocol_df</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>takes a protocol df and sends every step to robot to execute<br>
params:<br>
int buff: the number of commands allowed in flight at a time<br>
Postconditions:<br>
every step in the protocol has been sent to the robot</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def execute_protocol_df(self):
    &#39;&#39;&#39;
    takes a protocol df and sends every step to robot to execute  
    params:  
        int buff: the number of commands allowed in flight at a time  
    Postconditions:  
        every step in the protocol has been sent to the robot  
    &#39;&#39;&#39;
    for i, row in self.rxn_df.iterrows():
        if row[&#39;op&#39;] == &#39;transfer&#39;:
            self._send_transfer_command(row,i)
        elif row[&#39;op&#39;] == &#39;pause&#39;:
            cid = self.portal.send_pack(&#39;pause&#39;,row[&#39;pause_time&#39;])
        elif row[&#39;op&#39;] == &#39;stop&#39;:
            #read through the inflight packets
            self.portal.send_pack(&#39;stop&#39;)
            self._stop(i)
        elif row[&#39;op&#39;] == &#39;scan&#39;:
            self._execute_scan(row, i)
        elif row[&#39;op&#39;] == &#39;dilution&#39;:
            self._send_dilution_commands(row, i)
        elif row[&#39;op&#39;] == &#39;mix&#39;:
            self._mix(row, i)
        elif row[&#39;op&#39;] == &#39;make&#39;:
            self._send_make(row, i)
        elif row[&#39;op&#39;] == &#39;save&#39;:
            self.save()
        elif row[&#39;op&#39;] == &#39;plot&#39;:
            self._create_plot(row, i)
        else:
            raise Exception(&#39;invalid operation {}&#39;.format(row[&#39;op&#39;]))</code></pre>
</details>
</dd>
<dt id="controller.Controller.init_robot"><code class="name flex">
<span>def <span class="ident">init_robot</span></span>(<span>self, simulate)</span>
</code></dt>
<dd>
<div class="desc"><p>this does the dirty work of sending accumulated params over network to the robot<br>
params:<br>
bool simulate: whether the robot should run a simulation<br>
Postconditions:<br>
robot has been initialized with necessary params</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def init_robot(self, simulate):
    &#39;&#39;&#39;
    this does the dirty work of sending accumulated params over network to the robot  
    params:  
        bool simulate: whether the robot should run a simulation  
    Postconditions:  
        robot has been initialized with necessary params  
    &#39;&#39;&#39;
    #send robot data to initialize itself
    cid = self.portal.send_pack(&#39;init&#39;, simulate, 
            self.robo_params[&#39;using_temp_ctrl&#39;], self.robo_params[&#39;temp&#39;],
            self.robo_params[&#39;labware_df&#39;].to_dict(), self.robo_params[&#39;instruments&#39;],
            self.robo_params[&#39;reagent_df&#39;].to_dict(), self.my_ip,
            self.robo_params[&#39;dry_containers&#39;].to_dict())</code></pre>
</details>
</dd>
<dt id="controller.Controller.plot_LAM_overlay"><code class="name flex">
<span>def <span class="ident">plot_LAM_overlay</span></span>(<span>self, df, wells, filename=None)</span>
</code></dt>
<dd>
<div class="desc"><p>plots overlayed spectra of wells in the order that they are specified<br>
params:<br>
df df: dataframe with columns = chem_names, and values of each column is a series
of scans in 701 intervals.<br>
str filename: the title of the plot, and the file<br>
list<str> wells: an ordered list of all of the chem_names you want to plot.<br>
Postconditions:<br>
plot has been written with name "overlay.png" to the plotting dir. or
{filename}.png if filename was supplied</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_LAM_overlay(self,df,wells,filename=None):
    &#39;&#39;&#39;
    plots overlayed spectra of wells in the order that they are specified  
    params:  
        df df: dataframe with columns = chem_names, and values of each column is a series
          of scans in 701 intervals.  
        str filename: the title of the plot, and the file  
        list&lt;str&gt; wells: an ordered list of all of the chem_names you want to plot.  
    Postconditions:  
        plot has been written with name &#34;overlay.png&#34; to the plotting dir. or 
        {filename}.png if filename was supplied  
    &#39;&#39;&#39;
    if not filename:
        filename = &#34;overlay&#34;
    x_vals = list(range(300,1001))
    #overlays only things you specify
    y = []
    #df = df[df_reorder]
    #headers = [well_key[k] for k in df.columns]
    #legend_colors = []
    for chem_name in wells:
        y.append(df[chem_name].iloc[-701:].to_list())
    self._plot_setup_overlay(filename)
    colors = list(cm.rainbow(np.linspace(0, 1,len(y))))
    for i in range(len(y)):
        plt.plot(x_vals,y[i],color = tuple(colors[i]))
    patches = [mpatches.Patch(color=color, label=label) for label, color in zip(wells, colors)]
    plt.legend(patches, wells, loc=&#39;upper right&#39;, frameon=False,prop={&#39;size&#39;:3})
    legend = pd.DataFrame({&#39;Color&#39;:patches,&#39;Labels&#39;: wells})
    plt.savefig(os.path.join(self.plot_path, &#39;{}.png&#39;.format(filename)))
    plt.close()</code></pre>
</details>
</dd>
<dt id="controller.Controller.plot_kin_subplots"><code class="name flex">
<span>def <span class="ident">plot_kin_subplots</span></span>(<span>self, df, n_cycles, wells, filename=None)</span>
</code></dt>
<dd>
<div class="desc"><p>TODO this function doesn't save properly, but it does show. Don't know issue<br>
plots kinetics for each well in the order given by wells.<br>
params:<br>
df df: the scan data<br>
int n_cycles: the number of cycles for the scan data<br>
list<str> wells: the wells you want to plot in order
Postconditions:<br>
plot has been written with name "{filename}_overlay.png" to the plotting dir.<br>
If filename is not supplied, name is kin_subplots</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_kin_subplots(self,df,n_cycles,wells,filename=None):
    &#39;&#39;&#39;
    TODO this function doesn&#39;t save properly, but it does show. Don&#39;t know issue  
    plots kinetics for each well in the order given by wells.  
    params:  
        df df: the scan data  
        int n_cycles: the number of cycles for the scan data  
        list&lt;str&gt; wells: the wells you want to plot in order
    Postconditions:  
        plot has been written with name &#34;{filename}_overlay.png&#34; to the plotting dir.  
        If filename is not supplied, name is kin_subplots
    &#39;&#39;&#39;
    if not filename:
        filename=kin_subplots
    x_vals = list(range(300,1001))
    colors = list(cm.rainbow(np.linspace(0, 1, n_cycles)))
    fig, axes = plt.subplots(8, 12, dpi=300, figsize=(50, 50),subplot_kw=dict(box_aspect=1,sharex = True,sharey = True))
    for idx, (chem_name, ax) in enumerate(zip(wells, axes.flatten())):
        ax.set_title(chem_name)
        self._plot_kin(ax, df, n_cycles, chem_name)
        plt.subplots_adjust(wspace=0.3, hspace= -0.1)
    
        ax.tick_params(
            which=&#39;both&#39;,
            bottom=&#39;off&#39;,
            left=&#39;off&#39;,
            right=&#39;off&#39;,
            top=&#39;off&#39;
        )
        ax.set_xlim((300,1000))
        ax.set_ylim((0,1.0))
        ax.set_xlabel(&#34;Wavlength (nm)&#34;)
        ax.set_ylabel(&#34;Absorbance (A.U.)&#34;)
        ax.set_xticks(range(301, 1100, 100))
        #ax.set_aspect(adjustable=&#39;box&#39;)
        #ax.set_yticks(range(0,1))
    else:
        [ax.set_visible(False) for ax in axes.flatten()[idx+1:]]
    plt.savefig(os.path.join(self.plot_path, &#39;{}.png&#39;.format(filename)))
    plt.close()</code></pre>
</details>
</dd>
<dt id="controller.Controller.plot_single_kin"><code class="name flex">
<span>def <span class="ident">plot_single_kin</span></span>(<span>self, df, n_cycles, chem_name, filename=None)</span>
</code></dt>
<dd>
<div class="desc"><p>plots one kinetics trace.
params:<br>
df df: the scan data<br>
int n_cycles: the number of cycles in per well scanned<br>
str chem_name: the name of the chemical to be plotted<br>
str filename: the name of the file to write<br>
Postconditions:<br>
A kinetics trace of the well has been written to the Plots directory.
under the name filename. If filename was None, the filename will be
{chem_name}_kinetics.png</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_single_kin(self, df, n_cycles, chem_name, filename=None):
    &#39;&#39;&#39;
    plots one kinetics trace. 
    params:  
        df df: the scan data  
        int n_cycles: the number of cycles in per well scanned  
        str chem_name: the name of the chemical to be plotted  
        str filename: the name of the file to write  
    Postconditions:  
        A kinetics trace of the well has been written to the Plots directory.
        under the name filename. If filename was None, the filename will be 
        {chem_name}_kinetics.png
    &#39;&#39;&#39;
    if not filename:
        filename = &#39;{}_kinetics&#39;.format(chem_name)
    self._plot_setup_overlay(&#39;Kinetics {}: &#39;.format(chem_name))
    self._plot_kin(plt,df, n_cycles, chem_name)
    plt.savefig(os.path.join(self.plot_path, &#39;{}.png&#39;.format(filename)))
    plt.close()</code></pre>
</details>
</dd>
<dt id="controller.Controller.run_all_checks"><code class="name flex">
<span>def <span class="ident">run_all_checks</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>it is expected that each subclass will implement a version of this method based
on the checks that they need to run.<br>
run_all_checks should run every appropriate pre rxn check</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def run_all_checks(self):
    &#39;&#39;&#39;
    it is expected that each subclass will implement a version of this method based
    on the checks that they need to run.  
    run_all_checks should run every appropriate pre rxn check  
    &#39;&#39;&#39;
    pass</code></pre>
</details>
</dd>
<dt id="controller.Controller.run_protocol"><code class="name flex">
<span>def <span class="ident">run_protocol</span></span>(<span>self, simulate)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def run_protocol(self,simulate):
    pass</code></pre>
</details>
</dd>
<dt id="controller.Controller.run_simulation"><code class="name flex">
<span>def <span class="ident">run_simulation</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@abstractmethod
def run_simulation(self):
    pass</code></pre>
</details>
</dd>
<dt id="controller.Controller.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self):
    self.portal.send_pack(&#39;save&#39;)
    #server will initiate file transfer
    files = self.portal.recv_ftp()
    for filename, file_bytes in files:
        with open(os.path.join(self.eve_files_path,filename), &#39;wb&#39;) as write_file:
            write_file.write(file_bytes)
    self.translate_wellmap()</code></pre>
</details>
</dd>
<dt id="controller.Controller.translate_wellmap"><code class="name flex">
<span>def <span class="ident">translate_wellmap</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Preconditions:<br>
there exists a file wellmap.tsv in self.eve_files, and that file has eve level
machine labels<br>
Postconditions:<br>
translated_wellmap.tsv has been created. translated is a copy of wellmap with <br>
it's locations translated to human locs, but the labware pos remains the same</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def translate_wellmap(self):
    &#39;&#39;&#39;
    Preconditions:  
        there exists a file wellmap.tsv in self.eve_files, and that file has eve level
        machine labels  
    Postconditions:  
        translated_wellmap.tsv has been created. translated is a copy of wellmap with   
        it&#39;s locations translated to human locs, but the labware pos remains the same  
    &#39;&#39;&#39;
    df = pd.read_csv(os.path.join(self.eve_files_path,&#39;wellmap.tsv&#39;), sep=&#39;\t&#39;)
    df[&#39;loc&#39;] = df.apply(lambda r: r[&#39;loc&#39;] if (r[&#39;deck_pos&#39;] not in [4,7]) else self.PLATEREADER_INDEX_TRANSLATOR.inv[(r[&#39;loc&#39;],&#39;platereader&#39;+str(r[&#39;deck_pos&#39;]))],axis=1)
    df.to_csv(os.path.join(self.eve_files_path,&#39;translated_wellmap.tsv&#39;),sep=&#39;\t&#39;,index=False)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="controller.DummyReader"><code class="flex name class">
<span>class <span class="ident">DummyReader</span></span>
<span>(</span><span>data_path)</span>
</code></dt>
<dd>
<div class="desc"><p>Inherits from AbstractPlateReader, so it has all of it's methods, but doesn't actually do
anything. useful for some simulations</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DummyReader(AbstractPlateReader):
    &#39;&#39;&#39;
    Inherits from AbstractPlateReader, so it has all of it&#39;s methods, but doesn&#39;t actually do
    anything. useful for some simulations
    &#39;&#39;&#39;
    pass</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="controller.AbstractPlateReader" href="#controller.AbstractPlateReader">AbstractPlateReader</a></li>
<li>abc.ABC</li>
</ul>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="controller.AbstractPlateReader" href="#controller.AbstractPlateReader">AbstractPlateReader</a></b></code>:
<ul class="hlist">
<li><code><a title="controller.AbstractPlateReader.edit_layout" href="#controller.AbstractPlateReader.edit_layout">edit_layout</a></code></li>
<li><code><a title="controller.AbstractPlateReader.exec_macro" href="#controller.AbstractPlateReader.exec_macro">exec_macro</a></code></li>
<li><code><a title="controller.AbstractPlateReader.load_reader_data" href="#controller.AbstractPlateReader.load_reader_data">load_reader_data</a></code></li>
<li><code><a title="controller.AbstractPlateReader.run_protocol" href="#controller.AbstractPlateReader.run_protocol">run_protocol</a></code></li>
<li><code><a title="controller.AbstractPlateReader.shake" href="#controller.AbstractPlateReader.shake">shake</a></code></li>
<li><code><a title="controller.AbstractPlateReader.shutdown" href="#controller.AbstractPlateReader.shutdown">shutdown</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="controller.PlateReader"><code class="flex name class">
<span>class <span class="ident">PlateReader</span></span>
<span>(</span><span>data_path, simulate=False)</span>
</code></dt>
<dd>
<div class="desc"><p>This class handles all platereader interactions. Inherits from the interface</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class PlateReader(AbstractPlateReader):
    &#39;&#39;&#39;
    This class handles all platereader interactions. Inherits from the interface
    &#39;&#39;&#39;
    SPECTRO_ROOT_PATH = &#34;/mnt/c/Program Files/SPECTROstar Nano V5.50/&#34;
    PROTOCOL_PATH = r&#34;C:\Program Files\SPECTROstar Nano V5.50\User\Definit&#34;
    SPECTRO_DATA_PATH = &#34;/mnt/c/Hendricks Lab/Plate Reader Data Backup&#34;

    def __init__(self, data_path, simulate=False):
        self.data_path = data_path
        self.simulate = simulate
        if not os.path.exists(self.data_path):
            os.makedirs(self.data_path)
        self._set_config_attr(&#39;Configuration&#39;,&#39;SimulationMode&#39;, str(int(simulate)))
        self._set_config_attr(&#39;ControlApp&#39;,&#39;AsDDEserver&#39;, &#39;True&#39;)
        self.exec_macro(&#34;dummy&#34;)
        self.exec_macro(&#34;init&#34;)
        self.exec_macro(&#39;PlateOut&#39;)
        
    def exec_macro(self, macro, *args):
        &#39;&#39;&#39;
        sends a macro command to the platereader and blocks waiting for response. If response
        not ok, it&#39;ll crash and burn  
        params:  
            str macro: should be a macro from the documentation  
            *args: associated arguments of the macto  
        Postconditions:  
            The command has been sent to the PlateReader, if the return status was not 0 (good)
            an error will be thrown  
        &#39;&#39;&#39;
        exec_str = &#34;&#39;{}Cln/DDEClient.exe&#39; {}&#34;.format(self.SPECTRO_ROOT_PATH, macro)
        #add arguments
        for arg in args:
            exec_str += &#34; &#39;{}&#39;&#34;.format(arg)
        print(&#39;&lt;&lt;Reader&gt;&gt; executing: {}&#39;.format(exec_str))
        exit_code = os.system(exec_str)
        try:
            assert (exit_code == 0)
        except:
            if exit_code &lt; 1000:
                raise Exception(&#34;PlateReader rejected command Error&#34;)
            elif exit_code == 1000:
                raise Exception(&#34;PlateReader Nonexistent Protocol Name Error&#34;)
            elif exit_code == 2000:
                raise Exception(&#34;PlateReader Communication Error&#34;)
            else:
                raise Exception(&#34;PlateReader Error. Exited with code {}&#34;.format(exit_code))

    def shake(self):
        &#39;&#39;&#39;
        executes a shake
        &#39;&#39;&#39;
        macro = &#34;Shake&#34;
        shake_type = 2
        shake_freq = 300
        shake_time = 60
        self.exec_macro(macro, shake_type, shake_freq, shake_time)

    def load_reader_data(self,filename, loc_to_name):
        &#39;&#39;&#39;
        takes in the filename of a reader output and returns a dataframe with the scan data
        loaded, and a dictionary with relevant metadata.  
        params:  
            str filename: the name of the file to read  
            dict&lt;str:str&gt; loc_to_name: maps location to name of reaction  
        returns:  
            df: the scan data for that file  
            dict&lt;str:obj&gt;: holds the metadata  
                str filename: the filename as you passed in  
                int n_cycles: the number of cycles  
        &#39;&#39;&#39;
        if self.simulate:
            return super().load_reader_data(filename, loc_to_name) #return dummy data
        else:
            #parse the metadata
            start_i, metadata = self._parse_metadata(filename, self.data_path)
            # Read data ignoring first metadata lines
            df = pd.read_csv(os.path.join(self.data_path,filename), skiprows=start_i,
                    header=None,index_col=0,na_values=[&#34;       -&#34;],encoding = &#39;latin1&#39;).T
            headers = [loc_to_name[x[:-1]] for x in df.columns]
            df.columns = headers
            df.dropna(inplace=True)
            df = df.astype(float)
            return df, metadata

    def _parse_metadata(self, filename):
        &#39;&#39;&#39;
        parses the meta data of a platereader output, and returns a dataframe of the scans
        and a dictionary of parameters  
        params:  
            str filename: the name of the file to be read  
        returns:  
            int: the index to start reading the dataframe at  
            dict&lt;str:obj&gt;: holds the metadata  
                str filename: the filename as you passed in  
                int n_cycles: the number of cycles  
        &#39;&#39;&#39;
        found_start = False
        i = 0
        n_cycles = None
        line = &#39;dowhile&#39;
        with open(os.path.join(self.data_path,filename), &#39;r&#39;,encoding=&#39;latin1&#39;) as file:
            while not found_start and line != &#39;&#39;:
                line = file.readline()
                if bool(re.match(r&#39;No\. of Cycles:&#39;,line)):
                    #is number of cycles
                    n_cycles = int((re.search(r&#39;\d+&#39;, line)).group(0))
                if line[:6] == &#39;T[Â°C]:&#39;:
                    while not bool(re.match(&#39;\D\d&#39;,line)) and line != &#39;&#39;:
                        #is not of form A1/B03 etc
                        line = file.readline()
                        i += 1
                    i -= 1 #cause you will increment once more 
                    found_start = True
                i+=1
        assert (line != &#39;&#39;), &#34;corrupt reader file. ran out of file to read before finding a scanned well&#34;
        assert (n_cycles != None), &#34;corrupt reader file. num cycles not found.&#34;
        return i, {&#39;n_cycles&#39;:n_cycles,&#39;filename&#39;:filename}

    def edit_layout(self, protocol_name, layout):
        &#39;&#39;&#39;
        This protocol creates a temporary file, .temp_ot2_bmg_layout.lb
        in the SPECTROstar root. It is also possible (theoretically) to 
        send a literal &#39;edit_layout&#39; command, but this fails for long
        strings. (not sure why, maybe windows limited sized strings?
        but the file works). It removes the file after importing  
        params:  
            str protocol_name: the name of the protocol that will be edited  
            list&lt;str&gt; wells: the wells that you want to be used for the protocol ordered.
              (first will be X1, second X2 etc. If layout is all, all wells will be made X  
        Postcondtions:  
            The protocol has had it&#39;s layout updated to include only the wells specified  
        &#39;&#39;&#39;
        if layout == &#39;all&#39;:
            #get a list of all the wellanmes
            layout = [a+str(i) for a in list(&#39;ABCDEFGH&#39;) for i in range(1,13,1)]
        well_entries = []
        for i, well in enumerate(layout):
            well_entries.append(&#34;{}=X{}&#34;.format(well, i+1))
        filepath_lin = os.path.join(self.SPECTRO_ROOT_PATH,&#39;.temp_ot2_bmg_layout.lb&#39;)
        filepath_win = os.path.join(wslpath(self.SPECTRO_ROOT_PATH,&#39;w&#39;),&#39;.temp_ot2_bmg_layout.lb&#39;)
        with open(filepath_lin, &#39;w+&#39;) as layout:
            layout.write(&#39;EmptyLayout&#39;)
            for entry in well_entries:
                layout.write(&#34;\n{}&#34;.format(entry))
        self.exec_macro(&#39;ImportLayout&#39;, protocol_name, self.PROTOCOL_PATH, filepath_win)
        os.remove(filepath_lin)

    def run_protocol(self, protocol_name, filename, layout=None):
        r&#39;&#39;&#39;
        params:  
            str protocol_name: the name of the protocol that will be edited  
            list&lt;str&gt; layout: the wells that you want to be used for the protocol ordered.
              (first will be X1, second X2 etc. If not specified will not alter layout)  
        &#39;&#39;&#39;
        if layout:
            self.edit_layout(protocol_name, layout)
        macro = &#39;run&#39;
        #three &#39;&#39; are plate ids to pad. data_path specified once for ascii and once for other
        self.exec_macro(macro, protocol_name, self.PROTOCOL_PATH, wslpath(self.SPECTRO_DATA_PATH,&#39;w&#39;), &#39;&#39;, &#39;&#39;, &#39;&#39;, &#39;&#39;, filename)
        #Note, here I am clearly passing in a save path for the file, but BMG tends to ignore
        #that, so we move it from the default landing zone to where I actually want it
        if not self.simulate:
            shutil.move(os.path.join(self.SPECTRO_DATA_PATH, &#34;{}.csv&#34;.format(filename)), 
                    os.path.join(self.data_path, &#34;{}.csv&#34;.format(filename)))


    def _set_config_attr(self, header, attr, val):
        &#39;&#39;&#39;
        opens the Spectrostar nano config file and replaces the value of attr under header
        with val
        There are better ways to build this function, but it&#39;s not something you&#39;ll use much
        so I&#39;m leaving it here  
        params:  
            str header: the header in the config file [header]  
            str attr: the attribute you want to change  
            obj val: the value to set the attribute to  
        Postconditions:  
            The SPECTROstar Nano.ini has had the attribute under the header overwritten with val
            or appended to end if it wasn&#39;t found   
        &#39;&#39;&#39;
        with open(os.path.join(self.SPECTRO_ROOT_PATH, r&#39;SPECTROstar Nano.ini&#39;), &#39;r&#39;) as config:
            file_str = config.readlines()
            write_str = &#39;&#39;
            header_exists = False
            i = 0
            while i &lt; len(file_str): #iterating through lines
                line = file_str[i]
                write_str += line
                if line[1:-2] == header:
                    header_exists = True#you found the appropriate header
                    i += 1
                    found_attr = False
                    line = file_str[i] #do
                    while &#39;[&#39; != line[0] and i &lt; len(file_str): #not a header and not EOF
                        if line[:line.find(&#39;=&#39;)] == attr:
                            found_attr = True
                            write_str += &#39;{}={}\n&#39;.format(attr, val)
                        else:
                            write_str += line
                        i += 1
                        if i &lt; len(file_str):
                            line = file_str[i]
                    if not found_attr:
                        write_str += &#39;{}={}\n&#39;.format(attr, val)
                else:
                    i += 1
            if not header_exists:
                write_str += &#39;[{}]\n&#39;.format(header)
                write_str += &#39;{}={}\n&#39;.format(attr, val)

        with open(os.path.join(self.SPECTRO_ROOT_PATH, r&#39;SPECTROstar Nano.ini&#39;), &#39;w+&#39;) as config:
            config.write(write_str)

    def shutdown(self):
        &#39;&#39;&#39;
        closes connection. Use this if you&#39;re done with this object at cleanup stage
        &#39;&#39;&#39;
        self.exec_macro(&#39;PlateIn&#39;)
        self.exec_macro(&#39;Terminate&#39;)
        self._set_config_attr(&#39;ControlApp&#39;,&#39;AsDDEserver&#39;,&#39;False&#39;)
        self._set_config_attr(&#39;ControlApp&#39;, &#39;DisablePlateCmds&#39;,&#39;False&#39;)
        self._set_config_attr(&#39;Configuration&#39;,&#39;SimulationMode&#39;, str(0))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="controller.AbstractPlateReader" href="#controller.AbstractPlateReader">AbstractPlateReader</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="controller.PlateReader.PROTOCOL_PATH"><code class="name">var <span class="ident">PROTOCOL_PATH</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="controller.PlateReader.SPECTRO_DATA_PATH"><code class="name">var <span class="ident">SPECTRO_DATA_PATH</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="controller.PlateReader.SPECTRO_ROOT_PATH"><code class="name">var <span class="ident">SPECTRO_ROOT_PATH</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="controller.PlateReader.edit_layout"><code class="name flex">
<span>def <span class="ident">edit_layout</span></span>(<span>self, protocol_name, layout)</span>
</code></dt>
<dd>
<div class="desc"><p>This protocol creates a temporary file, .temp_ot2_bmg_layout.lb
in the SPECTROstar root. It is also possible (theoretically) to
send a literal 'edit_layout' command, but this fails for long
strings. (not sure why, maybe windows limited sized strings?
but the file works). It removes the file after importing<br>
params:<br>
str protocol_name: the name of the protocol that will be edited<br>
list<str> wells: the wells that you want to be used for the protocol ordered.
(first will be X1, second X2 etc. If layout is all, all wells will be made X<br>
Postcondtions:<br>
The protocol has had it's layout updated to include only the wells specified</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def edit_layout(self, protocol_name, layout):
    &#39;&#39;&#39;
    This protocol creates a temporary file, .temp_ot2_bmg_layout.lb
    in the SPECTROstar root. It is also possible (theoretically) to 
    send a literal &#39;edit_layout&#39; command, but this fails for long
    strings. (not sure why, maybe windows limited sized strings?
    but the file works). It removes the file after importing  
    params:  
        str protocol_name: the name of the protocol that will be edited  
        list&lt;str&gt; wells: the wells that you want to be used for the protocol ordered.
          (first will be X1, second X2 etc. If layout is all, all wells will be made X  
    Postcondtions:  
        The protocol has had it&#39;s layout updated to include only the wells specified  
    &#39;&#39;&#39;
    if layout == &#39;all&#39;:
        #get a list of all the wellanmes
        layout = [a+str(i) for a in list(&#39;ABCDEFGH&#39;) for i in range(1,13,1)]
    well_entries = []
    for i, well in enumerate(layout):
        well_entries.append(&#34;{}=X{}&#34;.format(well, i+1))
    filepath_lin = os.path.join(self.SPECTRO_ROOT_PATH,&#39;.temp_ot2_bmg_layout.lb&#39;)
    filepath_win = os.path.join(wslpath(self.SPECTRO_ROOT_PATH,&#39;w&#39;),&#39;.temp_ot2_bmg_layout.lb&#39;)
    with open(filepath_lin, &#39;w+&#39;) as layout:
        layout.write(&#39;EmptyLayout&#39;)
        for entry in well_entries:
            layout.write(&#34;\n{}&#34;.format(entry))
    self.exec_macro(&#39;ImportLayout&#39;, protocol_name, self.PROTOCOL_PATH, filepath_win)
    os.remove(filepath_lin)</code></pre>
</details>
</dd>
<dt id="controller.PlateReader.exec_macro"><code class="name flex">
<span>def <span class="ident">exec_macro</span></span>(<span>self, macro, *args)</span>
</code></dt>
<dd>
<div class="desc"><p>sends a macro command to the platereader and blocks waiting for response. If response
not ok, it'll crash and burn<br>
params:<br>
str macro: should be a macro from the documentation<br>
*args: associated arguments of the macto<br>
Postconditions:<br>
The command has been sent to the PlateReader, if the return status was not 0 (good)
an error will be thrown</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def exec_macro(self, macro, *args):
    &#39;&#39;&#39;
    sends a macro command to the platereader and blocks waiting for response. If response
    not ok, it&#39;ll crash and burn  
    params:  
        str macro: should be a macro from the documentation  
        *args: associated arguments of the macto  
    Postconditions:  
        The command has been sent to the PlateReader, if the return status was not 0 (good)
        an error will be thrown  
    &#39;&#39;&#39;
    exec_str = &#34;&#39;{}Cln/DDEClient.exe&#39; {}&#34;.format(self.SPECTRO_ROOT_PATH, macro)
    #add arguments
    for arg in args:
        exec_str += &#34; &#39;{}&#39;&#34;.format(arg)
    print(&#39;&lt;&lt;Reader&gt;&gt; executing: {}&#39;.format(exec_str))
    exit_code = os.system(exec_str)
    try:
        assert (exit_code == 0)
    except:
        if exit_code &lt; 1000:
            raise Exception(&#34;PlateReader rejected command Error&#34;)
        elif exit_code == 1000:
            raise Exception(&#34;PlateReader Nonexistent Protocol Name Error&#34;)
        elif exit_code == 2000:
            raise Exception(&#34;PlateReader Communication Error&#34;)
        else:
            raise Exception(&#34;PlateReader Error. Exited with code {}&#34;.format(exit_code))</code></pre>
</details>
</dd>
<dt id="controller.PlateReader.load_reader_data"><code class="name flex">
<span>def <span class="ident">load_reader_data</span></span>(<span>self, filename, loc_to_name)</span>
</code></dt>
<dd>
<div class="desc"><p>takes in the filename of a reader output and returns a dataframe with the scan data
loaded, and a dictionary with relevant metadata.<br>
params:<br>
str filename: the name of the file to read<br>
dict<str:str> loc_to_name: maps location to name of reaction<br>
returns:<br>
df: the scan data for that file<br>
dict<str:obj>: holds the metadata<br>
str filename: the filename as you passed in<br>
int n_cycles: the number of cycles</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_reader_data(self,filename, loc_to_name):
    &#39;&#39;&#39;
    takes in the filename of a reader output and returns a dataframe with the scan data
    loaded, and a dictionary with relevant metadata.  
    params:  
        str filename: the name of the file to read  
        dict&lt;str:str&gt; loc_to_name: maps location to name of reaction  
    returns:  
        df: the scan data for that file  
        dict&lt;str:obj&gt;: holds the metadata  
            str filename: the filename as you passed in  
            int n_cycles: the number of cycles  
    &#39;&#39;&#39;
    if self.simulate:
        return super().load_reader_data(filename, loc_to_name) #return dummy data
    else:
        #parse the metadata
        start_i, metadata = self._parse_metadata(filename, self.data_path)
        # Read data ignoring first metadata lines
        df = pd.read_csv(os.path.join(self.data_path,filename), skiprows=start_i,
                header=None,index_col=0,na_values=[&#34;       -&#34;],encoding = &#39;latin1&#39;).T
        headers = [loc_to_name[x[:-1]] for x in df.columns]
        df.columns = headers
        df.dropna(inplace=True)
        df = df.astype(float)
        return df, metadata</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="controller.AbstractPlateReader" href="#controller.AbstractPlateReader">AbstractPlateReader</a></b></code>:
<ul class="hlist">
<li><code><a title="controller.AbstractPlateReader.run_protocol" href="#controller.AbstractPlateReader.run_protocol">run_protocol</a></code></li>
<li><code><a title="controller.AbstractPlateReader.shake" href="#controller.AbstractPlateReader.shake">shake</a></code></li>
<li><code><a title="controller.AbstractPlateReader.shutdown" href="#controller.AbstractPlateReader.shutdown">shutdown</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="controller.ProtocolExecutor"><code class="flex name class">
<span>class <span class="ident">ProtocolExecutor</span></span>
<span>(</span><span>rxn_sheet_name, my_ip, server_ip, buff_size=4, use_cache=False)</span>
</code></dt>
<dd>
<div class="desc"><p>class to execute a protocol from the docs<br>
ATTRIBUTES:<br>
df rxn_df: the reaction df. Not passed in, but created in init<br>
INHERITED ATTRIBUTES:<br>
armchair.Armchair portal, str rxn_sheet_name, str cache_path, bool use_cache, <br>
str eve_files_path, str debug_path, str my_ip, str server_ip,<br>
dict<str:object> robo_params, bool simulate, int buff_size<br>
PRIVATE ATTRS:<br>
pd.index _products: the product columns<br>
INHERITED PRIVATE ATTRS:<br>
dict<str:tuple\<obj>> _cached_reader_locs<br>
METHODS:<br>
execute_protocol_df() void: used to execute a single row of the reaction df<br>
run_all_checks() void: wrapper for pre rxn error checking to handle any found errors
run automatically when you run your simulation<br>
CHECKS: all print messages for errors and return error codes<br>
check_rxn_df() int: checks for errors in input.<br>
check_labware() int: checks for errors in labware/labware assignments. <br>
check_products() int: checks for errors in the product placement.<br>
check_reagents() int: checks for errors in the reagent_info tab.<br>
TESTS: These are run after a reaction concludes to make sure things went well<br>
run_all_tests() bool: True if you passed, else false. run when at end of simulation<br>
test_vol_lab_cont() bool: tests that labware volume and containers are correct<br>
test_contents() bool: tests that the contents of each container is ok<br>
INHERITED METHODS:<br>
run_protocol(simulate, port) void, close_connection() void, init_robot(simulate),
translate_wellmap() void, run_simulation() bool
</p>
<p>Note that init does not initialize the portal. This must be done explicitly or by calling
a run function that creates a portal. The portal is not passed to init because although
the code must not use more than one portal at a time, the portal may change over the
lifetime of the class
NOte that pr cannot be initialized until you know if you're simulating or not, so it
is instantiated in run</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ProtocolExecutor(Controller): 
    &#39;&#39;&#39;
    class to execute a protocol from the docs  
    ATTRIBUTES:  
        df rxn_df: the reaction df. Not passed in, but created in init  
    INHERITED ATTRIBUTES:  
        armchair.Armchair portal, str rxn_sheet_name, str cache_path, bool use_cache,   
        str eve_files_path, str debug_path, str my_ip, str server_ip,  
        dict&lt;str:object&gt; robo_params, bool simulate, int buff_size  
    PRIVATE ATTRS:  
        pd.index _products: the product columns  
    INHERITED PRIVATE ATTRS:  
        dict&lt;str:tuple&lt;obj&gt;&gt; _cached_reader_locs  
    METHODS:  
        execute_protocol_df() void: used to execute a single row of the reaction df  
        run_all_checks() void: wrapper for pre rxn error checking to handle any found errors
          run automatically when you run your simulation  
        CHECKS: all print messages for errors and return error codes  
        check_rxn_df() int: checks for errors in input.  
        check_labware() int: checks for errors in labware/labware assignments.   
        check_products() int: checks for errors in the product placement.  
        check_reagents() int: checks for errors in the reagent_info tab.  
        TESTS: These are run after a reaction concludes to make sure things went well  
        run_all_tests() bool: True if you passed, else false. run when at end of simulation  
        test_vol_lab_cont() bool: tests that labware volume and containers are correct  
        test_contents() bool: tests that the contents of each container is ok  
    INHERITED METHODS:  
        run_protocol(simulate, port) void, close_connection() void, init_robot(simulate), 
        translate_wellmap() void, run_simulation() bool  
    &#39;&#39;&#39;

    def __init__(self, rxn_sheet_name, my_ip, server_ip, buff_size=4, use_cache=False):
        &#39;&#39;&#39;
        Note that init does not initialize the portal. This must be done explicitly or by calling
        a run function that creates a portal. The portal is not passed to init because although
        the code must not use more than one portal at a time, the portal may change over the 
        lifetime of the class
        NOte that pr cannot be initialized until you know if you&#39;re simulating or not, so it
        is instantiated in run
        &#39;&#39;&#39;
        super().__init__(rxn_sheet_name, my_ip, server_ip, buff_size, use_cache)

    def run_simulation(self):
        &#39;&#39;&#39;
        runs a full simulation of the protocol with
        Temporarilly overwrites the self.server_ip with loopback, but will restore it at
        end of function  
        Returns:  
            bool: True if all tests were passed  
        &#39;&#39;&#39;
        #cache some things before you overwrite them for the simulation
        stored_server_ip = self.server_ip
        stored_simulate = self.simulate
        self.server_ip = &#39;127.0.0.1&#39;
        self.simulate = True

        print(&#39;&lt;&lt;controller&gt;&gt; ENTERING SIMULATION&#39;)
        port = 50000
        #launch an eve server in background for simulation purposes
        b = threading.Barrier(2,timeout=20)
        eve_thread = threading.Thread(target=launch_eve_server, kwargs={&#39;my_ip&#39;:&#39;&#39;,&#39;barrier&#39;:b},name=&#39;eve_thread&#39;)
        eve_thread.start()

        #do create a connection
        b.wait()
        self._run(port, simulate=True)

        #run post execution tests
        tests_passed = self.run_all_tests()

        #collect the eve thread
        eve_thread.join()

        #restore changed vars
        self.server_ip = stored_server_ip
        self.simulate = stored_simulate
        print(&#39;&lt;&lt;controller&gt;&gt; EXITING SIMULATION&#39;)
        return tests_passed

    def run_protocol(self, simulate=False, port=50000):
        &#39;&#39;&#39;
        The real deal. Input a server addr and port if you choose and protocol will be run  
        params:  
            str simulate: (this should never be used in normal operation. It is for debugging
              on the robot)  
        NOTE: the simulate here is a little different than running run_simulation(). This simulate
          is sent to the robot to tell it to simulate the reaction, but that it all. The other
          simulate changes some things about how code is run from the controller
        &#39;&#39;&#39;
        print(&#39;&lt;&lt;controller&gt;&gt; RUNNING PROTOCOL&#39;)
        self._run(port, simulate=simulate)
        print(&#39;&lt;&lt;controller&gt;&gt; EXITING PROTOCOL&#39;)
        
    @error_exit
    def _run(self, port, simulate):
        &#39;&#39;&#39;
        Returns:  
            bool: True if all tests were passed  
        &#39;&#39;&#39;
        self._init_pr(simulate)
        #create a connection
        sock = socket.socket(socket.AF_INET)
        sock.connect((self.server_ip, port))
        buffered_sock = BufferedSocket(sock, maxsize=1e9, timeout=None)
        print(&#34;&lt;&lt;controller&gt;&gt; connected&#34;)
        self.portal = Armchair(buffered_sock,&#39;controller&#39;,&#39;Armchair_Logs&#39;, buffsize=4)

        self.init_robot(simulate)
        self.execute_protocol_df()
        self.close_connection()
        self.pr.shutdown()

    def init_robot(self,simulate):
        &#39;&#39;&#39;
        calls super init robot, and then sends an init_containers command to initialize all the
        prodcuts  
        params:  
            bool simulate: whether the robot should run a simulation  
        &#39;&#39;&#39;
        super().init_robot(simulate)
        #send robot data to initialize empty product containers. Because we know things like total
        #vol and desired labware, this makes sense for a planned experiment
        self.portal.send_pack(&#39;init_containers&#39;, self.robo_params[&#39;product_df&#39;].to_dict())
    
    def _rename_products(self, rxn_df):
        &#39;&#39;&#39;
        renames dilutions acording to the reagent that created them
        and renames rxns to have a concentration  
        Preconditions:  
            dilution cols are named dilution_1/2 etc  
            callback is the last column in the dataframe  
            rxn_df is not expected to be initialized yet. This is a helper for the initialization  
        params:  
            df rxn_df: the dataframe with all the reactions  
        Postconditions:  
            the df has had it&#39;s dilution columns renamed to the chemical used to produce it + C&lt;conc&gt;  
            rxn columns have C1 appended to them  
        &#39;&#39;&#39;
        dilution_cols = [col for col in rxn_df.columns if &#39;dilution_placeholder&#39; in col]
        #get the rxn col names
        rxn_cols = rxn_df.loc[:, &#39;reagent&#39;:&#39;chemical_name&#39;].drop(columns=[&#39;reagent&#39;,&#39;chemical_name&#39;]).columns
        rename_key = {}
        for col in rxn_cols:
            if &#39;dilution_placeholder&#39; in col:
                row = rxn_df.loc[~rxn_df[col].isna()].squeeze()
                reagent_name = row[&#39;chemical_name&#39;]
                name = reagent_name[:reagent_name.rfind(&#39;C&#39;)+1]+str(row[&#39;dilution_conc&#39;])
                rename_key[col] = name
            else:
                rename_key[col] = &#34;{}C1.0&#34;.format(col).replace(&#39; &#39;,&#39;_&#39;)
        rxn_df.rename(rename_key, axis=1, inplace=True)

    def _get_rxn_max_vol(self, name, products):
        &#39;&#39;&#39;
        Preconditions:  
            volume in a container can change only during a &#39;transfer&#39; or &#39;dilution&#39;. Easy to add more
            by changing the vol_change_rows
            self.rxn_df is initialized  
        params:  
            str name: the column name to be searched  
            list&lt;str&gt; products: the column names of all reagents (we could look this up in rxn_df, but
              convenient to pass it in)  
        returns:  
            float: the maximum volume that this container will ever hold at one time, not taking into 
              account aspirations for dilutions  
        &#39;&#39;&#39;
        vol_change_rows = self.rxn_df.loc[self.rxn_df[&#39;op&#39;].apply(lambda x: x in [&#39;transfer&#39;,&#39;dilution&#39;])]
        aspirations = vol_change_rows[&#39;chemical_name&#39;] == name
        max_vol = 0
        current_vol = 0
        for i, is_aspiration in aspirations.iteritems():
            if is_aspiration and self.rxn_df.loc[i,&#39;op&#39;] == &#39;transfer&#39;:
                #This is a row where we&#39;re transfering from this well
                current_vol -= self.rxn_df.loc[i, products].sum()
            elif is_aspiration and self.rxn_df.loc[i, &#39;op&#39;] == &#39;dilution&#39;:
                _, transfer_row = self._get_dilution_transfer_rows(self.rxn_df.loc[i])
                vol = transfer_row[self._products].sum() 
                current_vol -= vol
            else:
                current_vol += self.rxn_df.loc[i,name]
                max_vol = max(max_vol, current_vol)
        return max_vol

    
    #TESTING
    #PRE Simulation
    def run_all_checks(self):
        found_errors = 0
        found_errors = max(found_errors, self.check_rxn_df())
        found_errors = max(found_errors, self.check_labware())
        found_errors = max(found_errors, self.check_reagents())
        found_errors = max(found_errors, self.check_products())
        if found_errors == 0:
            print(&#34;&lt;&lt;controller&gt;&gt; All prechecks passed!&#34;)
            return
        elif found_errors == 1:
            if &#39;y&#39;==input(&#34;&lt;&lt;controller&gt;&gt; Please check the above errors and if you would like to ignore them and continue enter &#39;y&#39; else any key&#34;):
                return
            else:
                raise Exception(&#39;Aborting base on user input&#39;)
        elif found_errors == 2:
            raise Exception(&#39;Critical Errors encountered during prechecks. Aborting&#39;)

                
    def check_products(self):
        &#39;&#39;&#39;
        checks to ensure that the products were correctly initialized  
        returns  
            int found_errors:  
                code:  
                0: OK.  
                1: Some Errors, but could run  
                2: Critical. Abort  
        &#39;&#39;&#39;
        found_errors = 0
        for i, r in self.robo_params[&#39;product_df&#39;].loc[\
                ~self.robo_params[&#39;product_df&#39;][&#39;labware&#39;].astype(bool) &amp; \
                ~self.robo_params[&#39;product_df&#39;][&#39;container&#39;].astype(bool)].iterrows():
            found_errors = max(found_errors,1)
            print(&#39;&lt;&lt;controller&gt;&gt; {} has no specified labware or container. It could end up in anything that has enough volume to contain it. Are you sure that\&#39;s what you want? &#39;.format(i))
        return found_errors

    #POST Simulation
    def run_all_tests(self):
        &#39;&#39;&#39;
        runs all post rxn tests  
        Returns:  
            bool: True if all tests were passed  
        &#39;&#39;&#39;
        print(&#39;&lt;&lt;controller&gt;&gt; running post execution tests&#39;)
        valid = True
        valid = valid and self.test_vol_lab_cont()
        valid = valid and self.test_contents()
        return valid

    def test_vol_lab_cont(self):
        &#39;&#39;&#39;
        tests that vol, labware, and containers are correct for a row of a side by side df with
        those attributes  
        Preconditions:  
            labware_df, reagent_df, and products_df are all initialized as vals in robo_params  
            self.rxn_df is initialized  
            df labware_df:  
            df rxn_df: as from excel  
            df reagent_df: info on reagents. columns from sheet. See excel specification  
            df product_df:  
            self.eve_files_path + wellmap.tsv exists (this is a file output by eve that is shipped
              over in close step  
        Postconditions:  
            Any errors will be printed to the screen.  
            If errors were found, a pkl of the sbs will be written  
        Returns:  
            bool: True if all tests were passed  
        &#39;&#39;&#39;
        sbs = self._get_vol_lab_cont_sbs()
        sbs[&#39;flag&#39;] = sbs.apply(lambda row: self._is_valid_vol_lab_cont_sbs(row), axis=1)
        filtered_sbs = sbs.loc[~sbs[&#39;flag&#39;]]
        if filtered_sbs.empty:
            print(&#39;&lt;&lt;controller&gt;&gt; congrats! Volumes, labware, containers, and deck_poses look good!&#39;)
        else:
            print(&#39;&lt;&lt;controller&gt;&gt; volume/deck pos/labware/container errors&#39;)
            with open(os.path.join(self.debug_path,&#39;vol_lab_cont_sbs.pkl&#39;), &#39;wb&#39;) as sbs_pkl:
                dill.dump(sbs, sbs_pkl)
            if input(&#39;&lt;&lt;controller&gt;&gt; would you like to view the full sbs? [yn] &#39;).lower() == &#39;y&#39;:
                print(sbs)
            return False
        return True

    def test_contents(self):
        &#39;&#39;&#39;
        tests to ensure that the contents of each container is correct
        note does not work for dilutions, and does not check reagents  
        params:  
            df rxn_df: from excel  
            bool use_cache: True if data is cached  
            str eve_logpath: the path to the eve logfiles  
        Postconditions:  
            if a difference was found it will be displayed,  
            if no differences are found, a friendly print message will be displayed  
        Returns:  
            bool: True if all tests were passed  
        &#39;&#39;&#39;
        sbs = self._create_contents_sbs()
        sbs[&#39;flag&#39;] = sbs.apply(self._is_valid_contents_sbs,axis=1)
        filtered_sbs = sbs.loc[~sbs[&#39;flag&#39;]]
        if filtered_sbs.empty:
            print(&#39;&lt;&lt;controller&gt;&gt; congrats! Contents are correct!&#39;)
        else:
            print(&#39;&lt;&lt;controller&gt;&gt; there ere some content errors&#39;)
            with open(os.path.join(self.debug_path,&#39;contents_sbs.pkl&#39;), &#39;wb&#39;) as sbs_pkl:
                dill.dump(sbs, sbs_pkl)
            if input(&#39;&lt;&lt;controller&gt;&gt; would you like to view the full sbs? [yn] &#39;).lower() == &#39;y&#39;:
                print(sbs)
            return False
        return True

    def _is_valid_vol_lab_cont_sbs(self, row):
        &#39;&#39;&#39;
        params:  
            pd.Series row: a row of a sbs dataframe:  
        returns:  
            Bool: True if it is a valid row  
        &#39;&#39;&#39;
        if row[&#39;deck_pos_t&#39;] != &#39;any&#39; and row[&#39;deck_pos&#39;] not in row[&#39;deck_pos_t&#39;]:
            print(&#39;&lt;&lt;controller&gt;&gt; deck_pos_error:&#39;)
            print(row.to_frame().T)
            print()
            return False
        if row[&#39;vol_t&#39;] != &#39;any&#39; and not math.isclose(row[&#39;vol&#39;],row[&#39;vol_t&#39;], abs_tol=1e-9):
            print(&#39;&lt;&lt;controller&gt;&gt; volume error:&#39;)
            print(row.to_frame().T)
            print()
            return False
        if row[&#39;container_t&#39;] != &#39;any&#39; and not row[&#39;container&#39;] == row[&#39;container_t&#39;]:
            print(&#39;&lt;&lt;controller&gt;&gt; container error:&#39;)
            print(row.to_frame().T)
            print()
            return False
        if row[&#39;loc_t&#39;] != &#39;any&#39; and row[&#39;loc&#39;] not in row[&#39;loc_t&#39;]:
            print(&#39;&lt;&lt;controller&gt;&gt; loc error:&#39;)
            print(row.to_frame().T)
            print()
            return False
        return True
    
    def _get_vol_lab_cont_sbs(self):
        &#39;&#39;&#39;
        This is for comparing the volumes, labwares, and containers  
        params:  
        Preconditions:  
            labware_df, reagent_df, and products_df are all initialized as vals in robo_params  
            self.rxn_df is initialized  
            df labware_df:  
            df rxn_df: as from excel  
            df reagent_df: info on reagents. columns from sheet. See excel specification  
            df product_df:  
            self.eve_files_path + wellmap.tsv exists (this is a file output by eve that is shipped
              over in close step  
        returns  
            df  
                + INDEX
                + chemical_name: the containers name
                + COLS: symmetric. Theoretical are suffixed _t
                + str deck_pos: position on deck
                + float vol: the volume in the container
                + list&lt;tuple&lt;str, float&gt;&gt; history: the chem_name paired with the amount or
                  keyword &#39;aspirate&#39; and vol
        &#39;&#39;&#39;
        #copy the locals cause we&#39;re changing them
        labware_df = self.robo_params[&#39;labware_df&#39;].set_index(&#39;name&#39;).rename(index={&#39;platereader7&#39;:&#39;platereader&#39;,&#39;platereader4&#39;:&#39;platereader&#39;}) #converting to dict like
        product_df = self.robo_params[&#39;product_df&#39;].copy()
        reagent_df = self.robo_params[&#39;reagent_df&#39;].copy()
        #create a df with sets of allowable locs and deck_poses
        def get_dry_container_cols(df):
            &#39;&#39;&#39;
            apply helper func to combine the rows of the dry_containers_df
            &#39;&#39;&#39;
            d = {&#39;loc&#39;:set(),&#39;deck_pos&#39;:set()}
            for i, r in df.iterrows():
                d[&#39;loc&#39;].add(r[&#39;loc&#39;])
                d[&#39;deck_pos&#39;].add(r[&#39;deck_pos&#39;])
            return pd.Series(d)
        dry_containers = self.robo_params[&#39;dry_containers&#39;].groupby(&#39;index&#39;).apply(get_dry_container_cols)
        def get_deck_pos(labware):
            &#39;&#39;&#39;
            apply helper func to get the deck position for products
            &#39;&#39;&#39;
            if labware:
                deck_pos = labware_df.loc[labware,&#39;deck_pos&#39;]
                if isinstance(deck_pos,np.int64):
                    return [deck_pos]
                else:
                    #for platereader with two indices
                    return deck_pos.to_list()
            else:
                return &#39;any&#39;
        product_df[&#39;deck_pos&#39;] = product_df[&#39;labware&#39;].apply(get_deck_pos)
        product_df[&#39;vol&#39;] = [self._vol_calc(name) for name in product_df.index]
        product_df[&#39;loc&#39;] = &#39;any&#39;
        product_df.replace(&#39;&#39;,&#39;any&#39;, inplace=True)

        #because reagents can be built, we now need to ensure that you end up with something 
        #that could be on a new set of labware for reagents
        reagent_df[&#39;deck_pos&#39;] = reagent_df[&#39;deck_pos&#39;].apply(lambda x: {x})
        reagent_df[&#39;loc&#39;] = reagent_df[&#39;loc&#39;].apply(lambda x: {x})
        reagent_df[&#39;vol&#39;] = &#39;any&#39; #I&#39;m not checking this because it&#39;s harder to check, and works fine
        reagent_df[&#39;container&#39;] = &#39;any&#39; #actually fixed, but checked by combo deck_pos and loc
        def merge_dry(row):
            &#39;&#39;&#39;
            apply helper to merge a reagent_df with a dry_container_df  
            Note, this is meant to be applied to the reagent_df, so it doesn&#39;t generate
            new rows if necessary. That must be done seperately.  
            &#39;&#39;&#39;
            d = {&#39;loc&#39;:{}, &#39;deck_pos&#39;:{}}
            found_match = False
            for name in dry_containers.index.unique():
                if name in row.name:
                    d[&#39;loc&#39;] = dry_containers.loc[name,&#39;loc&#39;].union(row[&#39;loc&#39;])
                    d[&#39;deck_pos&#39;] = dry_containers.loc[name,&#39;deck_pos&#39;].union(row[&#39;deck_pos&#39;])
                    found_match = True
            if not found_match:
                d[&#39;loc&#39;] = row[&#39;loc&#39;]
                d[&#39;deck_pos&#39;] = row[&#39;deck_pos&#39;]
            return pd.Series(d)
        reagent_df[[&#39;loc&#39;, &#39;deck_pos&#39;]] = reagent_df.apply(merge_dry, axis=1)
                    
        theoretical_df = pd.concat((reagent_df.loc[:,[&#39;loc&#39;, &#39;deck_pos&#39;,\
                &#39;vol&#39;,&#39;container&#39;]], product_df.loc[:,[&#39;loc&#39;, &#39;deck_pos&#39;,&#39;vol&#39;,&#39;container&#39;]]))
        result_df = pd.read_csv(os.path.join(self.eve_files_path,&#39;wellmap.tsv&#39;), sep=&#39;\t&#39;).set_index(&#39;chem_name&#39;)
        sbs = result_df.join(theoretical_df, rsuffix=&#39;_t&#39;) #side by side
        #could still have NaNs if a dry reagent was made, but not specified at start
        sbs_rows_w_nan = sbs.loc[sbs.isna().any(axis=1)].index
        for chem_name in sbs_rows_w_nan:
            for dry_name in dry_containers.index:
                if dry_name in chem_name:
                    sbs.at[chem_name,&#39;loc_t&#39;] = dry_containers.at[dry_name,&#39;loc&#39;]
                    sbs.at[chem_name,&#39;deck_pos_t&#39;] = dry_containers.at[dry_name,&#39;deck_pos&#39;]
                    sbs.at[chem_name,&#39;vol_t&#39;] = &#39;any&#39;
                    sbs.at[chem_name,&#39;container_t&#39;] = &#39;any&#39;
        return sbs

    def _vol_calc(self, name):
        &#39;&#39;&#39;
        params:
            str name: chem_name
        returns:
            volume at end in that name
        &#39;&#39;&#39;
        dispenses = self.rxn_df.loc[(self.rxn_df[&#39;op&#39;] == &#39;dilution&#39;) |
                (self.rxn_df[&#39;op&#39;] == &#39;transfer&#39;)][name].sum()
        transfer_aspirations = self.rxn_df.loc[(self.rxn_df[&#39;op&#39;]==&#39;transfer&#39;) &amp;\
                (self.rxn_df[&#39;chemical_name&#39;] == name),self._products].sum().sum()
        dilution_rows = self.rxn_df.loc[(self.rxn_df[&#39;op&#39;]==&#39;dilution&#39;) &amp;\
                (self.rxn_df[&#39;chemical_name&#39;] == name),:]
        def calc_dilution_vol(row):
            _, reagent_transfer_row = self._get_dilution_transfer_rows(row) #the _ is water
            return reagent_transfer_row[self._products].sum()

        if dilution_rows.empty:
            dilution_aspirations = 0.0
        else:
            dilution_vols = dilution_rows.apply(lambda r: calc_dilution_vol(r),axis=1)
            dilution_aspirations = dilution_vols.sum()
        return dispenses - transfer_aspirations - dilution_aspirations
    
    def _is_valid_contents_sbs(self, row):
        &#39;&#39;&#39;
        tests if a row of contents sbs is valid
        params:  
            pd.Series row: has vol_t and vol  
        returns:  
            False if vol_t!=vol else True  
        Postconditions:  
            If vol_t!=vol the row will be printed  
            
        &#39;&#39;&#39;
        if not math.isclose(row[&#39;vol_t&#39;], row[&#39;vol&#39;]):
            print(&#39;&lt;&lt;controller&gt;&gt; contents error:&#39;)
            print(row.to_frame().T)
            print()
            return False
        return True


        if not sbs.loc[~sbs[&#39;flag&#39;]].empty:
            print(&#39;&lt;&lt;controller&gt;&gt; found some invalid contents. Displaying rows&#39;)
            container_index = sbs.loc[~sbs[&#39;flag&#39;]].index.get_level_values(&#39;container&#39;)
            print(sbs.loc[container_index])
        else:
            print(&#39;&lt;&lt;controller&gt;&gt; Well done! Product have correct ratios of reagents&#39;)

    def _create_contents_sbs(self):
        &#39;&#39;&#39;
        constructs a side by side frame from the history in well_history.tsv and the reaction
        df
        NOTE: completely ignores aspiration, but if all of your dispenses are correct, and your
        final contents are correct you&#39;re looking pretty good
        &#39;&#39;&#39;
        history = pd.read_csv(os.path.join(self.eve_files_path, &#39;well_history.tsv&#39;),na_filter=False,sep=&#39;\t&#39;).rename(columns={&#39;chemical&#39;:&#39;chem_name&#39;})
        disp_hist = history.loc[history[&#39;chem_name&#39;].astype(bool)]
        contents = disp_hist.groupby([&#39;container&#39;,&#39;chem_name&#39;]).sum()
        theoretical_his_list = []
        for _, row in self.rxn_df.loc[(self.rxn_df[&#39;op&#39;] == &#39;transfer&#39;) | \
                (self.rxn_df[&#39;op&#39;] == &#39;dilution&#39;)].iterrows():
            if row[&#39;op&#39;] == &#39;transfer&#39;:
                for product in self._products:
                    theoretical_his_list.append((product, row[product], row[&#39;chemical_name&#39;]))
            else: #row[&#39;op&#39;] == &#39;dilution&#39;
                water_transfer_row, reagent_transfer_row = self._get_dilution_transfer_rows(row) #the _ is water
                product_vols = water_transfer_row[self._products]
                target_reagent = product_vols.loc[~product_vols.apply(lambda x: \
                        math.isclose(x,0,abs_tol=1e-9))].index[0]
                theoretical_his_list.append((target_reagent, water_transfer_row[target_reagent], \
                        &#39;WaterC1.0&#39;))
                theoretical_his_list.append((target_reagent, \
                        reagent_transfer_row[target_reagent], \
                        reagent_transfer_row[&#39;chemical_name&#39;]))
        theoretical_his = pd.DataFrame(theoretical_his_list, \
                columns=[&#39;container&#39;, &#39;vol&#39;, &#39;chem_name&#39;])
        theoretical_contents = theoretical_his.groupby([&#39;container&#39;,&#39;chem_name&#39;]).sum()
        theoretical_contents = theoretical_contents.loc[~theoretical_contents[&#39;vol&#39;].apply(lambda x:\
                math.isclose(x,0))]
        sbs = theoretical_contents.join(contents, how=&#39;left&#39;,lsuffix=&#39;_t&#39;)
        return sbs</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="controller.Controller" href="#controller.Controller">Controller</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="controller.ProtocolExecutor.check_products"><code class="name flex">
<span>def <span class="ident">check_products</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>checks to ensure that the products were correctly initialized<br>
returns<br>
int found_errors:<br>
code:<br>
0: OK.<br>
1: Some Errors, but could run<br>
2: Critical. Abort</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_products(self):
    &#39;&#39;&#39;
    checks to ensure that the products were correctly initialized  
    returns  
        int found_errors:  
            code:  
            0: OK.  
            1: Some Errors, but could run  
            2: Critical. Abort  
    &#39;&#39;&#39;
    found_errors = 0
    for i, r in self.robo_params[&#39;product_df&#39;].loc[\
            ~self.robo_params[&#39;product_df&#39;][&#39;labware&#39;].astype(bool) &amp; \
            ~self.robo_params[&#39;product_df&#39;][&#39;container&#39;].astype(bool)].iterrows():
        found_errors = max(found_errors,1)
        print(&#39;&lt;&lt;controller&gt;&gt; {} has no specified labware or container. It could end up in anything that has enough volume to contain it. Are you sure that\&#39;s what you want? &#39;.format(i))
    return found_errors</code></pre>
</details>
</dd>
<dt id="controller.ProtocolExecutor.init_robot"><code class="name flex">
<span>def <span class="ident">init_robot</span></span>(<span>self, simulate)</span>
</code></dt>
<dd>
<div class="desc"><p>calls super init robot, and then sends an init_containers command to initialize all the
prodcuts<br>
params:<br>
bool simulate: whether the robot should run a simulation</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def init_robot(self,simulate):
    &#39;&#39;&#39;
    calls super init robot, and then sends an init_containers command to initialize all the
    prodcuts  
    params:  
        bool simulate: whether the robot should run a simulation  
    &#39;&#39;&#39;
    super().init_robot(simulate)
    #send robot data to initialize empty product containers. Because we know things like total
    #vol and desired labware, this makes sense for a planned experiment
    self.portal.send_pack(&#39;init_containers&#39;, self.robo_params[&#39;product_df&#39;].to_dict())</code></pre>
</details>
</dd>
<dt id="controller.ProtocolExecutor.run_all_tests"><code class="name flex">
<span>def <span class="ident">run_all_tests</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>runs all post rxn tests<br>
Returns:<br>
bool: True if all tests were passed</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_all_tests(self):
    &#39;&#39;&#39;
    runs all post rxn tests  
    Returns:  
        bool: True if all tests were passed  
    &#39;&#39;&#39;
    print(&#39;&lt;&lt;controller&gt;&gt; running post execution tests&#39;)
    valid = True
    valid = valid and self.test_vol_lab_cont()
    valid = valid and self.test_contents()
    return valid</code></pre>
</details>
</dd>
<dt id="controller.ProtocolExecutor.run_protocol"><code class="name flex">
<span>def <span class="ident">run_protocol</span></span>(<span>self, simulate=False, port=50000)</span>
</code></dt>
<dd>
<div class="desc"><p>The real deal. Input a server addr and port if you choose and protocol will be run<br>
params:<br>
str simulate: (this should never be used in normal operation. It is for debugging
on the robot)<br>
NOTE: the simulate here is a little different than running run_simulation(). This simulate
is sent to the robot to tell it to simulate the reaction, but that it all. The other
simulate changes some things about how code is run from the controller</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_protocol(self, simulate=False, port=50000):
    &#39;&#39;&#39;
    The real deal. Input a server addr and port if you choose and protocol will be run  
    params:  
        str simulate: (this should never be used in normal operation. It is for debugging
          on the robot)  
    NOTE: the simulate here is a little different than running run_simulation(). This simulate
      is sent to the robot to tell it to simulate the reaction, but that it all. The other
      simulate changes some things about how code is run from the controller
    &#39;&#39;&#39;
    print(&#39;&lt;&lt;controller&gt;&gt; RUNNING PROTOCOL&#39;)
    self._run(port, simulate=simulate)
    print(&#39;&lt;&lt;controller&gt;&gt; EXITING PROTOCOL&#39;)</code></pre>
</details>
</dd>
<dt id="controller.ProtocolExecutor.run_simulation"><code class="name flex">
<span>def <span class="ident">run_simulation</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>runs a full simulation of the protocol with
Temporarilly overwrites the self.server_ip with loopback, but will restore it at
end of function<br>
Returns:<br>
bool: True if all tests were passed</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def run_simulation(self):
    &#39;&#39;&#39;
    runs a full simulation of the protocol with
    Temporarilly overwrites the self.server_ip with loopback, but will restore it at
    end of function  
    Returns:  
        bool: True if all tests were passed  
    &#39;&#39;&#39;
    #cache some things before you overwrite them for the simulation
    stored_server_ip = self.server_ip
    stored_simulate = self.simulate
    self.server_ip = &#39;127.0.0.1&#39;
    self.simulate = True

    print(&#39;&lt;&lt;controller&gt;&gt; ENTERING SIMULATION&#39;)
    port = 50000
    #launch an eve server in background for simulation purposes
    b = threading.Barrier(2,timeout=20)
    eve_thread = threading.Thread(target=launch_eve_server, kwargs={&#39;my_ip&#39;:&#39;&#39;,&#39;barrier&#39;:b},name=&#39;eve_thread&#39;)
    eve_thread.start()

    #do create a connection
    b.wait()
    self._run(port, simulate=True)

    #run post execution tests
    tests_passed = self.run_all_tests()

    #collect the eve thread
    eve_thread.join()

    #restore changed vars
    self.server_ip = stored_server_ip
    self.simulate = stored_simulate
    print(&#39;&lt;&lt;controller&gt;&gt; EXITING SIMULATION&#39;)
    return tests_passed</code></pre>
</details>
</dd>
<dt id="controller.ProtocolExecutor.test_contents"><code class="name flex">
<span>def <span class="ident">test_contents</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>tests to ensure that the contents of each container is correct
note does not work for dilutions, and does not check reagents<br>
params:<br>
df rxn_df: from excel<br>
bool use_cache: True if data is cached<br>
str eve_logpath: the path to the eve logfiles<br>
Postconditions:<br>
if a difference was found it will be displayed,<br>
if no differences are found, a friendly print message will be displayed<br>
Returns:<br>
bool: True if all tests were passed</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_contents(self):
    &#39;&#39;&#39;
    tests to ensure that the contents of each container is correct
    note does not work for dilutions, and does not check reagents  
    params:  
        df rxn_df: from excel  
        bool use_cache: True if data is cached  
        str eve_logpath: the path to the eve logfiles  
    Postconditions:  
        if a difference was found it will be displayed,  
        if no differences are found, a friendly print message will be displayed  
    Returns:  
        bool: True if all tests were passed  
    &#39;&#39;&#39;
    sbs = self._create_contents_sbs()
    sbs[&#39;flag&#39;] = sbs.apply(self._is_valid_contents_sbs,axis=1)
    filtered_sbs = sbs.loc[~sbs[&#39;flag&#39;]]
    if filtered_sbs.empty:
        print(&#39;&lt;&lt;controller&gt;&gt; congrats! Contents are correct!&#39;)
    else:
        print(&#39;&lt;&lt;controller&gt;&gt; there ere some content errors&#39;)
        with open(os.path.join(self.debug_path,&#39;contents_sbs.pkl&#39;), &#39;wb&#39;) as sbs_pkl:
            dill.dump(sbs, sbs_pkl)
        if input(&#39;&lt;&lt;controller&gt;&gt; would you like to view the full sbs? [yn] &#39;).lower() == &#39;y&#39;:
            print(sbs)
        return False
    return True</code></pre>
</details>
</dd>
<dt id="controller.ProtocolExecutor.test_vol_lab_cont"><code class="name flex">
<span>def <span class="ident">test_vol_lab_cont</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>tests that vol, labware, and containers are correct for a row of a side by side df with
those attributes<br>
Preconditions:<br>
labware_df, reagent_df, and products_df are all initialized as vals in robo_params<br>
self.rxn_df is initialized<br>
df labware_df:<br>
df rxn_df: as from excel<br>
df reagent_df: info on reagents. columns from sheet. See excel specification<br>
df product_df:<br>
self.eve_files_path + wellmap.tsv exists (this is a file output by eve that is shipped
over in close step<br>
Postconditions:<br>
Any errors will be printed to the screen.<br>
If errors were found, a pkl of the sbs will be written<br>
Returns:<br>
bool: True if all tests were passed</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def test_vol_lab_cont(self):
    &#39;&#39;&#39;
    tests that vol, labware, and containers are correct for a row of a side by side df with
    those attributes  
    Preconditions:  
        labware_df, reagent_df, and products_df are all initialized as vals in robo_params  
        self.rxn_df is initialized  
        df labware_df:  
        df rxn_df: as from excel  
        df reagent_df: info on reagents. columns from sheet. See excel specification  
        df product_df:  
        self.eve_files_path + wellmap.tsv exists (this is a file output by eve that is shipped
          over in close step  
    Postconditions:  
        Any errors will be printed to the screen.  
        If errors were found, a pkl of the sbs will be written  
    Returns:  
        bool: True if all tests were passed  
    &#39;&#39;&#39;
    sbs = self._get_vol_lab_cont_sbs()
    sbs[&#39;flag&#39;] = sbs.apply(lambda row: self._is_valid_vol_lab_cont_sbs(row), axis=1)
    filtered_sbs = sbs.loc[~sbs[&#39;flag&#39;]]
    if filtered_sbs.empty:
        print(&#39;&lt;&lt;controller&gt;&gt; congrats! Volumes, labware, containers, and deck_poses look good!&#39;)
    else:
        print(&#39;&lt;&lt;controller&gt;&gt; volume/deck pos/labware/container errors&#39;)
        with open(os.path.join(self.debug_path,&#39;vol_lab_cont_sbs.pkl&#39;), &#39;wb&#39;) as sbs_pkl:
            dill.dump(sbs, sbs_pkl)
        if input(&#39;&lt;&lt;controller&gt;&gt; would you like to view the full sbs? [yn] &#39;).lower() == &#39;y&#39;:
            print(sbs)
        return False
    return True</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="controller.Controller" href="#controller.Controller">Controller</a></b></code>:
<ul class="hlist">
<li><code><a title="controller.Controller.ChemCacheEntry" href="#controller.Controller.ChemCacheEntry">ChemCacheEntry</a></code></li>
<li><code><a title="controller.Controller.check_labware" href="#controller.Controller.check_labware">check_labware</a></code></li>
<li><code><a title="controller.Controller.check_reagents" href="#controller.Controller.check_reagents">check_reagents</a></code></li>
<li><code><a title="controller.Controller.check_rxn_df" href="#controller.Controller.check_rxn_df">check_rxn_df</a></code></li>
<li><code><a title="controller.Controller.close_connection" href="#controller.Controller.close_connection">close_connection</a></code></li>
<li><code><a title="controller.Controller.execute_protocol_df" href="#controller.Controller.execute_protocol_df">execute_protocol_df</a></code></li>
<li><code><a title="controller.Controller.plot_LAM_overlay" href="#controller.Controller.plot_LAM_overlay">plot_LAM_overlay</a></code></li>
<li><code><a title="controller.Controller.plot_kin_subplots" href="#controller.Controller.plot_kin_subplots">plot_kin_subplots</a></code></li>
<li><code><a title="controller.Controller.plot_single_kin" href="#controller.Controller.plot_single_kin">plot_single_kin</a></code></li>
<li><code><a title="controller.Controller.run_all_checks" href="#controller.Controller.run_all_checks">run_all_checks</a></code></li>
<li><code><a title="controller.Controller.translate_wellmap" href="#controller.Controller.translate_wellmap">translate_wellmap</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="controller.init_parser" href="#controller.init_parser">init_parser</a></code></li>
<li><code><a title="controller.launch_auto" href="#controller.launch_auto">launch_auto</a></code></li>
<li><code><a title="controller.launch_protocol_exec" href="#controller.launch_protocol_exec">launch_protocol_exec</a></code></li>
<li><code><a title="controller.main" href="#controller.main">main</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="controller.AbstractPlateReader" href="#controller.AbstractPlateReader">AbstractPlateReader</a></code></h4>
<ul class="two-column">
<li><code><a title="controller.AbstractPlateReader.PROTOCOL_PATH" href="#controller.AbstractPlateReader.PROTOCOL_PATH">PROTOCOL_PATH</a></code></li>
<li><code><a title="controller.AbstractPlateReader.SPECTRO_ROOT_PATH" href="#controller.AbstractPlateReader.SPECTRO_ROOT_PATH">SPECTRO_ROOT_PATH</a></code></li>
<li><code><a title="controller.AbstractPlateReader.edit_layout" href="#controller.AbstractPlateReader.edit_layout">edit_layout</a></code></li>
<li><code><a title="controller.AbstractPlateReader.exec_macro" href="#controller.AbstractPlateReader.exec_macro">exec_macro</a></code></li>
<li><code><a title="controller.AbstractPlateReader.load_reader_data" href="#controller.AbstractPlateReader.load_reader_data">load_reader_data</a></code></li>
<li><code><a title="controller.AbstractPlateReader.run_protocol" href="#controller.AbstractPlateReader.run_protocol">run_protocol</a></code></li>
<li><code><a title="controller.AbstractPlateReader.shake" href="#controller.AbstractPlateReader.shake">shake</a></code></li>
<li><code><a title="controller.AbstractPlateReader.shutdown" href="#controller.AbstractPlateReader.shutdown">shutdown</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="controller.AutoContr" href="#controller.AutoContr">AutoContr</a></code></h4>
<ul class="">
<li><code><a title="controller.AutoContr.check_rxn_df" href="#controller.AutoContr.check_rxn_df">check_rxn_df</a></code></li>
<li><code><a title="controller.AutoContr.run_protocol" href="#controller.AutoContr.run_protocol">run_protocol</a></code></li>
<li><code><a title="controller.AutoContr.run_simulation" href="#controller.AutoContr.run_simulation">run_simulation</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="controller.Controller" href="#controller.Controller">Controller</a></code></h4>
<ul class="">
<li><code><a title="controller.Controller.ChemCacheEntry" href="#controller.Controller.ChemCacheEntry">ChemCacheEntry</a></code></li>
<li><code><a title="controller.Controller.PLATEREADER_INDEX_TRANSLATOR" href="#controller.Controller.PLATEREADER_INDEX_TRANSLATOR">PLATEREADER_INDEX_TRANSLATOR</a></code></li>
<li><code><a title="controller.Controller.check_labware" href="#controller.Controller.check_labware">check_labware</a></code></li>
<li><code><a title="controller.Controller.check_reagents" href="#controller.Controller.check_reagents">check_reagents</a></code></li>
<li><code><a title="controller.Controller.check_rxn_df" href="#controller.Controller.check_rxn_df">check_rxn_df</a></code></li>
<li><code><a title="controller.Controller.close_connection" href="#controller.Controller.close_connection">close_connection</a></code></li>
<li><code><a title="controller.Controller.execute_protocol_df" href="#controller.Controller.execute_protocol_df">execute_protocol_df</a></code></li>
<li><code><a title="controller.Controller.init_robot" href="#controller.Controller.init_robot">init_robot</a></code></li>
<li><code><a title="controller.Controller.plot_LAM_overlay" href="#controller.Controller.plot_LAM_overlay">plot_LAM_overlay</a></code></li>
<li><code><a title="controller.Controller.plot_kin_subplots" href="#controller.Controller.plot_kin_subplots">plot_kin_subplots</a></code></li>
<li><code><a title="controller.Controller.plot_single_kin" href="#controller.Controller.plot_single_kin">plot_single_kin</a></code></li>
<li><code><a title="controller.Controller.run_all_checks" href="#controller.Controller.run_all_checks">run_all_checks</a></code></li>
<li><code><a title="controller.Controller.run_protocol" href="#controller.Controller.run_protocol">run_protocol</a></code></li>
<li><code><a title="controller.Controller.run_simulation" href="#controller.Controller.run_simulation">run_simulation</a></code></li>
<li><code><a title="controller.Controller.save" href="#controller.Controller.save">save</a></code></li>
<li><code><a title="controller.Controller.translate_wellmap" href="#controller.Controller.translate_wellmap">translate_wellmap</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="controller.DummyReader" href="#controller.DummyReader">DummyReader</a></code></h4>
</li>
<li>
<h4><code><a title="controller.PlateReader" href="#controller.PlateReader">PlateReader</a></code></h4>
<ul class="two-column">
<li><code><a title="controller.PlateReader.PROTOCOL_PATH" href="#controller.PlateReader.PROTOCOL_PATH">PROTOCOL_PATH</a></code></li>
<li><code><a title="controller.PlateReader.SPECTRO_DATA_PATH" href="#controller.PlateReader.SPECTRO_DATA_PATH">SPECTRO_DATA_PATH</a></code></li>
<li><code><a title="controller.PlateReader.SPECTRO_ROOT_PATH" href="#controller.PlateReader.SPECTRO_ROOT_PATH">SPECTRO_ROOT_PATH</a></code></li>
<li><code><a title="controller.PlateReader.edit_layout" href="#controller.PlateReader.edit_layout">edit_layout</a></code></li>
<li><code><a title="controller.PlateReader.exec_macro" href="#controller.PlateReader.exec_macro">exec_macro</a></code></li>
<li><code><a title="controller.PlateReader.load_reader_data" href="#controller.PlateReader.load_reader_data">load_reader_data</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="controller.ProtocolExecutor" href="#controller.ProtocolExecutor">ProtocolExecutor</a></code></h4>
<ul class="two-column">
<li><code><a title="controller.ProtocolExecutor.check_products" href="#controller.ProtocolExecutor.check_products">check_products</a></code></li>
<li><code><a title="controller.ProtocolExecutor.init_robot" href="#controller.ProtocolExecutor.init_robot">init_robot</a></code></li>
<li><code><a title="controller.ProtocolExecutor.run_all_tests" href="#controller.ProtocolExecutor.run_all_tests">run_all_tests</a></code></li>
<li><code><a title="controller.ProtocolExecutor.run_protocol" href="#controller.ProtocolExecutor.run_protocol">run_protocol</a></code></li>
<li><code><a title="controller.ProtocolExecutor.run_simulation" href="#controller.ProtocolExecutor.run_simulation">run_simulation</a></code></li>
<li><code><a title="controller.ProtocolExecutor.test_contents" href="#controller.ProtocolExecutor.test_contents">test_contents</a></code></li>
<li><code><a title="controller.ProtocolExecutor.test_vol_lab_cont" href="#controller.ProtocolExecutor.test_vol_lab_cont">test_vol_lab_cont</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>